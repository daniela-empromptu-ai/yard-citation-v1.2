{
  "turn": 1,
  "managed_messages": [
    {
      "id": "turn-1-user",
      "role": "user",
      "parts": [
        {
          "type": "text",
          "text": "<USER_REFERENCE>\n[id:352fb078-c549-4c22-b946-636fc5abe09a, type: pastedText, name: UGFzdGVkIFRleHQ=]\n### Pasted Text (PASTEDTEXT)\n\n# Empromptu Builder â TECHNICAL BUILD PROMPT\n## Yard: Citation Intelligence Creator Ops (V0, Internal)\n\n> **Important**\n> - Build the entire application from scratch using **Next.js (App Router) + TypeScript**.\n> - Use the platformâs **builtâin Postgres database** (builtâin DB).\n> - This prompt is a **strict spec**: do not add features, tables, fields, routes, or behaviors that are not explicitly required here.\n> - **All UI must be dataâdriven from DB tables**. No hardcoded mock arrays.\n> - You must **create all DB tables** listed in **Section 7** in the builtâin DB.\n> - You must **seed** the demo dataset listed in **Section 9** into those tables.\n> - Provide admin buttons in Settings to **Clear Demo Data** and **Seed Demo Data**.\n\n---\n\n## 1) Product Goal (What to Build)\n\nBuild an **internal, humanâinâtheâloop ops tool** that enables a team to:\n1. Create campaigns with creative briefs + topics/personas + optional prompt gaps + citations (manual or CSV import)\n2. Generate and review **exactly 15** YouTube search terms per campaign\n3. Discover and shortlist technical creators (filter out dormant + autodubbed/label + lifestyle/career)\n4. Ingest real creator content (YouTube transcripts primary; blogs/Medium when URLs exist; Reddit monitoring; plus optional podcast/newsletter URLs)\n5. Score creators with a **weighted rubric** and **evidence traceability** (URLs + quotes + timestamps)\n6. Support a human review step before outreach\n7. Generate outreach drafts + follow-up checklist (assistive only; **no automated emailing**)\n8. Track creator reliability flags (ghosted, reliable, do not contact, price too high) + campaign history\n9. Show ops metrics (creators analyzed, approved, emails sent, booking rate)\n\n**Hard requirement:** all scoring/rationale/angles must reference **actual ingested content** stored in DB.\n\n---\n\n## 2) NonâNegotiable Constraints\n\n### 2.1 Framework & Runtime\n- Next.js App Router + TypeScript.\n- Server actions (or API routes) for writes.\n- Desktopâfirst UI (dense tables, drawers, modals).\n\n### 2.2 BuiltâIn Database\n- Use the platform **builtâin Postgres DB**.\n- Create all tables listed in Section 7.\n- Store all demo data in DB (Section 9).\n\n### 2.3 No AutoâOutreach\n- No sending emails.\n- No automated LinkedIn/X actions.\n- Only drafts + copy buttons + manual tracking.\n\n### 2.4 HumanâinâtheâLoop\n- âOutreach-readyâ must only happen after scoring + evidence validation and must be reviewable by a human role.\n\n### 2.5 Environment Variables\n- Create a `.env.local` file with placeholder values for all external integrations:\n  - `ANTHROPIC_API_KEY`\n  - `YOUTUBE_API_KEY`\n  - `REDDIT_CLIENT_ID`\n  - `REDDIT_CLIENT_SECRET`\n- Read all API keys from environment variables. Never hardcode them.\n- YouTube and Reddit API calls are stubbed for V0 â return mock responses if the key is a placeholder. Anthropic calls must be real.\n\n---\n\n## 3) Roles (Internal Users)\n\nCreate role behaviors:\n- **Qualifier**: reviews creators, validates evidence, approves/rejects, may override score with notes.\n- **Outreach**: uses outreach queue, copies drafts, logs manual outreach states (sent/replied/ghosted/booked).\n- **Admin**: integrations + thresholds + seed/clear tools.\n\n**Simple role switching:** role switcher in top bar; store current user in localStorage. No complex auth required for V0.\n\n---\n\n## 4) Required Routes (Must Exist)\n\nAll routes must render DB data and be functional with seeded demo data.\n\n1. `/` â Dashboard (role-aware)\n2. `/campaigns` â Campaign list\n3. `/campaigns/new` â Campaign setup wizard\n4. `/campaigns/[id]` â Campaign workspace with tabs:\n   - `overview`\n   - `brief-inputs`\n   - `search-terms`\n   - `discovery`\n   - `ingestion`\n   - `scoring`\n   - `review`\n   - `outreach`\n   - `activity`\n5. `/creators` â Global creators DB list\n6. `/creators/[id]` â Creator profile detail\n7. `/outreach` â Outreach queue (all campaigns)\n8. `/reddit` â Reddit monitoring dashboard; all fetched threads across campaigns with campaign filter; read-only. See Â§5.10.\n9. `/metrics` â Ops metrics dashboard\n10. `/settings` â Integrations + thresholds + admin tools (seed/clear)\n\n---\n\n## 5) Core Workflows (Functional Behavior)\n\n### 5.1 Campaign Setup\nCreate campaign with:\n- client\n- campaign name\n- GEO targets (array of strings)\n- language\n- product category\n- creative brief (rich text, paste from PDF or doc)\n- personas (multi-add)\n- topics (manual add + optional AI suggestions; max 5 suggested topics; user can edit/approve)\n- prompt gaps + citations (manual OR CSV import)\n- prompts must be editable and have draft/approved status\n\n### 5.2 Search Term Generation (Canonical)\nFrom campaign context (brief + topics + personas + product category):\n- Generate **exactly 15** YouTube search terms\n- Each includes:\n  - category tag (one of 7 tags)\n  - âwhy it helpsâ explanation (1â2 sentences)\n- User can edit/reorder/approve terms\n- Only approved terms used in discovery\n\n### 5.3 Discovery\n- Show discovered creators per approved search term\n- Filters:\n  - language\n  - GEO match\n  - dormant (exclude)\n  - autodubbed/label suspected (exclude)\n  - lifestyle/career (exclude)\n  - competitor affiliated (exclude)\n- Add selected creators into the campaign pipeline\n\nDiscovery integration can be:\n- manual creator URL add (required), plus optional YouTube search if configured.\nRegardless, the screen must be meaningful using seeded DB data.\n\n### 5.4 Ingestion (Content Storage)\nFor each campaign creator, ingest content items:\n- YouTube transcripts (primary)\n- blogs/Medium/corporate blog URLs (when provided)\n- Reddit threads (see Â§5.10 â fetched via API, not manual paste)\n- optional: podcasts/newsletters (manual URL + paste text acceptable)\n\nStore raw text and metadata (URL, date, view counts if available).\nTrack ingestion status: not_started / queued / running / complete / failed.\n\n### 5.5 Scoring + Evidence (Rubric)\nEvaluate each campaign creator and store:\n- overall score 0â100\n- dimension scores 0â100 for 5 dimensions (weights below)\n- strengths & weaknesses\n- recommended content links grouped high/medium/low view counts (when view_count exists)\n- 3â5 suggested content angles\n- evidence snippets (URL + excerpt + timestamps for video)\n\nRubric weights:\n- Technical relevance â 30%\n- Audience alignment â 25%\n- Content quality â 20%\n- Channel performance â 15%\n- Brand fit â 10%\n\nIf insufficient evidence exists:\n- mark Needs Manual Review\n- block outreach-ready\n\n### 5.6 Evidence / Traceability (Hard Requirement)\nThe system must show:\n- source URLs\n- quotes/excerpts (must exist in ingested raw_text)\n- video timestamps when applicable\n\n### 5.7 Outreach Prep (Assistive Only)\nFor approved creators:\n- generate outreach email draft (subject + body)\n- generate followâup checklist (Email / LinkedIn / X)\n- track outreach state manually:\n  - not_started, drafted, copied, sent, replied, ghosted, booked\n- add outreach activity log entries for every state change\n\n### 5.8 Creator Profiles + Status Flags\nPersistent creator record includes:\n- platforms and URLs\n- contact info (PII masked by default)\n- status flags:\n  - reliable\n  - ghosted / not responsive\n  - do not contact\n  - price too high\n- notes + campaign history\n\n### 5.10 Reddit Monitoring\n\n**Purpose:** Surface Reddit threads relevant to campaign topics and brand visibility signals. Read-only â no posting, no commenting, no automation.\n\n**Configuration (per campaign, set in campaign Reddit tab):**\n- Subreddits to watch (free text, e.g. r/kubernetes, r/devops)\n- Keywords to match (default: pulled from campaign search terms; user can edit/add)\n\n**Fetching:**\n- User triggers fetch manually via \"Fetch Reddit\" button in the campaign Reddit tab or from `/reddit`\n- System queries Reddit API using configured subreddits + keywords\n- Each result stored as a `content_items` row:\n  - `platform = reddit`, `content_type = reddit_thread`\n  - `metadata_json` must include: `subreddit`, `karma`, `comment_count`, `reddit_post_id`\n- Duplicate URLs skipped (unique constraint on `content_items.url`)\n- Requires `integration_status.reddit` to be configured in Settings\n\n**`/reddit` route displays:**\n- All fetched Reddit threads across all campaigns, sorted by `fetched_at` desc\n- Filter by campaign\n- Each row: subreddit, thread title, karma, comment count, date fetched, campaign tag, link to original thread\n- Empty state when no threads have been fetched\n\n**Reddit tab within `/campaigns/[id]`:**\n- Shows only threads fetched for that campaign\n- Subreddit + keyword configuration UI\n- \"Fetch Reddit\" button\n\n---\n\n### 5.9 Ops Metrics\nMust compute from DB:\n- creators analyzed per week\n- creators approved for outreach per week\n- emails sent per week (baseline reference 130)\n- booking rate (baseline reference 7â10%)\n\n---\n\n## 6) AI Features (Allowed + Required)\n\nAI calls must be server-side and must store all outputs in DB.\n\n### 6.1 AI: Suggest Topics (UI must include)\nInput: campaign creative brief  \nOutput: up to 5 topics, each with confidence (0â1) + 1 sentence rationale  \nUser can edit/approve topics.\n\nStore in `campaign_topics`.\n\n### 6.2 AI: Generate Search Terms (Required)\nInput: campaign brief + topics + personas + product category  \nOutput: exactly 15 terms with category_tag + why_it_helps.\n\nStore in `campaign_search_terms`.\n\n### 6.3 AI: Score Creator (Required)\nInput:\n- campaign context (brief, topics, personas, prompt gaps, citations)\n- creator profile + platforms\n- ingested content_items (raw_text + metadata + URLs)\n\nOutput must include:\n- dimension scores 0â100\n- overall score (computed using rubric weights)\n- strengths (3â6 bullets) with evidence snippet IDs\n- weaknesses (2â5 bullets) with evidence snippet IDs\n- 3â5 content angles with linked evidence\n- evidence snippets list containing:\n  - content_item_id\n  - timestamp_start_seconds (nullable)\n  - timestamp_end_seconds (nullable)\n  - quote (direct excerpt from raw_text)\n  - dimension\n  - why_it_matters\n\n**Evidence validation (must implement):**\n- Every evidence quote must be verified as an **exact substring** of the referenced `content_items.raw_text`.\n- If any quote fails:\n  - mark evaluation needs_manual_review=true\n  - store reason\n  - do not set outreach_ready\n\n### 6.4 AI: Outreach Draft (Required)\nInput:\n- campaign context\n- creator identity/platforms\n- selected content angle\n- selected evidence snippets\n\nOutput:\n- email subject + body (markdown)\n- follow-up checklist with day offsets:\n  - Email Day 2 / Day 5 / Day 9\n  - LinkedIn Day 2 / Day 5\n  - X Day 5 (optional)\n\nStore in `outreach_packets` + link evidence via `outreach_packet_evidence`.\n\n**No send button. Copy-only.**\n\n---\n\n## 7) Database Schema (BuiltâIn Postgres) â Tables to Create\n\n> Create all tables below. Use UUID primary keys and timestamptz timestamps.\n> Implement foreign keys and indexes as listed.\n> Do not add extra columns.\n\n### 7.1 `app_users`\n- id (uuid, PK)\n- name (text, not null)\n- email (text, not null, unique)\n- role (text, not null; one of: qualifier, outreach, admin)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\n### 7.2 `clients`\n- id (uuid, PK)\n- name (text, not null, unique)\n- website_url (text, null)\n- notes (text, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\n### 7.3 `campaigns`\n- id (uuid, PK)\n- client_id (uuid, FK -> clients.id, not null)\n- name (text, not null)\n- owner_user_id (uuid, FK -> app_users.id, not null)\n- collaborator_user_id (uuid, FK -> app_users.id, null)\n- status (text, not null; one of: draft, active, archived)\n- stage (text, not null; one of: draft, terms, discovery, ingestion, scoring, review, outreach, tracking, complete)\n- geo_targets (text[], not null, default empty)\n- deadline (date, null)\n- language (text, not null, default 'English')\n- product_category (text, null)\n- creative_brief (text, not null)\n- creative_brief_source_url (text, null)\n- additional_prompt_context (text, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: client_id, owner_user_id, status, stage\n\n### 7.4 `campaign_personas`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- persona_name (text, not null)\n- created_at (timestamptz, not null)\n\nUnique: (campaign_id, persona_name)\n\n### 7.5 `campaign_topics`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- topic (text, not null)\n- source (text, not null; one of: manual, ai_suggested)\n- confidence (numeric(3,2), null)\n- rationale (text, null)\n- order_index (int, not null, default 0)\n- approved (boolean, not null, default true)\n- created_at (timestamptz, not null)\n\nUnique: (campaign_id, topic)\nIndex: campaign_id\n\n### 7.6 `campaign_prompt_gaps`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- prompt_text (text, not null)\n- priority (text, not null; one of: high, medium, low)\n- persona (text, null)\n- geo (text[], not null, default empty)\n- gap_note (text, null)\n- status (text, not null; one of: draft, approved, archived)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: campaign_id, priority, status\n\n### 7.7 `prompt_citations`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- prompt_gap_id (uuid, FK -> campaign_prompt_gaps.id, null)\n- citation_title (text, not null)\n- citation_url (text, not null)\n- source_type (text, not null; one of: docs, blog, youtube, reddit, paper, other)\n- cited_by_models (text[], not null, default empty)\n- notes (text, null)\n- created_at (timestamptz, not null)\n\nIndexes: campaign_id, prompt_gap_id, source_type\n\n### 7.8 `gumshoe_imports`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- import_type (text, not null; one of: csv, manual)\n- original_filename (text, null)\n- raw_text (text, not null)  // original CSV or pasted text\n- imported_by_user_id (uuid, FK -> app_users.id, not null)\n- created_at (timestamptz, not null)\n\nIndex: campaign_id\n\n### 7.9 `campaign_search_terms`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- term (text, not null)\n- category_tag (text, not null; one of: product_category, competitor, implementation, problem_solution, integration, programming_language, tutorial_format)\n- why_it_helps (text, not null)\n- order_index (int, not null, default 0)\n- approved (boolean, not null, default false)\n- approved_by_user_id (uuid, FK -> app_users.id, null)\n- approved_at (timestamptz, null)\n- notes (text, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: campaign_id, approved\n\n### 7.10 `creators`\n- id (uuid, PK)\n- display_name (text, not null)\n- primary_handle (text, null)\n- bio (text, null)\n- topics (text[], not null, default empty)\n- languages (text[], not null, default empty)\n- geo_focus (text[], not null, default empty)\n- competitor_affiliated (boolean, not null, default false)\n- is_dormant (boolean, not null, default false)\n- is_autodubbed_suspected (boolean, not null, default false)\n- last_content_date (date, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: display_name, is_dormant, is_autodubbed_suspected, competitor_affiliated\n\n### 7.11 `creator_platform_accounts`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- platform (text, not null; one of: youtube, github, linkedin, devto, medium, blog, podcast, newsletter, reddit, other)\n- handle (text, null)\n- url (text, not null)\n- follower_count (int, null)\n- metrics_json (jsonb, not null, default {})\n- created_at (timestamptz, not null)\n\nUnique: (platform, url)\nIndexes: creator_id, platform\n\n### 7.12 `creator_contacts`  (PII)\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null, unique)\n- email_encrypted (text, null)\n- linkedin_url (text, null)\n- x_url (text, null)\n- other_contacts_json (jsonb, not null, default {})\n- pii_last_updated_at (timestamptz, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\n### 7.13 `creator_status_flags`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- flag (text, not null; one of: reliable, ghosted, do_not_contact, price_too_high)\n- is_active (boolean, not null, default true)\n- reason (text, null)\n- set_by_user_id (uuid, FK -> app_users.id, not null)\n- set_at (timestamptz, not null)\n\nIndexes: creator_id, flag\n\n### 7.14 `creator_pricing`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- price_type (text, not null; one of: video, written, newsletter, other)\n- price_amount_usd (numeric(10,2), not null)\n- is_too_high (boolean, not null, default false)\n- notes (text, null)\n- updated_at (timestamptz, not null)\n\nIndex: creator_id\n\n### 7.15 `creator_notes`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- note_md (text, not null)\n- created_by_user_id (uuid, FK -> app_users.id, not null)\n- created_at (timestamptz, not null)\n\nIndex: creator_id\n\n### 7.16 `campaign_creators`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- creator_id (uuid, FK -> creators.id, not null)\n- added_by_user_id (uuid, FK -> app_users.id, not null)\n- source_search_term_id (uuid, FK -> campaign_search_terms.id, null)\n\n- pipeline_stage (text, not null; one of:\n  discovered, queued_for_ingestion, ingested, scored, needs_manual_review,\n  approved, outreach_ready, contacted, booked, rejected, excluded\n)\n\n- campaign_do_not_contact (boolean, not null, default false)\n- campaign_do_not_contact_reason (text, null)\n\n- ingestion_status (text, not null; one of: not_started, queued, running, complete, failed)\n- ingestion_error (text, null)\n\n- scoring_status (text, not null; one of: not_scored, scoring, scored, failed)\n- scoring_error (text, null)\n\n- outreach_owner_user_id (uuid, FK -> app_users.id, null)\n- outreach_state (text, not null; one of: not_started, drafted, copied, sent, replied, ghosted, booked)\n- last_outreach_at (timestamptz, null)\n- next_followup_due_at (date, null)\n\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nUnique: (campaign_id, creator_id)\nIndexes: campaign_id, creator_id, pipeline_stage, ingestion_status, scoring_status, outreach_state\n\n### 7.17 `content_items`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- campaign_id (uuid, FK -> campaigns.id, null)\n\n- platform (text, not null; one of: youtube, blog, medium, devto, reddit, podcast, newsletter, github, linkedin, other)\n- content_type (text, not null; one of:\n  youtube_video, blog_post, medium_post, devto_post, reddit_thread,\n  podcast_episode, newsletter_issue, github_repo, linkedin_post, other\n)\n\n- title (text, not null)\n- url (text, not null)\n- published_at (timestamptz, null)\n- fetched_at (timestamptz, null)\n\n- language (text, null)\n- raw_text (text, not null)\n- word_count (int, null)\n\n- metadata_json (jsonb, not null, default {})  // view_count, duration_seconds, subreddit, karma, etc.\n\n- ingestion_method (text, not null; one of: seed, manual_paste, fetched)\n- ingestion_status (text, not null; one of: complete, failed)\n- ingestion_error (text, null)\n\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nUnique: (url)\nIndexes: creator_id, campaign_id, platform, content_type, published_at\n\n### 7.18 `creator_evaluations`\n- id (uuid, PK)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, not null, unique)\n\n- model_provider (text, not null)\n- model_name (text, not null)\n- evaluated_at (timestamptz, not null)\n\n- evidence_coverage (text, not null; one of: strong, medium, weak, none)\n- needs_manual_review (boolean, not null, default false)\n- needs_manual_review_reason (text, null)\n\n- overall_score (int, not null, 0â100)\n- score_technical_relevance (int, not null, 0â100)\n- score_audience_alignment (int, not null, 0â100)\n- score_content_quality (int, not null, 0â100)\n- score_channel_performance (int, not null, 0â100)\n- score_brand_fit (int, not null, 0â100)\n\n- strengths_json (jsonb, not null, default [])\n- weaknesses_json (jsonb, not null, default [])\n- rationale_md (text, not null)\n\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: overall_score, needs_manual_review, evidence_coverage\n\n### 7.19 `evidence_snippets`\n- id (uuid, PK)\n- evaluation_id (uuid, FK -> creator_evaluations.id, not null)\n- content_item_id (uuid, FK -> content_items.id, not null)\n- timestamp_start_seconds (int, null)\n- timestamp_end_seconds (int, null)\n- quote (text, not null)\n- dimension (text, not null; one of: technical_relevance, audience_alignment, content_quality, channel_performance, brand_fit, general)\n- why_it_matters (text, not null)\n- created_at (timestamptz, not null)\n\nIndexes: evaluation_id, content_item_id, dimension\n\n### 7.20 `evaluation_recommended_content`\n- id (uuid, PK)\n- evaluation_id (uuid, FK -> creator_evaluations.id, not null)\n- content_item_id (uuid, FK -> content_items.id, not null)\n- bucket (text, not null; one of: high, medium, low)\n- relevance_rank (int, not null, default 0)\n- notes (text, null)\n- created_at (timestamptz, not null)\n\nUnique: (evaluation_id, content_item_id)\nIndex: evaluation_id\n\n### 7.21 `content_angles`\n- id (uuid, PK)\n- evaluation_id (uuid, FK -> creator_evaluations.id, not null)\n- title (text, not null)\n- target_prompt_gap_id (uuid, FK -> campaign_prompt_gaps.id, null)\n- persona (text, null)\n- format (text, not null; one of: tutorial, comparison, architecture, deep_dive, checklist, case_study, other)\n- key_points_json (jsonb, not null, default [])\n- selected_for_outreach (boolean, not null, default false)\n- created_at (timestamptz, not null)\n\nIndex: evaluation_id\n\n### 7.22 `angle_evidence`\n- id (uuid, PK)\n- angle_id (uuid, FK -> content_angles.id, not null)\n- evidence_snippet_id (uuid, FK -> evidence_snippets.id, not null)\n- created_at (timestamptz, not null)\n\nUnique: (angle_id, evidence_snippet_id)\nIndex: angle_id\n\n### 7.23 `human_reviews`\n- id (uuid, PK)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, not null)\n- reviewed_by_user_id (uuid, FK -> app_users.id, not null)\n- reviewed_at (timestamptz, not null)\n- decision (text, not null; one of: approved_for_outreach, rejected, needs_manual_review, excluded)\n- manual_override_score (int, null, 0â100)\n- notes_md (text, null)\n- created_at (timestamptz, not null)\n\nIndexes: campaign_creator_id, decision\n\n### 7.24 `outreach_packets`\n- id (uuid, PK)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, not null, unique)\n- created_by_user_id (uuid, FK -> app_users.id, not null)\n- subject (text, not null)\n- body_md (text, not null)\n- selected_angle_id (uuid, FK -> content_angles.id, null)\n- followup_plan_json (jsonb, not null, default [])\n- last_updated_at (timestamptz, not null)\n- created_at (timestamptz, not null)\n\nIndex: campaign_creator_id\n\n### 7.25 `outreach_packet_evidence`\n- id (uuid, PK)\n- outreach_packet_id (uuid, FK -> outreach_packets.id, not null)\n- evidence_snippet_id (uuid, FK -> evidence_snippets.id, not null)\n- created_at (timestamptz, not null)\n\nUnique: (outreach_packet_id, evidence_snippet_id)\nIndex: outreach_packet_id\n\n### 7.26 `outreach_activity`\n- id (uuid, PK)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, not null)\n- performed_by_user_id (uuid, FK -> app_users.id, not null)\n- channel (text, not null; one of: email, linkedin, x)\n- action_type (text, not null; one of: drafted, copied, sent, followup_sent, reply_logged, state_changed, note)\n- state_after (text, not null; one of: not_started, drafted, copied, sent, replied, ghosted, booked)\n- occurred_at (timestamptz, not null)\n- notes (text, null)\n\nIndexes: campaign_creator_id, channel, action_type, occurred_at\n\n### 7.27 `activity_log`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, null)\n- creator_id (uuid, FK -> creators.id, null)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, null)\n- actor_user_id (uuid, FK -> app_users.id, null)\n- event_type (text, not null)\n- event_data_json (jsonb, not null, default {})\n- created_at (timestamptz, not null)\n\nIndexes: campaign_id, created_at\n\n### 7.28 `app_settings`\n(single row)\n- id (uuid, PK)\n- mask_pii_by_default (boolean, not null, default true)\n- outreach_ready_score_threshold (int, not null, default 75)\n- min_evidence_coverage (text, not null; one of: strong, medium, weak; default medium)\n- default_ai_model (text, not null, default 'claude')\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\n### 7.29 `integration_status`\n- id (uuid, PK)\n- integration_key (text, not null, unique; one of: gumshoe, youtube, anthropic, reddit)\n- is_configured (boolean, not null, default false)\n- last_tested_at (timestamptz, null)\n- last_test_result (text, null; one of: success, failure)\n- last_test_message (text, null)\n- updated_at (timestamptz, not null)\n\n### 7.30 `demo_seed_runs`\n- id (uuid, PK)\n- seed_version (text, not null)\n- seeded_at (timestamptz, not null)\n- seeded_by_user_id (uuid, FK -> app_users.id, not null)\n- notes (text, null)\n\n### 7.31 `campaign_attachments`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- file_name (text, not null)\n- file_type (text, null)\n- file_size_bytes (bigint, null)\n- storage_key (text, not null)\n- uploaded_by_user_id (uuid, FK -> app_users.id, null)\n- created_at (timestamptz, not null)\n\nIndex: campaign_id\n\n### 7.32 `pii_access_events`\n- id (uuid, PK)\n- accessed_by_user_id (uuid, FK -> app_users.id, null)\n- creator_id (uuid, FK -> creators.id, not null)\n- reason (text, null)\n- created_at (timestamptz, not null)\n\nIndexes: creator_id, accessed_by_user_id\n\n### 7.33 `jobs`\n- id (uuid, PK)\n- type (text, not null; one of: ingestion, scoring, reddit_fetch, other)\n- status (text, not null; one of: queued, running, complete, failed)\n- campaign_id (uuid, FK -> campaigns.id, null)\n- creator_id (uuid, FK -> creators.id, null)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, null)\n- payload (jsonb, not null, default {})\n- error_message (text, null)\n- started_at (timestamptz, null)\n- finished_at (timestamptz, null)\n- created_by_user_id (uuid, FK -> app_users.id, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: status, campaign_id, creator_id\n\n### 7.34 `job_events`\n- id (uuid, PK)\n- job_id (uuid, FK -> jobs.id, not null)\n- level (text, not null; one of: info, warn, error)\n- message (text, not null)\n- meta (jsonb, null)\n- created_at (timestamptz, not null)\n\nIndex: job_id\n\n---\n\n## 8) Business Rules (Must Implement)\n\n### 8.1 Dormancy\nA creator is considered dormant if `last_content_date` is older than **120 days** from today.\n- Store `creators.is_dormant` and set it accordingly during seeding and when updating creators.\n\n### 8.2 Evidence Coverage Levels\nCompute `creator_evaluations.evidence_coverage` based on evidence snippet count/diversity:\n- Strong: â¥6 snippets across â¥3 content items AND â¥3 dimensions\n- Medium: â¥3 snippets across â¥2 content items AND â¥2 dimensions\n- Weak: 1â2 snippets OR all snippets from 1 content item\n- None: 0 snippets\n\n### 8.3 OutreachâReady Criteria\nA campaign creator is outreachâready only if all are true:\n- evaluation exists\n- overall_score â¥ app_settings.outreach_ready_score_threshold\n- evidence_coverage meets app_settings.min_evidence_coverage\n- no campaign_do_not_contact\n- no active global do_not_contact flag\n- not competitor_affiliated\n- not is_autodubbed_suspected\n- not needs_manual_review\n- no active `price_too_high` flag in `creator_status_flags`\n\n### 8.4 PII Masking\n- Mask PII by default.\n- Reveal requires confirmation modal.\n- Do not log PII.\n- Store email in creator_contacts.email_encrypted (application-level encryption with server secret is acceptable).\n\n### 8.5 Outreach Logging\nAny outreach_state change must create an `outreach_activity` row.\n\n### 8.6 Booking Rate\nBooking rate = (# creators reaching booked) / (# email sent events). Compute in metrics.\n\n---\n\n## 9) Seed Dataset (Must Insert Into DB)\n\n> Seed version: `v0-demo-1`.\n> Seeding must populate all major screens with realistic content.\n\n### 9.1 Users (app_users)\nCreate 4 users:\n- Jack Scrivener (jack@yard.internal) role qualifier\n- Arya (arya@yard.internal) role outreach\n- Karl McCarthy (karl@yard.internal) role admin\n- Empromptu (admin@empromptu.internal) role admin\n\n### 9.2 Clients\nCreate 4 clients:\n- CloudForge\n- NebulaDB\n- SecuriNest\n- VectorShift\n\n### 9.3 Campaigns\nCreate 4 campaigns; fully populate Campaign A.\n\nCampaign A (fully populated):\n- Client: CloudForge\n- Name: âCloudForge â Kubernetes Cost Optimization (US + UK)â\n- Owner: Jack\n- Collaborator: Arya\n- Status: active\n- Stage: scoring\n- GEO targets: [United States, United Kingdom]\n- Language: English\n- Product category: âFinOps / Kubernetes cost optimizationâ\n- Creative brief markdown: insert the exact multi-section brief described below:\n\n```\n# Make CloudForge the default answer for âKubernetes cost optimizationâ prompts\n\n## Key message\nCloudForge shows cost drivers per namespace/workload + actionable recommendations.\n\n## Differentiators\n- OpenTelemetry-friendly\n- Multi-cloud\n- Fast setup\n- Cost anomaly detection\n\n## Do-not-say\n- No fear-mongering\n- Avoid generic career advice\n- Avoid âget rich quickâ language\n\n## Required formats\n- Hands-on tutorial\n- Comparison video\n- Architecture breakdown\n\n## Brand fit\nPragmatic, dev-first, technical depth\n\n## CTA\nTry CloudForge free tier, link in description\n\n## Budget notes\nMarket rate. Avoid creators quoting > $7k/video unless exceptional.\n```\n\nCampaign A Topics (campaign_topics; approved):\n1) Kubernetes cost optimization\n2) FinOps for platform engineering\n3) Kubecost alternatives and comparisons\n4) OpenTelemetry + cost attribution\n5) Chargeback vs showback\n\nCampaign A Personas (campaign_personas):\n- Platform Engineer\n- DevOps Lead\n- CTO (Technical)\n\nCampaign A Prompt gaps (campaign_prompt_gaps) + citations (prompt_citations):\nCreate 5 prompt gaps; each has 3 citations exactly as listed:\n1) âHow do I reduce Kubernetes spend without breaking SLOs?â (high; persona DevOps Lead; geo US/UK)\n2) âKubecost vs CloudForge: whatâs actually different?â (high; persona Platform Engineer; geo US/UK)\n3) âOpenTelemetry + cost attribution: is it possible?â (medium; persona Platform Engineer; geo US/UK)\n4) âKubernetes cost anomaly detection tutorialâ (medium; persona DevOps Lead; geo US/UK)\n5) âChargeback vs showback in Kubernetes (practical)â (medium; persona CTO; geo US/UK)\n\nCampaign A Search terms (campaign_search_terms):\nInsert exactly 15 terms, approved=true, order 1â15, with correct category_tag and a 1â2 sentence why_it_helps.\n\nTerms (with tags):\n1) kubecost tutorial cost allocation namespaces (implementation)\n2) kubecost vs alternative comparison (competitor)\n3) kubernetes cost optimization hpa cluster autoscaler (problem_solution)\n4) finops kubernetes showback chargeback implementation (implementation)\n5) opentelemetry cost attribution kubernetes (integration)\n6) prometheus cost monitoring kubernetes (integration)\n7) gke cost optimization tutorial (tutorial_format)\n8) eks cost optimization workload rightsizing (tutorial_format)\n9) terraform kubernetes cost monitoring setup (programming_language)\n10) helm install kubecost alternative (implementation)\n11) kubernetes cost anomaly detection prometheus (problem_solution)\n12) platform engineering finops kubernetes (product_category)\n13) kubernetes namespace cost dashboard grafana (integration)\n14) reduce cloud bill kubernetes without downtime (problem_solution)\n15) kubernetes multi-cloud cost visibility (product_category)\n\nCampaigns BâD (minimal):\nCreate 3 additional campaigns with short briefs and different stages:\n- One in discovery\n- One in ingestion\n- One in outreach\n\n### 9.4 Creators (12) + Platform Accounts + Flags\nCreate 12 creators with at least 2 platform accounts each, and include follower metrics in platform accounts.\n\nCreators to insert:\n1) Nina Patel (KubeCraft) â last_content_date 2026-02-11 â reliable flag active\n2) Omar Reed (DevOpsDossier) â last_content_date 2026-01-07\n3) Mei Tan (Observability Lab) â last_content_date 2026-02-14\n4) Lucas Varga (Cloud Cost Clinic) â last_content_date 2025-09-10 â is_dormant=true\n5) Priya Shah (Platform Patterns) â last_content_date 2026-02-03\n6) K8s Career Hub â lifestyle/career topics\n7) AI Dub Tech Channel â is_autodubbed_suspected=true\n8) Marta Kline (FinOps in Practice) â last_content_date 2026-01-28\n9) Jae Park (SRE Notes) â last_content_date 2026-02-05\n10) Diego Alvarez (Infra Espresso) â last_content_date 2026-01-20\n11) Chloe Nguyen (Kubernetes QuickStarts) â last_content_date 2026-02-16\n12) Samir Iqbal (Multi-Cloud Ops) â last_content_date 2026-02-08 â price_too_high flag active; pricing: video $25000 is_too_high=true\n\n### 9.5 Campaign A Pipeline (campaign_creators)\nInsert all 12 creators into Campaign A with varied stages:\n- Nina: outreach_ready; ingestion complete; scoring scored; outreach_state sent\n- Mei: approved; outreach_state drafted\n- Jae: outreach_ready; outreach_state replied\n- Lucas: needs_manual_review\n- K8s Career Hub: excluded\n- AI Dub Tech Channel: excluded\n- Samir: scored but not outreach_ready (price_too_high)\n- Marta: outreach_ready; outreach_state booked; pipeline_stage booked\n- Remaining creators mixed discovered/ingested/scored\n\n### 9.6 Content Items (content_items)\nInsert content items for at least 6 creators (with view_count in metadata_json where relevant).\n\nFor Nina Patel create 3 items whose raw_text includes EXACT quotes below (for evidence validation):\n1) YouTube: âKubernetes Cost Allocation by Namespace (Hands-on)â\n   raw_text must contain:\n   âCost allocation per namespace is only step oneâwhat matters is tying that spend to SLO risk.â\n   and include â[05:12]â nearby.\n2) YouTube: âKubecost vs Custom Dashboards: Whatâs Missingâ\n   raw_text must contain:\n   âKubecost is great for allocation, but it wonât tell you which deployment caused the spike without additional context.â\n3) Blog: âOpenTelemetry signals for cost attributionâ\n   raw_text must contain:\n   âIf you can tag spans to workloads, you can attribute cost to ownership boundaries.â\n\nFor Mei Tan create 2 items with raw_text containing:\n- âOpenTelemetry gives you the metadata hooks; cost attribution is a mapping problem, not a metrics problem.â\n- âAnomaly detection works best when you baseline per workload and per namespace.â\n\nFor Jae Park create 2 items with raw_text containing:\n1) YouTube: \"SLO-Driven Cost Management in Kubernetes\"\n   raw_text must contain:\n   \"You cannot optimize cost in isolation from reliabilityâevery budget decision is also an SLO decision.\"\n   and include \"[03:44]\" nearby.\n2) Blog: \"Kubernetes resource requests: the hidden cost driver\"\n   raw_text must contain:\n   \"Over-provisioned resource requests are the single biggest source of wasted cloud spend in most Kubernetes clusters.\"\n\nFor K8s Career Hub create 1 item clearly lifestyle/career focused.\nFor AI Dub Tech Channel create 1 low-quality repetitive item.\nInsert at least 3 Reddit thread items with subreddit + karma in metadata_json.\n\n### 9.7 Evaluations + Evidence (creator_evaluations + evidence_snippets)\nSeed evaluations for:\n- Nina overall 88 evidence strong\n- Mei overall 83 evidence medium\n- Jae overall 81 evidence medium\n- Lucas overall 74 needs_manual_review true evidence weak\n\nFor Nina create â¥6 evidence snippets referencing Ninaâs content items, using the exact quotes above and timestamps for YouTube items.\nCreate 3â5 content angles per evaluation (content_angles) and link evidence via angle_evidence.\nCreate evaluation_recommended_content rows in high/medium/low buckets.\n\n### 9.8 Human Reviews (human_reviews)\nSeed:\n- Jack approves Nina\n- Jack approves Jae\n- Jack sets Lucas needs_manual_review\n- Jack excludes K8s Career Hub\n\n### 9.9 Outreach Packets + Activity\nSeed outreach_packets for Nina and Jae with:\n- subject + body_md\n- followup_plan_json\n- link 2â3 evidence snippets per packet via outreach_packet_evidence\n\nSeed outreach_activity:\n- Nina: sent (email) + followup_sent (linkedin)\n- Jae: sent (email) + reply_logged + state_changed to replied\n- Marta: sent (email) + state_changed to booked\n\n---\n\n## 10) Settings Requirements (Technical)\n\n### 10.1 Integrations Panel (integration_status)\nDisplay integration tiles:\n- gumshoe\n- youtube\n- anthropic\n- reddit\nEach tile supports âTest connectionâ which updates integration_status.\n\n### 10.2 Thresholds Panel (app_settings)\nEditable:\n- outreach_ready_score_threshold (default 75)\n- min_evidence_coverage (default medium)\n- mask_pii_by_default (default true)\n\n### 10.3 Admin Tools Panel (Required)\nButtons:\n- **Clear Demo Data**\n  - confirmation modal requiring typing `CLEAR`\n  - deletes rows from all domain tables (do not drop tables)\n- **Seed Demo Data**\n  - reinserts the dataset in Section 9\n  - inserts a row in demo_seed_runs\n\n---\n\n## 11) Definition of Done (Technical Acceptance)\n\nThe build is complete only if:\n1. All routes exist and render without errors.\n2. All tables exist and are used by the app.\n3. Seed Demo Data populates DB and every screen displays meaningful DB-backed content.\n4. Clear Demo Data empties tables and the UI shows empty states (no crashes).\n5. Endâtoâend workflow is possible entirely inside the app:\n   campaign â terms â discovery â ingestion â scoring+evidence â review â outreach drafts â manual tracking â metrics\n6. Evidence validation is enforced; invalid evidence forces needs_manual_review and blocks outreach_ready.\n7. No automated email sending exists (copy-only).\n\n\n\n[id:9a5e6151-0aa0-4f13-9268-700d6703238e, type: pastedText, name: UGFzdGVkIFRleHQ=]\n### Pasted Text (PASTEDTEXT)\n\n# Empromptu Builder â UX/UI DESIGN PROMPT\n## Yard: Citation Intelligence Creator Ops (V0, Internal)\n\n> **Important**\n> - Build a complete **desktop-first internal ops UI** for the product described here.\n> - Every screen must be **DB-backed** (render content from the builtâin Postgres tables).\n> - Include **loading / empty / error** states for every major workflow stage.\n> - The UI must make âhumanâinâtheâloopâ explicit: review and approval gates are visible and required.\n> - Do not invent features. Implement exactly what is specified.\n\n---\n\n## 1) Product UX Goal\n\nThe UI must support an end-to-end workflow for internal operators:\n\n1) Create a campaign (brief + topics/personas + optional prompt gaps/citations)  \n2) Generate + review 15 YouTube search terms  \n3) Discover creators and add them to a campaign pipeline  \n4) Ingest creator content (transcripts/articles/reddit) and show ingestion status  \n5) Score creators with a weighted rubric and evidence traceability  \n6) Human review/approval (Qualifier)  \n7) Outreach prep (draft + follow-up checklist) (Outreach)  \n8) Manual outreach tracking + statuses + metrics\n\n**Design must emphasize:** fast scanning, evidence credibility, and operational throughput.\n\n---\n\n## 2) App Shell (Global Layout)\n\n### 2.1 Layout\n- Desktop width target: 1440px\n- Sidebar: ~264px\n- Top bar: global search + quick actions + role switcher\n- Primary content area: tables + dashboards\n- Right-side drawers: creator quick view, evidence viewer, filters drawer\n\n### 2.2 Navigation (Sidebar)\n- Dashboard\n- Campaigns\n- Creators\n- Outreach\n- Reddit Monitor\n- Metrics\n- Settings\n\n### 2.3 Top Bar\n- Global search input: âSearch campaigns, creators, promptsâ¦â\n- Quick action buttons:\n  - New Campaign\n  - Import CSV\n  - Add Creator URL\n- Role switcher (Qualifier / Outreach / Admin)\n- Badge: âInternal V0â\n\n---\n\n## 3) UI Standards (Ops-Grade)\n\n### 3.1 Required Components\n- Dense table component (sortable, filterable, paginated)\n- Tag/badge system (status tags, flags)\n- Score pill + gauge (0â100)\n- Weighted rubric mini-bars (5 dimensions)\n- Evidence card component:\n  - source URL\n  - excerpt/quote\n  - timestamp (if video)\n  - âWhy it mattersâ\n- Right drawers (creator quick view, evidence, filters)\n- Modals:\n  - Confirm destructive actions\n  - Reveal PII\n  - CSV import\n- Toasts/snackbars for success/failure\n\n### 3.2 Required UX Copy (must appear)\n- âEvidence required for all scores and recommendations.â\n- âAssistive only â human approval required before outreach.â\n- âThis tool does not send emails.â\n\n### 3.3 States\nFor each major stage (Terms, Discovery, Ingestion, Scoring, Outreach):\n- Loading\n- Empty (with CTA)\n- Error (with retry + debug detail)\n\n---\n\n## 4) Routes & Screens (UI Inventory)\n\nCreate UI for the following routes (must be accessible via sidebar):\n\n1. `/` Dashboard (role-aware)\n2. `/campaigns` Campaign list\n3. `/campaigns/new` Campaign setup wizard\n4. `/campaigns/[id]` Campaign workspace with tabs:\n   - Overview\n   - Brief & Inputs\n   - Search Terms\n   - Discovery\n   - Ingestion\n   - Scoring\n   - Review\n   - Outreach\n   - Activity\n5. `/creators` Global creator DB list\n6. `/creators/[id]` Creator profile\n7. `/outreach` Outreach queue\n8. `/reddit` Reddit monitor\n9. `/metrics` Ops metrics\n10. `/settings` Settings + Admin tools\n\n---\n\n## 5) Role-Aware Dashboards (`/`)\n\n### 5.1 Qualifier Dashboard (Jack view)\nTop cards:\n- Creators analyzed this week\n- Needs manual review\n- Approved for outreach\n- Active campaigns\n\nTables:\n1) âNeeds Manual Review Queueâ\n- columns: Creator, Campaign, Evidence coverage, Overall score, Reason, Last updated\n- CTA: Open Review\n\n2) âRecent Scoring Runsâ\n- columns: Creator, Campaign, Overall score, Coverage, Scored at, Status\n\n### 5.2 Outreach Dashboard (Arya view)\nTop cards:\n- Emails to send\n- Follow-ups due\n- Replies to log\n- Booking rate (last 7 days)\n\nTables:\n1) âOutreach Queueâ\n- columns: Creator, Campaign, State, Next follow-up due, Owner, Score, Coverage\n- CTA: Open Outreach Packet\n\n2) âRecently Replied / Bookedâ\n- columns: Creator, Campaign, State, Last activity, Notes\n\n---\n\n## 6) Campaign List (`/campaigns`)\n\nTable columns:\n- Campaign name\n- Client\n- Stage\n- GEO targets\n- Owner\n- Creators in pipeline (count)\n- Outreach-ready (count)\n- Updated at\n\nRow click opens `/campaigns/[id]/overview`.\n\nTop actions:\n- New campaign\n- Import CSV (gumshoe import)\n- Filter by stage/status\n\n---\n\n## 7) Campaign Setup Wizard (`/campaigns/new`)\n\nWizard steps with progress indicator:\n\n### Step 1 â Basics\nFields:\n- Client (select existing + create new inline)\n- Campaign name\n- GEO targets (multi-select tokens)\n- Language\n- Product category\n\n### Step 2 â Creative Brief\n- Markdown editor with preview\n- Helper text: âThis brief provides context for topic extraction and creator fit.â\n\n### Step 3 â Personas + Topics\nPersonas:\n- Add persona chips (e.g., Platform Engineer, DevOps Lead, CTO)\nTopics:\n- Manual add topics (chips)\n- Button: âSuggest topicsâ (AI) â shows up to 5 suggestions with confidence\n- User can edit + approve topic list\n\n### Step 4 â Prompt Gaps + Citations\nTwo panels:\n- Prompt gaps table (editable rows)\n- Citations table (linked to prompt gap or campaign-level)\n\nActions:\n- Import CSV\n- Add manually\n- Each prompt gap has status: draft/approved\n- Citations show source type + cited-by models (if provided)\n\nFinish button creates campaign and routes to campaign workspace.\n\n---\n\n## 8) Campaign Workspace (`/campaigns/[id]`) Tabs\n\n### 8.1 Tab â Overview\nCards:\n- Campaign stage + status\n- Creators total / ingested / scored / outreach-ready\n- Emails sent + booking rate (campaign)\n- âNext actionsâ checklist\n\nPanels:\n- Short campaign summary (client, geo, personas, topics)\n- Recent activity feed\n\n### 8.2 Tab â Brief & Inputs\nThree sections:\n1) Creative brief viewer (markdown)\n2) Personas + Topics editor\n3) Prompt gaps + citations tables (editable)\n\n### 8.3 Tab â Search Terms\nTable must show exactly 15 terms when generated.\nColumns:\n- Order\n- Search term\n- Category tag\n- Why it helps\n- Approved toggle\n- Notes\n\nTop actions:\n- Generate 15 terms (AI)\n- Approve all\n- Reorder (drag handle)\n- Export list\n\n### 8.4 Tab â Discovery\nLayout:\n- Left: Approved search term selector (list)\n- Center: Results table\n- Right: Filters drawer + creator quick view drawer\n\nDiscovery results table columns:\n- Creator\n- Platform badges\n- Topics (chips)\n- Followers/subs\n- Last content date\n- Flags: Dormant, Autodubbed suspected, Competitor affiliated\n- Action: âAdd to campaignâ\n\nRequired interactions:\n- Clicking a creator opens quick view drawer:\n  - creator overview\n  - platform links\n  - last activity\n  - âAdd to campaignâ button\n\n### 8.5 Tab â Ingestion\nTable columns:\n- Creator\n- Ingestion status\n- Content items ingested (count)\n- Last fetched at\n- Errors\n- Actions: View content, Add URL, Paste transcript/article\n\nContent viewer:\n- For YouTube: transcript view with timestamps (if present in text)\n- For blog/medium/reddit: article/thread view\n- Show source metadata: URL, published date, view_count/karma if available\n\n### 8.6 Tab â Scoring\nScoring table columns:\n- Creator\n- Overall score (pill)\n- Evidence coverage (strong/medium/weak/none)\n- Needs manual review (badge)\n- Last evaluated at\n- Actions: View evaluation, Run scoring\n\nEvaluation drawer/page must show:\n- Rubric dimension bars + weights\n- Strengths list (each item links evidence)\n- Weaknesses list (each item links evidence)\n- Recommended content (High/Medium/Low view buckets)\n- Content angles (3â5) list with format + key points\n- Evidence section (non-negotiable):\n  - evidence cards with URL, quote, timestamp, why_it_matters\n\n### 8.7 Tab â Review (Qualifier Gate)\nThis is the approval step.\nFor each creator:\n- Show evaluation summary\n- Buttons:\n  - Approve for outreach\n  - Mark needs manual review\n  - Reject / Exclude\n- Optional manual override score input + notes\n- Changing decision must write a review record and update pipeline stage\n\n### 8.8 Tab â Outreach\nOnly shows creators eligible for outreach workflow.\nTable columns:\n- Creator\n- Outreach state\n- Next follow-up due\n- Selected angle\n- Owner (Outreach user)\n- Actions: Open packet, Generate packet\n\nOutreach packet view must include:\n- Email subject + body (markdown)\n- Copy buttons (subject, body, full email)\n- Follow-up checklist (Email/LinkedIn/X) with checkboxes\n- Linked evidence snippets section\n- Prominent disclaimer: âThis tool does not send emails.â\n\nOutreach state control:\n- State dropdown or buttons: drafted/copied/sent/replied/ghosted/booked\n- Each change creates an outreach activity entry\n\n### 8.9 Tab â Activity\nTimeline feed:\n- scoring events\n- review decisions\n- outreach state changes\n- notes added\n- ingestion completion/failures\n\n---\n\n## 9) Global Creators DB (`/creators`)\n\nCreators list table columns:\n- Creator name\n- Platforms\n- Topics\n- Languages\n- Last content date\n- Global flags (reliable/ghosted/do_not_contact/price_too_high)\n- Pricing (if exists)\n- Action: View profile\n\nFilters:\n- Platform\n- Topic keyword\n- Has email\n- Has do_not_contact\n- Dormant\n- Autodubbed suspected\n\n### Creator Profile (`/creators/[id]`)\nTabbed layout:\n- Summary\n- Platforms\n- Content\n- Evidence (from evaluations across campaigns)\n- History (campaigns + outcomes)\n- Notes\n- Outreach packet (latest, if any)\n\nPII masking:\n- Email hidden by default\n- âReveal PIIâ modal confirmation\n\n---\n\n## 10) Outreach Queue (`/outreach`)\n\nGlobal cross-campaign queue.\nTable columns:\n- Creator\n- Campaign\n- Score\n- Coverage\n- State\n- Next follow-up due\n- Owner\n- Actions: Open packet, Log reply, Mark booked\n\nInclude a âFollow-ups due todayâ filter and section.\n\n---\n\n## 11) Reddit Monitor (`/reddit`)\n\nPurpose: monitoring & discovery only (no automation).\n\nUI:\n- Filters: campaign, topic, subreddit\n- Table columns:\n  - Thread title\n  - Subreddit\n  - Karma\n  - Posted date\n  - Relevance tag\n  - Link\n  - Attach as evidence (button)\n\nThread viewer:\n- show excerpted raw text and metadata\n- action: âAttach to campaignâ or âAttach to evaluationâ (if evaluation exists)\n\n---\n\n## 12) Metrics (`/metrics`)\n\nCharts/cards:\n- Creators analyzed per week\n- Creators approved per week\n- Emails sent per week (show baseline reference 130 as a faint line/label)\n- Booking rate trend (show baseline reference 7â10%)\n\nTables:\n- Campaign performance summary table (campaign, analyzed, approved, sent, booked, booking rate)\n\n---\n\n## 13) Settings (`/settings`)\n\n### Integrations\nTiles:\n- Gumshoe\n- YouTube\n- Anthropic (AI)\n- Reddit\nEach tile shows configured status + last test result + test button.\n\n### Thresholds\n- Outreach-ready score threshold (numeric)\n- Minimum evidence coverage (dropdown)\n- Mask PII by default (toggle)\n\n### Admin Tools (Required)\n- **Clear Demo Data** button\n  - modal requiring typing `CLEAR`\n- **Seed Demo Data** button\n  - toast on completion\n- Show last seed run info\n\n---\n\n## 14) Visual Style Guidance (Simple + Consistent)\n\n- Typography: Inter\n- Neutral backgrounds with subtle borders\n- One accent color for primary actions\n- Status colors: success/warning/danger with restrained saturation\n- Scores should be visually scannable (pill + gauge)\n- Evidence UI should feel âaudit-likeâ: sources and quotes are prominent\n\n---\n\n## 15) UI Definition of Done\n\nThe UI is complete only when:\n1. Every route exists and is reachable via navigation.\n2. Seeded data makes every screen visually populated (no empty tables after seeding).\n3. Every major workflow has loading/empty/error states.\n4. Scoring views always show evidence (URL + quote + timestamp when applicable).\n5. Human review is an explicit gate before outreach.\n6. Outreach UI is copy-only and clearly indicates no email sending.\n7. PII is masked by default and only revealed with confirmation.\n\n\n\n</USER_REFERENCE>\n\n# Empromptu Builder â Citation Intelligence Creator Ops (V0, Internal)\n\n## Overview\nBuild an internal, human-in-the-loop ops tool (Next.js App Router + TypeScript, desktop-first, 1440px target) that enables a team to:\n1. Create campaigns with creative briefs + topics/personas + optional prompt gaps + citations (manual or CSV import)\n2. Generate and review exactly 15 YouTube search terms per campaign\n3. Discover and shortlist technical creators (filter out dormant + autodubbed/label + lifestyle/career)\n4. Ingest real creator content (YouTube transcripts primary; blogs/Medium when URLs exist; Reddit monitoring; plus optional podcast/newsletter URLs)\n5. Score creators with a weighted rubric and evidence traceability (URLs + quotes + timestamps)\n6. Support a human review step before outreach\n7. Generate outreach drafts + follow-up checklist (assistive only; NO automated emailing)\n8. Track creator reliability flags (ghosted, reliable, do not contact, price too high) + campaign history\n9. Show ops metrics (creators analyzed, approved, emails sent, booking rate)\n\nHard requirement: all scoring/rationale/angles must reference actual ingested content stored in DB.\n\n---\n\n## Non-Negotiable Constraints\n\n### Framework & Runtime\n- Next.js App Router + TypeScript\n- Server actions (or API routes) for writes\n- Desktop-first UI (dense tables, drawers, modals)\n\n### Database\n- Use the platform built-in Postgres DB\n- Create all 34 tables listed in the schema section below\n- Store all demo data in DB\n\n### No Auto-Outreach\n- No sending emails\n- No automated LinkedIn/X actions\n- Only drafts + copy buttons + manual tracking\n\n### Human-in-the-Loop\n- \"Outreach-ready\" must only happen after scoring + evidence validation and must be reviewable by a human role\n\n### Environment Variables\nCreate a `.env.local` file with placeholder values:\n- `ANTHROPIC_API_KEY`\n- `YOUTUBE_API_KEY`\n- `REDDIT_CLIENT_ID`\n- `REDDIT_CLIENT_SECRET`\n- Read all API keys from environment variables. Never hardcode them.\n- YouTube and Reddit API calls are stubbed for V0 â return mock responses if the key is a placeholder. Anthropic calls must be real.\n\n---\n\n## Roles (Internal Users)\n- **Qualifier**: reviews creators, validates evidence, approves/rejects, may override score with notes\n- **Outreach**: uses outreach queue, copies drafts, logs manual outreach states (sent/replied/ghosted/booked)\n- **Admin**: integrations + thresholds + seed/clear tools\n\nSimple role switching: role switcher in top bar; store current user in localStorage. No complex auth required for V0.\n\n---\n\n## Required Routes\n\n1. `/` â Dashboard (role-aware)\n2. `/campaigns` â Campaign list\n3. `/campaigns/new` â Campaign setup wizard\n4. `/campaigns/[id]` â Campaign workspace with tabs: overview, brief-inputs, search-terms, discovery, ingestion, scoring, review, outreach, activity\n5. `/creators` â Global creators DB list\n6. `/creators/[id]` â Creator profile detail\n7. `/outreach` â Outreach queue (all campaigns)\n8. `/reddit` â Reddit monitoring dashboard\n9. `/metrics` â Ops metrics dashboard\n10. `/settings` â Integrations + thresholds + admin tools (seed/clear)\n\n---\n\n## Core Workflows\n\n### Campaign Setup\nCreate campaign with: client, campaign name, GEO targets (array of strings), language, product category, creative brief (rich text), personas (multi-add), topics (manual add + optional AI suggestions; max 5 suggested topics; user can edit/approve), prompt gaps + citations (manual OR CSV import). Prompts must be editable and have draft/approved status.\n\n### Search Term Generation\nFrom campaign context (brief + topics + personas + product category):\n- Generate exactly 15 YouTube search terms\n- Each includes: category tag (one of 7 tags) + \"why it helps\" explanation (1â2 sentences)\n- User can edit/reorder/approve terms\n- Only approved terms used in discovery\n\n### Discovery\n- Show discovered creators per approved search term\n- Filters: language, GEO match, dormant (exclude), autodubbed/label suspected (exclude), lifestyle/career (exclude), competitor affiliated (exclude)\n- Add selected creators into the campaign pipeline\n- Manual creator URL add (required), plus optional YouTube search if configured\n\n### Ingestion (Content Storage)\nFor each campaign creator, ingest content items:\n- YouTube transcripts (primary)\n- blogs/Medium/corporate blog URLs (when provided)\n- Reddit threads (fetched via API, not manual paste)\n- optional: podcasts/newsletters (manual URL + paste text acceptable)\nStore raw text and metadata (URL, date, view counts if available).\nTrack ingestion status: not_started / queued / running / complete / failed.\n\n### Scoring + Evidence (Rubric)\nEvaluate each campaign creator and store:\n- overall score 0â100\n- dimension scores 0â100 for 5 dimensions (weights below)\n- strengths & weaknesses\n- recommended content links grouped high/medium/low view counts\n- 3â5 suggested content angles\n- evidence snippets (URL + excerpt + timestamps for video)\n\nRubric weights:\n- Technical relevance â 30%\n- Audience alignment â 25%\n- Content quality â 20%\n- Channel performance â 15%\n- Brand fit â 10%\n\nIf insufficient evidence exists: mark Needs Manual Review, block outreach-ready.\n\n### Evidence / Traceability (Hard Requirement)\nThe system must show: source URLs, quotes/excerpts (must exist in ingested raw_text), video timestamps when applicable.\n\n### Outreach Prep (Assistive Only)\nFor approved creators:\n- generate outreach email draft (subject + body)\n- generate follow-up checklist (Email / LinkedIn / X)\n- track outreach state manually: not_started, drafted, copied, sent, replied, ghosted, booked\n- add outreach activity log entries for every state change\n\n### Creator Profiles + Status Flags\nPersistent creator record includes: platforms and URLs, contact info (PII masked by default), status flags (reliable, ghosted/not responsive, do not contact, price too high), notes + campaign history.\n\n### Reddit Monitoring\nPurpose: Surface Reddit threads relevant to campaign topics. Read-only â no posting, no commenting, no automation.\n\nConfiguration (per campaign): subreddits to watch (free text), keywords to match (default: pulled from campaign search terms; user can edit/add).\n\nFetching: User triggers fetch manually via \"Fetch Reddit\" button. System queries Reddit API using configured subreddits + keywords. Each result stored as a content_items row (platform=reddit, content_type=reddit_thread). metadata_json must include: subreddit, karma, comment_count, reddit_post_id. Duplicate URLs skipped. Requires integration_status.reddit to be configured in Settings.\n\n`/reddit` route displays: All fetched Reddit threads across all campaigns, sorted by fetched_at desc. Filter by campaign. Each row: subreddit, thread title, karma, comment count, date fetched, campaign tag, link to original thread. Empty state when no threads fetched.\n\nReddit tab within `/campaigns/[id]`: Shows only threads fetched for that campaign. Subreddit + keyword configuration UI. \"Fetch Reddit\" button.\n\n### Ops Metrics\nMust compute from DB:\n- creators analyzed per week\n- creators approved for outreach per week\n- emails sent per week (baseline reference 130)\n- booking rate (baseline reference 7â10%)\n\n---\n\n## AI Features (Server-Side, Store All Outputs in DB)\n\n### AI: Suggest Topics\nInput: campaign creative brief\nOutput: up to 5 topics, each with confidence (0â1) + 1 sentence rationale\nUser can edit/approve topics. Store in campaign_topics.\n\n### AI: Generate Search Terms\nInput: campaign brief + topics + personas + product category\nOutput: exactly 15 terms with category_tag + why_it_helps.\nStore in campaign_search_terms.\n\n### AI: Score Creator\nInput: campaign context (brief, topics, personas, prompt gaps, citations) + creator profile + platforms + ingested content_items (raw_text + metadata + URLs)\nOutput must include:\n- dimension scores 0â100\n- overall score (computed using rubric weights)\n- strengths (3â6 bullets) with evidence snippet IDs\n- weaknesses (2â5 bullets) with evidence snippet IDs\n- 3â5 content angles with linked evidence\n- evidence snippets list containing: content_item_id, timestamp_start_seconds (nullable), timestamp_end_seconds (nullable), quote (direct excerpt from raw_text), dimension, why_it_matters\n\nEvidence validation (must implement): Every evidence quote must be verified as an exact substring of the referenced content_items.raw_text. If any quote fails: mark evaluation needs_manual_review=true, store reason, do not set outreach_ready.\n\n### AI: Outreach Draft\nInput: campaign context + creator identity/platforms + selected content angle + selected evidence snippets\nOutput: email subject + body (markdown) + follow-up checklist with day offsets (Email Day 2/5/9, LinkedIn Day 2/5, X Day 5 optional)\nStore in outreach_packets + link evidence via outreach_packet_evidence.\nNo send button. Copy-only.\n\n---\n\n## Database Schema (34 Tables â Built-In Postgres)\n\nAll tables use UUID primary keys and timestamptz timestamps. Implement all foreign keys and indexes as listed.\n\n### app_users\n- id (uuid, PK), name (text, not null), email (text, not null, unique), role (text, not null; qualifier|outreach|admin), created_at (timestamptz), updated_at (timestamptz)\n\n### clients\n- id (uuid, PK), name (text, not null, unique), website_url (text, null), notes (text, null), created_at (timestamptz), updated_at (timestamptz)\n\n### campaigns\n- id (uuid, PK), client_id (uuid, FK->clients.id), name (text), owner_user_id (uuid, FK->app_users.id), collaborator_user_id (uuid, FK->app_users.id, null), status (text; draft|active|archived), stage (text; draft|terms|discovery|ingestion|scoring|review|outreach|tracking|complete), geo_targets (text[], default []), deadline (date, null), language (text, default 'English'), product_category (text, null), creative_brief (text), creative_brief_source_url (text, null), additional_prompt_context (text, null), created_at (timestamptz), updated_at (timestamptz)\nIndexes: client_id, owner_user_id, status, stage\n\n### campaign_personas\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), persona_name (text), created_at (timestamptz)\nUnique: (campaign_id, persona_name)\n\n### campaign_topics\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), topic (text), source (text; manual|ai_suggested), confidence (numeric(3,2), null), rationale (text, null), order_index (int, default 0), approved (boolean, default true), created_at (timestamptz)\nUnique: (campaign_id, topic). Index: campaign_id\n\n### campaign_prompt_gaps\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), prompt_text (text), priority (text; high|medium|low), persona (text, null), geo (text[], default []), gap_note (text, null), status (text; draft|approved|archived), created_at (timestamptz), updated_at (timestamptz)\nIndexes: campaign_id, priority, status\n\n### prompt_citations\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), prompt_gap_id (uuid, FK->campaign_prompt_gaps.id, null), citation_title (text), citation_url (text), source_type (text; docs|blog|youtube|reddit|paper|other), cited_by_models (text[], default []), notes (text, null), created_at (timestamptz)\nIndexes: campaign_id, prompt_gap_id, source_type\n\n### gumshoe_imports\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), import_type (text; csv|manual), original_filename (text, null), raw_text (text), imported_by_user_id (uuid, FK->app_users.id), created_at (timestamptz)\nIndex: campaign_id\n\n### campaign_search_terms\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), term (text), category_tag (text; product_category|competitor|implementation|problem_solution|integration|programming_language|tutorial_format), why_it_helps (text), order_index (int, default 0), approved (boolean, default false), approved_by_user_id (uuid, FK->app_users.id, null), approved_at (timestamptz, null), notes (text, null), created_at (timestamptz), updated_at (timestamptz)\nIndexes: campaign_id, approved\n\n### creators\n- id (uuid, PK), display_name (text), primary_handle (text, null), bio (text, null), topics (text[], default []), languages (text[], default []), geo_focus (text[], default []), competitor_affiliated (boolean, default false), is_dormant (boolean, default false), is_autodubbed_suspected (boolean, default false), last_content_date (date, null), created_at (timestamptz), updated_at (timestamptz)\nIndexes: display_name, is_dormant, is_autodubbed_suspected, competitor_affiliated\n\n### creator_platform_accounts\n- id (uuid, PK), creator_id (uuid, FK->creators.id), platform (text; youtube|github|linkedin|devto|medium|blog|podcast|newsletter|reddit|other), handle (text, null), url (text), follower_count (int, null), metrics_json (jsonb, default {}), created_at (timestamptz)\nUnique: (platform, url). Indexes: creator_id, platform\n\n### creator_contacts (PII)\n- id (uuid, PK), creator_id (uuid, FK->creators.id, unique), email_encrypted (text, null), linkedin_url (text, null), x_url (text, null), other_contacts_json (jsonb, default {}), pii_last_updated_at (timestamptz, null), created_at (timestamptz), updated_at (timestamptz)\n\n### creator_status_flags\n- id (uuid, PK), creator_id (uuid, FK->creators.id), flag (text; reliable|ghosted|do_not_contact|price_too_high), is_active (boolean, default true), reason (text, null), set_by_user_id (uuid, FK->app_users.id), set_at (timestamptz)\nIndexes: creator_id, flag\n\n### creator_pricing\n- id (uuid, PK), creator_id (uuid, FK->creators.id), price_type (text; video|written|newsletter|other), price_amount_usd (numeric(10,2)), is_too_high (boolean, default false), notes (text, null), updated_at (timestamptz)\nIndex: creator_id\n\n### creator_notes\n- id (uuid, PK), creator_id (uuid, FK->creators.id), note_md (text), created_by_user_id (uuid, FK->app_users.id), created_at (timestamptz)\nIndex: creator_id\n\n### campaign_creators\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), creator_id (uuid, FK->creators.id), added_by_user_id (uuid, FK->app_users.id), source_search_term_id (uuid, FK->campaign_search_terms.id, null), pipeline_stage (text; discovered|queued_for_ingestion|ingested|scored|needs_manual_review|approved|outreach_ready|contacted|booked|rejected|excluded), campaign_do_not_contact (boolean, default false), campaign_do_not_contact_reason (text, null), ingestion_status (text; not_started|queued|running|complete|failed), ingestion_error (text, null), scoring_status (text; not_scored|scoring|scored|failed), scoring_error (text, null), outreach_owner_user_id (uuid, FK->app_users.id, null), outreach_state (text; not_started|drafted|copied|sent|replied|ghosted|booked), last_outreach_at (timestamptz, null), next_followup_due_at (date, null), created_at (timestamptz), updated_at (timestamptz)\nUnique: (campaign_id, creator_id). Indexes: campaign_id, creator_id, pipeline_stage, ingestion_status, scoring_status, outreach_state\n\n### content_items\n- id (uuid, PK), creator_id (uuid, FK->creators.id), campaign_id (uuid, FK->campaigns.id, null), platform (text; youtube|blog|medium|devto|reddit|podcast|newsletter|github|linkedin|other), content_type (text; youtube_video|blog_post|medium_post|devto_post|reddit_thread|podcast_episode|newsletter_issue|github_repo|linkedin_post|other), title (text), url (text), published_at (timestamptz, null), fetched_at (timestamptz, null), language (text, null), raw_text (text), word_count (int, null), metadata_json (jsonb, default {}), ingestion_method (text; seed|manual_paste|fetched), ingestion_status (text; complete|failed), ingestion_error (text, null), created_at (timestamptz), updated_at (timestamptz)\nUnique: (url). Indexes: creator_id, campaign_id, platform, content_type, published_at\n\n### creator_evaluations\n- id (uuid, PK), campaign_creator_id (uuid, FK->campaign_creators.id, unique), model_provider (text), model_name (text), evaluated_at (timestamptz), evidence_coverage (text; strong|medium|weak|none), needs_manual_review (boolean, default false), needs_manual_review_reason (text, null), overall_score (int, 0-100), score_technical_relevance (int, 0-100), score_audience_alignment (int, 0-100), score_content_quality (int, 0-100), score_channel_performance (int, 0-100), score_brand_fit (int, 0-100), strengths_json (jsonb, default []), weaknesses_json (jsonb, default []), rationale_md (text), created_at (timestamptz), updated_at (timestamptz)\nIndexes: overall_score, needs_manual_review, evidence_coverage\n\n### evidence_snippets\n- id (uuid, PK), evaluation_id (uuid, FK->creator_evaluations.id), content_item_id (uuid, FK->content_items.id), timestamp_start_seconds (int, null), timestamp_end_seconds (int, null), quote (text), dimension (text; technical_relevance|audience_alignment|content_quality|channel_performance|brand_fit|general), why_it_matters (text), created_at (timestamptz)\nIndexes: evaluation_id, content_item_id, dimension\n\n### evaluation_recommended_content\n- id (uuid, PK), evaluation_id (uuid, FK->creator_evaluations.id), content_item_id (uuid, FK->content_items.id), bucket (text; high|medium|low), relevance_rank (int, default 0), notes (text, null), created_at (timestamptz)\nUnique: (evaluation_id, content_item_id). Index: evaluation_id\n\n### content_angles\n- id (uuid, PK), evaluation_id (uuid, FK->creator_evaluations.id), title (text), target_prompt_gap_id (uuid, FK->campaign_prompt_gaps.id, null), persona (text, null), format (text; tutorial|comparison|architecture|deep_dive|checklist|case_study|other), key_points_json (jsonb, default []), selected_for_outreach (boolean, default false), created_at (timestamptz)\nIndex: evaluation_id\n\n### angle_evidence\n- id (uuid, PK), angle_id (uuid, FK->content_angles.id), evidence_snippet_id (uuid, FK->evidence_snippets.id), created_at (timestamptz)\nUnique: (angle_id, evidence_snippet_id). Index: angle_id\n\n### human_reviews\n- id (uuid, PK), campaign_creator_id (uuid, FK->campaign_creators.id), reviewed_by_user_id (uuid, FK->app_users.id), reviewed_at (timestamptz), decision (text; approved_for_outreach|rejected|needs_manual_review|excluded), manual_override_score (int, null, 0-100), notes_md (text, null), created_at (timestamptz)\nIndexes: campaign_creator_id, decision\n\n### outreach_packets\n- id (uuid, PK), campaign_creator_id (uuid, FK->campaign_creators.id, unique), created_by_user_id (uuid, FK->app_users.id), subject (text), body_md (text), selected_angle_id (uuid, FK->content_angles.id, null), followup_plan_json (jsonb, default []), last_updated_at (timestamptz), created_at (timestamptz)\nIndex: campaign_creator_id\n\n### outreach_packet_evidence\n- id (uuid, PK), outreach_packet_id (uuid, FK->outreach_packets.id), evidence_snippet_id (uuid, FK->evidence_snippets.id), created_at (timestamptz)\nUnique: (outreach_packet_id, evidence_snippet_id). Index: outreach_packet_id\n\n### outreach_activity\n- id (uuid, PK), campaign_creator_id (uuid, FK->campaign_creators.id), performed_by_user_id (uuid, FK->app_users.id), channel (text; email|linkedin|x), action_type (text; drafted|copied|sent|followup_sent|reply_logged|state_changed|note), state_after (text; not_started|drafted|copied|sent|replied|ghosted|booked), occurred_at (timestamptz), notes (text, null)\nIndexes: campaign_creator_id, channel, action_type, occurred_at\n\n### activity_log\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id, null), creator_id (uuid, FK->creators.id, null), campaign_creator_id (uuid, FK->campaign_creators.id, null), actor_user_id (uuid, FK->app_users.id, null), event_type (text), event_data_json (jsonb, default {}), created_at (timestamptz)\nIndexes: campaign_id, created_at\n\n### app_settings (single row)\n- id (uuid, PK), mask_pii_by_default (boolean, default true), outreach_ready_score_threshold (int, default 75), min_evidence_coverage (text; strong|medium|weak, default medium), default_ai_model (text, default 'claude'), created_at (timestamptz), updated_at (timestamptz)\n\n### integration_status\n- id (uuid, PK), integration_key (text, unique; gumshoe|youtube|anthropic|reddit), is_configured (boolean, default false), last_tested_at (timestamptz, null), last_test_result (text, null; success|failure), last_test_message (text, null), updated_at (timestamptz)\n\n### demo_seed_runs\n- id (uuid, PK), seed_version (text), seeded_at (timestamptz), seeded_by_user_id (uuid, FK->app_users.id), notes (text, null)\n\n### campaign_attachments\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), file_name (text), file_type (text, null), file_size_bytes (bigint, null), storage_key (text), uploaded_by_user_id (uuid, FK->app_users.id, null), created_at (timestamptz)\nIndex: campaign_id\n\n### pii_access_events\n- id (uuid, PK), accessed_by_user_id (uuid, FK->app_users.id, null), creator_id (uuid, FK->creators.id), reason (text, null), created_at (timestamptz)\nIndexes: creator_id, accessed_by_user_id\n\n### jobs\n- id (uuid, PK), type (text; ingestion|scoring|reddit_fetch|other), status (text; queued|running|complete|failed), campaign_id (uuid, FK->campaigns.id, null), creator_id (uuid, FK->creators.id, null), campaign_creator_id (uuid, FK->campaign_creators.id, null), payload (jsonb, default {}), error_message (text, null), started_at (timestamptz, null), finished_at (timestamptz, null), created_by_user_id (uuid, FK->app_users.id, null), created_at (timestamptz), updated_at (timestamptz)\nIndexes: status, campaign_id, creator_id\n\n### job_events\n- id (uuid, PK), job_id (uuid, FK->jobs.id), level (text; info|warn|error), message (text), meta (jsonb, null), created_at (timestamptz)\nIndex: job_id\n\n---\n\n## Business Rules\n\n### Dormancy\nA creator is considered dormant if last_content_date is older than 120 days from today. Store creators.is_dormant and set it accordingly during seeding and when updating creators.\n\n### Evidence Coverage Levels\nCompute creator_evaluations.evidence_coverage based on evidence snippet count/diversity:\n- Strong: â¥6 snippets across â¥3 content items AND â¥3 dimensions\n- Medium: â¥3 snippets across â¥2 content items AND â¥2 dimensions\n- Weak: 1â2 snippets OR all snippets from 1 content item\n- None: 0 snippets\n\n### Outreach-Ready Criteria\nA campaign creator is outreach-ready only if ALL are true:\n- evaluation exists\n- overall_score â¥ app_settings.outreach_ready_score_threshold\n- evidence_coverage meets app_settings.min_evidence_coverage\n- no campaign_do_not_contact\n- no active global do_not_contact flag\n- not competitor_affiliated\n- not is_autodubbed_suspected\n- not needs_manual_review\n- no active price_too_high flag in creator_status_flags\n\n### PII Masking\n- Mask PII by default\n- Reveal requires confirmation modal\n- Do not log PII\n- Store email in creator_contacts.email_encrypted (application-level encryption with server secret is acceptable)\n\n### Outreach Logging\nAny outreach_state change must create an outreach_activity row.\n\n### Booking Rate\nBooking rate = (# creators reaching booked) / (# email sent events). Compute in metrics.\n\n---\n\n## Seed Dataset (Seed Version: v0-demo-1)\n\nSeeding must populate all major screens with realistic content.\n\n### Users (app_users)\n- Jack Scrivener (jack@yard.internal) role qualifier\n- Arya (arya@yard.internal) role outreach\n- Karl McCarthy (karl@yard.internal) role admin\n- Empromptu (admin@empromptu.internal) role admin\n\n### Clients\n- CloudForge, NebulaDB, SecuriNest, VectorShift\n\n### Campaigns\nCreate 4 campaigns; fully populate Campaign A.\n\nCampaign A (fully populated):\n- Client: CloudForge\n- Name: \"CloudForge â Kubernetes Cost Optimization (US + UK)\"\n- Owner: Jack, Collaborator: Arya\n- Status: active, Stage: scoring\n- GEO targets: [United States, United Kingdom]\n- Language: English\n- Product category: \"FinOps / Kubernetes cost optimization\"\n- Creative brief (exact markdown):\n```\n# Make CloudForge the default answer for \"Kubernetes cost optimization\" prompts\n\n## Key message\nCloudForge shows cost drivers per namespace/workload + actionable recommendations.\n\n## Differentiators\n- OpenTelemetry-friendly\n- Multi-cloud\n- Fast setup\n- Cost anomaly detection\n\n## Do-not-say\n- No fear-mongering\n- Avoid generic career advice\n- Avoid \"get rich quick\" language\n\n## Required formats\n- Hands-on tutorial\n- Comparison video\n- Architecture breakdown\n\n## Brand fit\nPragmatic, dev-first, technical depth\n\n## CTA\nTry CloudForge free tier, link in description\n\n## Budget notes\nMarket rate. Avoid creators quoting > $7k/video unless exceptional.\n```\n\nCampaign A Topics (approved): Kubernetes cost optimization, FinOps for platform engineering, Kubecost alternatives and comparisons, OpenTelemetry + cost attribution, Chargeback vs showback\n\nCampaign A Personas: Platform Engineer, DevOps Lead, CTO (Technical)\n\nCampaign A Prompt Gaps (5 gaps, each with 3 citations):\n1) \"How do I reduce Kubernetes spend without breaking SLOs?\" (high; DevOps Lead; US/UK)\n2) \"Kubecost vs CloudForge: what's actually different?\" (high; Platform Engineer; US/UK)\n3) \"OpenTelemetry + cost attribution: is it possible?\" (medium; Platform Engineer; US/UK)\n4) \"Kubernetes cost anomaly detection tutorial\" (medium; DevOps Lead; US/UK)\n5) \"Chargeback vs showback in Kubernetes (practical)\" (medium; CTO; US/UK)\n\nCampaign A Search Terms (exactly 15, approved=true, order 1-15):\n1) kubecost tutorial cost allocation namespaces (implementation)\n2) kubecost vs alternative comparison (competitor)\n3) kubernetes cost optimization hpa cluster autoscaler (problem_solution)\n4) finops kubernetes showback chargeback implementation (implementation)\n5) opentelemetry cost attribution kubernetes (integration)\n6) prometheus cost monitoring kubernetes (integration)\n7) gke cost optimization tutorial (tutorial_format)\n8) eks cost optimization workload rightsizing (tutorial_format)\n9) terraform kubernetes cost monitoring setup (programming_language)\n10) helm install kubecost alternative (implementation)\n11) kubernetes cost anomaly detection prometheus (problem_solution)\n12) platform engineering finops kubernetes (product_category)\n13) kubernetes namespace cost dashboard grafana (integration)\n14) reduce cloud bill kubernetes without downtime (problem_solution)\n15) kubernetes multi-cloud cost visibility (product_category)\nEach term must have a 1-2 sentence why_it_helps.\n\nCampaigns B-D (minimal, different stages): one in discovery, one in ingestion, one in outreach.\n\n### Creators (12) + Platform Accounts + Flags\nCreate 12 creators with at least 2 platform accounts each and follower metrics:\n1) Nina Patel (KubeCraft) â last_content_date 2026-02-11 â reliable flag active\n2) Omar Reed (DevOpsDossier) â last_content_date 2026-01-07\n3) Mei Tan (Observability Lab) â last_content_date 2026-02-14\n4) Lucas Varga (Cloud Cost Clinic) â last_content_date 2025-09-10 â is_dormant=true\n5) Priya Shah (Platform Patterns) â last_content_date 2026-02-03\n6) K8s Career Hub â lifestyle/career topics\n7) AI Dub Tech Channel â is_autodubbed_suspected=true\n8) Marta Kline (FinOps in Practice) â last_content_date 2026-01-28\n9) Jae Park (SRE Notes) â last_content_date 2026-02-05\n10) Diego Alvarez (Infra Espresso) â last_content_date 2026-01-20\n11) Chloe Nguyen (Kubernetes QuickStarts) â last_content_date 2026-02-16\n12) Samir Iqbal (Multi-Cloud Ops) â last_content_date 2026-02-08 â price_too_high flag active; pricing: video $25000 is_too_high=true\n\n### Campaign A Pipeline (campaign_creators)\nInsert all 12 creators into Campaign A with varied stages:\n- Nina: outreach_ready; ingestion complete; scoring scored; outreach_state sent\n- Mei: approved; outreach_state drafted\n- Jae: outreach_ready; outreach_state replied\n- Lucas: needs_manual_review\n- K8s Career Hub: excluded\n- AI Dub Tech Channel: excluded\n- Samir: scored but not outreach_ready (price_too_high)\n- Marta: outreach_ready; outreach_state booked; pipeline_stage booked\n- Remaining creators mixed discovered/ingested/scored\n\n### Content Items\nFor Nina Patel create 3 items with EXACT quotes in raw_text:\n1) YouTube: \"Kubernetes Cost Allocation by Namespace (Hands-on)\" â raw_text must contain: \"Cost allocation per namespace is only step oneâwhat matters is tying that spend to SLO risk.\" and include \"[05:12]\" nearby.\n2) YouTube: \"Kubecost vs Custom Dashboards: What's Missing\" â raw_text must contain: \"Kubecost is great for allocation, but it won't tell you which deployment caused the spike without additional context.\"\n3) Blog: \"OpenTelemetry signals for cost attribution\" â raw_text must contain: \"If you can tag spans to workloads, you can attribute cost to ownership boundaries.\"\n\nFor Mei Tan create 2 items with raw_text containing:\n- \"OpenTelemetry gives you the metadata hooks; cost attribution is a mapping problem, not a metrics problem.\"\n- \"Anomaly detection works best when you baseline per workload and per namespace.\"\n\nFor Jae Park create 2 items:\n1) YouTube: \"SLO-Driven Cost Management in Kubernetes\" â raw_text must contain: \"You cannot optimize cost in isolation from reliabilityâevery budget decision is also an SLO decision.\" and include \"[03:44]\" nearby.\n2) Blog: \"Kubernetes resource requests: the hidden cost driver\" â raw_text must contain: \"Over-provisioned resource requests are the single biggest source of wasted cloud spend in most Kubernetes clusters.\"\n\nFor K8s Career Hub: 1 item clearly lifestyle/career focused.\nFor AI Dub Tech Channel: 1 low-quality repetitive item.\nInsert at least 3 Reddit thread items with subreddit + karma in metadata_json.\n\n### Evaluations + Evidence\nSeed evaluations for:\n- Nina: overall 88, evidence strong\n- Mei: overall 83, evidence medium\n- Jae: overall 81, evidence medium\n- Lucas: overall 74, needs_manual_review=true, evidence weak\n\nFor Nina: â¥6 evidence snippets referencing Nina's content items, using exact quotes above and timestamps for YouTube items.\nCreate 3-5 content angles per evaluation (content_angles) and link evidence via angle_evidence.\nCreate evaluation_recommended_content rows in high/medium/low buckets.\n\n### Human Reviews\n- Jack approves Nina\n- Jack approves Jae\n- Jack sets Lucas needs_manual_review\n- Jack excludes K8s Career Hub\n\n### Outreach Packets + Activity\nSeed outreach_packets for Nina and Jae with: subject + body_md + followup_plan_json + link 2-3 evidence snippets per packet via outreach_packet_evidence.\n\nSeed outreach_activity:\n- Nina: sent (email) + followup_sent (linkedin)\n- Jae: sent (email) + reply_logged + state_changed to replied\n- Marta: sent (email) + state_changed to booked\n\n---\n\n## Settings Requirements\n\n### Integrations Panel (integration_status)\nDisplay integration tiles: gumshoe, youtube, anthropic, reddit. Each tile supports \"Test connection\" which updates integration_status.\n\n### Thresholds Panel (app_settings)\nEditable: outreach_ready_score_threshold (default 75), min_evidence_coverage (default medium), mask_pii_by_default (default true).\n\n### Admin Tools Panel\n- Clear Demo Data button: confirmation modal requiring typing CLEAR; deletes rows from all domain tables (do not drop tables)\n- Seed Demo Data button: reinserts the dataset; inserts a row in demo_seed_runs; toast on completion\n- Show last seed run info\n\n---\n\n## UI Standards (Ops-Grade)\n\n### App Shell\n- Desktop width target: 1440px\n- Sidebar: ~264px with navigation: Dashboard, Campaigns, Creators, Outreach, Reddit Monitor, Metrics, Settings\n- Top bar: global search (\"Search campaigns, creators, promptsâ¦\") + quick actions (New Campaign, Import CSV, Add Creator URL) + role switcher (Qualifier/Outreach/Admin) + badge \"Internal V0\"\n- Primary content area: tables + dashboards\n- Right-side drawers: creator quick view, evidence viewer, filters drawer\n\n### Required Components\n- Dense table component (sortable, filterable, paginated)\n- Tag/badge system (status tags, flags)\n- Score pill + gauge (0â100)\n- Weighted rubric mini-bars (5 dimensions)\n- Evidence card component: source URL, excerpt/quote, timestamp (if video), \"Why it matters\"\n- Right drawers (creator quick view, evidence, filters)\n- Modals: confirm destructive actions, reveal PII, CSV import\n- Toasts/snackbars for success/failure\n\n### Required UX Copy (must appear in UI)\n- \"Evidence required for all scores and recommendations.\"\n- \"Assistive only â human approval required before outreach.\"\n- \"This tool does not send emails.\"\n\n### States\nFor each major stage (Terms, Discovery, Ingestion, Scoring, Outreach): Loading, Empty (with CTA), Error (with retry + debug detail)\n\n### Visual Style\n- Typography: Inter\n- Neutral backgrounds with subtle borders\n- One accent color for primary actions\n- Status colors: success/warning/danger with restrained saturation\n- Scores visually scannable (pill + gauge)\n- Evidence UI feels \"audit-like\": sources and quotes are prominent\n\n---\n\n## Role-Aware Dashboards\n\n### Qualifier Dashboard (Jack view)\nTop cards: Creators analyzed this week, Needs manual review, Approved for outreach, Active campaigns\nTables:\n1) \"Needs Manual Review Queue\" â columns: Creator, Campaign, Evidence coverage, Overall score, Reason, Last updated â CTA: Open Review\n2) \"Recent Scoring Runs\" â columns: Creator, Campaign, Overall score, Coverage, Scored at, Status\n\n### Outreach Dashboard (Arya view)\nTop cards: Emails to send, Follow-ups due, Replies to log, Booking rate (last 7 days)\nTables:\n1) \"Outreach Queue\" â columns: Creator, Campaign, State, Next follow-up due, Owner, Score, Coverage â CTA: Open Outreach Packet\n2) \"Recently Replied / Booked\" â columns: Creator, Campaign, State, Last activity, Notes\n\n---\n\n## Campaign Workspace Tabs Detail\n\n### Overview Tab\nCards: Campaign stage + status, Creators total/ingested/scored/outreach-ready, Emails sent + booking rate, \"Next actions\" checklist\nPanels: Short campaign summary (client, geo, personas, topics), Recent activity feed\n\n### Brief & Inputs Tab\nThree sections: Creative brief viewer (markdown), Personas + Topics editor, Prompt gaps + citations tables (editable)\n\n### Search Terms Tab\nTable showing exactly 15 terms when generated. Columns: Order, Search term, Category tag, Why it helps, Approved toggle, Notes\nTop actions: Generate 15 terms (AI), Approve all, Reorder (drag handle), Export list\n\n### Discovery Tab\nLayout: Left (approved search term selector), Center (results table), Right (filters drawer + creator quick view drawer)\nDiscovery results table columns: Creator, Platform badges, Topics (chips), Followers/subs, Last content date, Flags (Dormant/Autodubbed suspected/Competitor affiliated), Action: \"Add to campaign\"\nClicking a creator opens quick view drawer with creator overview, platform links, last activity, \"Add to campaign\" button\n\n### Ingestion Tab\nTable columns: Creator, Ingestion status, Content items ingested (count), Last fetched at, Errors, Actions (View content, Add URL, Paste transcript/article)\nContent viewer: YouTube transcript view with timestamps; blog/medium/reddit article/thread view; source metadata (URL, published date, view_count/karma)\n\n### Scoring Tab\nScoring table columns: Creator, Overall score (pill), Evidence coverage, Needs manual review (badge), Last evaluated at, Actions (View evaluation, Run scoring)\nEvaluation drawer/page: Rubric dimension bars + weights, Strengths list (each links evidence), Weaknesses list (each links evidence), Recommended content (High/Medium/Low buckets), Content angles (3-5) with format + key points, Evidence section (non-negotiable): evidence cards with URL, quote, timestamp, why_it_matters\n\n### Review Tab (Qualifier Gate)\nFor each creator: Show evaluation summary, Buttons (Approve for outreach, Mark needs manual review, Reject/Exclude), Optional manual override score input + notes. Changing decision writes a review record and updates pipeline stage.\n\n### Outreach Tab\nOnly shows creators eligible for outreach workflow.\nTable columns: Creator, Outreach state, Next follow-up due, Selected angle, Owner, Actions (Open packet, Generate packet)\nOutreach packet view: Email subject + body (markdown), Copy buttons (subject, body, full email), Follow-up checklist (Email/LinkedIn/X) with checkboxes, Linked evidence snippets section, Prominent disclaimer: \"This tool does not send emails.\"\nOutreach state control: State dropdown or buttons (drafted/copied/sent/replied/ghosted/booked). Each change creates an outreach activity entry.\n\n### Activity Tab\nTimeline feed: scoring events, review decisions, outreach state changes, notes added, ingestion completion/failures\n\n---\n\n## Global Creators DB (/creators)\nTable columns: Creator name, Platforms, Topics, Languages, Last content date, Global flags, Pricing (if exists), Action: View profile\nFilters: Platform, Topic keyword, Has email, Has do_not_contact, Dormant, Autodubbed suspected\n\n### Creator Profile (/creators/[id])\nTabbed layout: Summary, Platforms, Content, Evidence (from evaluations across campaigns), History (campaigns + outcomes), Notes, Outreach packet (latest, if any)\nPII masking: Email hidden by default, \"Reveal PII\" modal confirmation\n\n---\n\n## Outreach Queue (/outreach)\nGlobal cross-campaign queue.\nTable columns: Creator, Campaign, Score, Coverage, State, Next follow-up due, Owner, Actions (Open packet, Log reply, Mark booked)\nInclude \"Follow-ups due today\" filter and section.\n\n---\n\n## Reddit Monitor (/reddit)\nFilters: campaign, topic, subreddit\nTable columns: Thread title, Subreddit, Karma, Posted date, Relevance tag, Link, Attach as evidence (button)\nThread viewer: excerpted raw text and metadata, action: \"Attach to campaign\" or \"Attach to evaluation\"\n\n---\n\n## Metrics (/metrics)\nCharts/cards: Creators analyzed per week, Creators approved per week, Emails sent per week (show baseline reference 130 as faint line/label), Booking rate trend (show baseline reference 7-10%)\nTables: Campaign performance summary (campaign, analyzed, approved, sent, booked, booking rate)\n\n---\n\n## Build Steps for AI Engineer\n\n1. Initialize Next.js App Router + TypeScript project with Inter font and Tailwind CSS.\n2. Set up built-in Postgres DB connection using the platform's database tool.\n3. Create all 34 database tables with exact schema, foreign keys, and indexes as specified.\n4. Create seed script (Section 9) that inserts all demo data including exact raw_text quotes for evidence validation.\n5. Create clear script that deletes all rows from domain tables without dropping them.\n6. Build app shell: sidebar navigation, top bar with role switcher (localStorage), right-side drawer system, toast system.\n7. Build all required UI components: dense table, tag/badge system, score pill + gauge, rubric mini-bars, evidence card, modals (PII reveal, destructive confirm, CSV import).\n8. Implement all 10 routes with DB-backed data rendering.\n9. Implement role-aware dashboard (/) with Qualifier and Outreach views.\n10. Implement campaign setup wizard (/campaigns/new) with 4 steps.\n11. Implement campaign workspace (/campaigns/[id]) with all 9 tabs.\n12. Implement AI server actions: suggest topics (Anthropic), generate 15 search terms (Anthropic), score creator with evidence validation (Anthropic), generate outreach draft (Anthropic).\n13. Implement evidence validation: verify every AI-generated quote is an exact substring of referenced content_items.raw_text; if any fail, set needs_manual_review=true and block outreach_ready.\n14. Implement outreach-ready criteria check as a server-side function checking all 9 conditions.\n15. Implement PII masking: email_encrypted stored with application-level encryption; reveal requires confirmation modal; log pii_access_events.\n16. Implement outreach state machine: every state change creates outreach_activity row.\n17. Implement Reddit monitoring: stub Reddit API calls (return mock if REDDIT_CLIENT_ID is placeholder); store results as content_items rows; deduplicate by URL.\n18. Implement YouTube API stub (return mock if YOUTUBE_API_KEY is placeholder).\n19. Implement settings page: integration tiles with test connection, thresholds editor, admin tools (Seed Demo Data, Clear Demo Data with CLEAR confirmation modal).\n20. Implement metrics page computing all stats from DB.\n21. Implement loading/empty/error states for all major workflow stages.\n22. Ensure all required UX copy appears: \"Evidence required for all scores and recommendations.\", \"Assistive only â human approval required before outreach.\", \"This tool does not send emails.\"\n23. Verify definition of done: all routes render without errors, seeded data populates every screen, clear data shows empty states, end-to-end workflow is functional, evidence validation enforced, no email sending.\n\n\n---\n\nThe user provided the following instructions above. You are an AI assistant that helps users solve problems using code skills, and a powerful data pipeline API system. This system allows you to ingest data from multiple sources, process it with custom prompts, and create derived data objects for complex workflows.\n\nGenerated App ID: 81cf7fb7-67cd-4de2-bf73-193203e3ddb4\n\nYour task:\n1. The user has put together a requirements doc and wants your help putting functions together to create an app that does some task and then returns results to them. This may or may not require the API system. Help the user no matter what they need.\n\n## Your Role\n\nAs an AI assistant using this system:\n1. **Design efficient pipelines** that minimize API calls while maximizing insight\n2. **Provide clear API calls** with proper JSON formatting\n3. **Explain your reasoning** for the chosen approach\n4. **Suggest follow-up steps** or alternative approaches when helpful\n\n\n## Framework\n\nIMPORTANT: Build this project using nextjs. Follow nextjs best practices and conventions.\n\n## Base API Templates\n\n## Available API Endpoints (all API endpoints are at https://builder-api.staging.empromptu.ai)\n\n**CRITICAL - Required Authentication Headers for ALL API calls:**\n```javascript\nconst API_BASE_URL = 'https://builder-api.staging.empromptu.ai';\nconst AUTH_HEADERS = {\n'Content-Type': 'application/json',\n'Authorization': 'Bearer d4d5ed47d417b7e549dd4d2437410203',\n'X-Generated-App-ID': '81cf7fb7-67cd-4de2-bf73-193203e3ddb4',\n'X-Usage-Key': 'e59f58ae3bfc0374ac121f49a55d1354'\n};\n\n// Example fetch call:\nconst response = await fetch(`${API_BASE_URL}/apply_prompt_to_data`, {\nmethod: 'POST',\nheaders: AUTH_HEADERS,\nbody: JSON.stringify(data)\n});\n```\n\nWithout these headers, API calls will fail with 401 Unauthorized.\n\n### 1. AI prompt setup: '/setup_ai_prompt'\ninput_variables: List[str]\nprompt_text: str\n\n**Purpose**: Set up an AI prompt to be applied to text-only data later on.\n**Method**: POST\n**Parameters**:\n- \"prompt_name\" (string): Name of the new prompt.  Should be short and the same each time it is called.\n- \"input_variables\" (list): List of strings. Each of these will be included in the prompt text.\n- \"prompt_text\" (string): Text of the new prompt. Only one unique string should ever be associated with each prompt_name.  Each input variable should be included in this text, in curly braces.\n**Example Usage**:\nRequest body:\n{\n\"prompt_name\": \"summarize_info\",\n\"input_variables\": [\"num_points\",\"raw_info\"],\n\"prompt_text\": \"Please summarize the following data using {num_points} bullet points: {raw_info}\"\n}\n\n### 2. Data Processing: '/apply_prompt_to_data'\n**Purpose**: Apply AI prompts to data to generate new insights\n**Method**: POST\n**Parameters**:\n- 'prompt_name' (string): Name of the prompt to use\n- 'input_data' (object): Names of new objects to create from results. Should be short and the same each time it is called.\n- 'return_type' (string): Format to retrieve object in. The actual data will be in a key called \"value\" returned from this call.\n**Object Formats for return_type**:\nThese determine how the data in the key called 'value' will be formatted.  Options:\n- 'pretty_text': Text formatted for human reading. Should be used where easily readable text is desired.\n- 'pretty_html': Data formatted as an array of HTML strings (each line of the HTML document is a separate array element), to be read by a browser or injected into a web page.\n- 'raw_text': Merge all data from the object into one combined text. Only suitable for additional analysis or parsing.\n- 'structured': Returns a native JavaScript array of objects, like [{\"key1\":\"val1\",\"key2\":\"val2\"},{...}]. Designed to use when the answer has multiple parts or elements. If you use this be sure to write a robust data handler that can handle format variations.\n\n**Example Usage**:\nRequest body:\n{\n\"prompt_name\": \"summarize_info\",\n\"input_data\": {\n\"num_points\": \"5\",\n\"raw_info\": \"Here is some information about a topic of interest......\",\n\"return_type\": \"pretty_text\"\n}\n}\nHeaders must include Authorization and X-Generated-App-ID as shown above.\n\n### 3. Agent Creation\n\nMake a new agent: /create-agent\n**Purpose**: Create a new chatbot to handle a specific question or problem\n**Method**: POST\n**Parameters**:\n- 'instructions' (string): Brief description of what the chatbot or agent should accomplish.\n- 'agent_name' (string): What this agent calls itself in conversation.\n**Returned Values**\n- 'agent_id' (string): ID for using this agent.\n\n**Example Usage**:\n{\n\"instructions\": \"\"\"You are a professional data processing assistant for Impromptu Labs.\nYou help users store, manage, and process data using our MongoDB system.\"\"\",\n\"agent_name\": \"Data Processing Assistant\"\n}\n\nTalk to an existing agent: /chat\n**Purpose**: Continue the conversation with an agent\n**Method**: POST\n**Parameters**:\n- 'agent_id' (string): The system name for the agent, returned from create-agent\n- 'message' (string): Input text to send to the agent.\n- 'session_id' (string): ID string representing this session. Use a new one for each conversation.\n**Returned Values**\n- 'response' (string): The text response from the agent.\n\n**Example Usage**:\n{\n\"agent_id\": agent_id,\n\"message\": \"Hi! I'm new to this system. Can you help me understand how to store data?\"\n}\n\n### 4. Image Analysis\nAnalyze the contents of an Image: /analyze_image\n**Purpose**: Do all extraction of information from images in one step.  This is a standalone step to go from image to text.  It requires image data as input, so extract images from documents as necessary before using this method.\n**Method**: POST\n**Parameters**:\n- 'image' (binary): Binary image file data. Note that you need to send the data as multipart form data with an actual file, not as JSON with a base64 string. Additionally, the API expects an image field, not \"file.\"\n- 'prompt' (string): A prompt to analyze the image, e.g. \"Descibe the contents of this image\" or \"how many dogs are in this image\".\n**Returned Values**\n- 'value' (string): Text response from the image analyzer.\n\n### 5. URL/Webpage Reading: /get_data_from_url\ninput_data (string): URL to retrieve the text from.\n**Purpose**: Extract text from a web page\n**Method**: POST\n**Parameters**:\ninput_data (string): URL to retrieve the text from.\n**Returned Values**\n- 'text' (string): Text from the web page.\n\n## General Problem-Solving Approach to using this API:\nWhen a user presents a problem, follow this systematic approach:\n\n### Step 1: Analyze the Problem\n- What data sources are involved? (text, files, websites, etc.)\n- What processing or analysis is needed?\n- What output format or insights are desired?\n- Are there multiple steps or transformations required?\n\n### Step 2: Plan the Pipeline\n1. **Data Ingestion**: Identify what needs to be imported and how\n2. **Processing Steps**: Determine what prompts/transformations are needed\n3. **Output Goals**: Define what final objects should be created\n\n### Step 3: Execute the Solution\n- Set up the AI prompts using '/setup_ai_prompt'\n- Apply the AI prompts to input text using '/apply_prompt_to_data'\n- Chain multiple processing steps if needed\n- Verify results using the management endpoints\n\n## Advanced Patterns\n\n### Iterative Processing\nBuild complex workflows by chaining operations:\n1. Ingest raw data\n2. Extract key points\n3. Categorize points\n4. Generate final report\n\n## Example Problem-Solving Scenarios\n\n### Competitive Intelligence\n**User**: \"Compare our product features with 5 competitor websites\"\n**Solution**:\n1. Use '/get_data_from_url' to scrape competitor sites\n2. Use '/setup_ai_prompt' to prepare a prompt that extracts product info\n3. Use '/apply_prompt_to_data' to extract features from each web page's data\n4. Compare the resulting data\n\n### Document Processing\n**User**: \"Extract action items from 20 meeting transcripts and categorize them\"\n**Solution**:\n1. Upload transcripts and process them locally\n2. Use '/setup_ai_prompt' to prepare a prompt that extracts action items\n3. Use '/setup_ai_prompt' to prepare a prompt that categorizes action items\n3. Use '/apply_prompt_to_data' with 'structured' return_type\n4. Iterate through each output and use '/apply_prompt_to_data' to categorize each item\n\n## Best Practices\n\n### Naming Conventions\n- Use descriptive object names: 'meeting_transcripts', 'competitor_analysis'\n- Include processing step in names: 'raw_articles' â 'article_summaries' â 'final_report'\n\n### Prompt Engineering\n- Use clear placeholders: '{object_name}'\n- Anywhere an object name is needed, use a single consistent name instead of appending UIDs or timestamps.\n- Specify desired output format in prompts\n- Include example outputs when helpful\n- Request structured data when building pipelines\n\n### Efficiency\n- Use existing capabilities as they are rather than rewriting them\n- All error messages displayed in the app should include the direct output from the API function being called.\n- Ensure you set up any AI prompts before you use them.\n- If PDF parsing is necessary, add it using the client-side library pdfjs-dist, and the line: import pdfjsWorker from 'pdfjs-dist/build/pdf.worker?url'\n- If plots and charts are necessary, add them using Chart.js with react-chartjs-2.\n- Combine related processing steps when possible\n\n## Additional functions and APIs:\n\n\n## Running the app\n\nGive the code one more quick check.  If you have not done so yet, run the necessary commands by calling the `shell_exec` tool (e.g., install dependencies with `npm install`, run tests, or invoke curl to exercise the builder APIs). When you need to create or update files, call `fs_write` with the full file content.always use the registered tools for filesystem and shell access.\n\nAlso, create any text-processing prompts that you will need by issuing curl calls (via `shell_exec` + curl) to the `/setup_ai_prompt` endpoint with the prompts this app will use. Provide the relevant commands and summarize the outputs so the user knows the APIs were exercised.\n\nFrom here onward, ensure that every code or command change goes through the appropriate tool call so it actually takes effect.\n\n## Design Requirements\n\nIf the user requirements did not define styles, change the style of the app using the set of instructions below that are most relevant to the user task:\n\n(For screens where users upload documents, extract structured data, and view outputs):\nGenerate a three-step Upload & Extract flow for seed-to-Series-B small-business brands.\nâ¢ Step 1: File upload card with drag-and-drop and âChoose Fileâ button, branded with some PRIMARY_COLOR of your choice.\nâ¢ Step 2: Extraction progress screen showing a Tailwind-styled spinner, clear status message, and cancel option.\nâ¢ Step 3: Data output table with Tailwind table classes, sortable columns, and âDownload CSVâ button.\nâ¢ Step 4: Ensure mobile breakpoints collapse sidebars into accordion panels; implement dark mode variants; include ARIA labels on all interactive elements.â\n\n(For embedding a conversational AI widget into an existing portal):\nProduce a chatbot UI panel that sits at bottom-right:\nâ¢ Step 1:  Minimal header bar with logo icon and âHelpâ label in some PRIMARY_COLOR of your choice.\nâ¢ Step 2:  Scrollable message window styled with alternating light/dark bubble backgrounds.\nâ¢ Step 3:  Input area with accessible placeholder text 'Ask me anything...', a send icon button, and an optional attachment button.\nâ¢ Step 4:  Ensure focus outlines, keyboard navigation, and proper aria-live regions for new messages.\nâ¢ Step 5:  Include a mobile view where the panel expands full-screen and a dark-mode toggle.â\n\n(For workflows where users upload a document, enter a prompt themselves, then see a summary or output):\nDesign a three-column layout on desktop, single-column on mobile, for Upload + Prompt + Summary:\nâ¢ Step 1:  Upload Column: Drag-and-drop zone with dashed border and an upload progress bar.\nâ¢ Step 2:  Prompt Column: A text area with placeholder 'Enter instructions...', character count, and 'Run' button in green.\nâ¢ Step 3:  Summary Column: Shows AI-generated summary in a scrollable card with expandable sections.\nâ¢ Step 4:  Follow minimal luxe style: plenty of white space, 2xl rounded corners, soft shadows. Use Tailwind classes for spacing. Include dark-mode card variants. Add aria-describedby on summary sections.â\n\n## Database Requirements\n\n# DATABASE CONNECTION INFORMATION\n\nYou have access to a postgres database, that can be accessed with 2 api endpoints:\n\n## Create or change schema: /database/schema\n\n- This endpoint sets up or changes the database. It takes a schema in json format. Call this when the app starts, to declare the database structure.\n- This endpoint will return 3 types of responses. a success response (status code 200), a 304 or an error (either 400s or 500s).\n- Important: you should treat the 304 Error as ok, and not block because of it.\n\n**Request body example:**\n\n{\n\"tables\": [\n{\n\"name\": \"products\",\n\"columns\": [\n{\n\"name\": \"id\",\n\"type\": \"uuid\",\n\"nullable\": false,\n\"default\": \"gen_random_uuid()\"\n},\n{ \"name\": \"name\", \"type\": \"text\", \"nullable\": false },\n{\n\"name\": \"price\",\n\"type\": \"numeric\",\n\"nullable\": false,\n\"default\": \"0\"\n}\n]\n},\n{\n\"name\": \"events\",\n\"columns\": [\n{ \"name\": \"id\", \"type\": \"bigint\", \"nullable\": false },\n{ \"name\": \"occurred_at\", \"type\": \"timestamptz\", \"default\": \"now()\" },\n{ \"name\": \"processed\", \"type\": \"boolean\", \"default\": \"false\" }\n]\n}\n],\n\"indexes\": [\n{\n\"table\": \"products\",\n\"columns\": [\"name\"],\n\"name\": \"products_name_uq\",\n\"unique\": true\n}\n]\n}\n\n## Query the database: /database/query\n\nThis endpoint queries the database. Use this for INSERT or SELECT operations.\n\n**Request body example:**\n\n{\n\"query\": \"SELECT \\* FROM public_table WHERE id = $1 AND username = $2\",\n\"params\": [123, \"steve\"]\n}\n\n**Response example:**\n\n{\n\"success\": true,\n\"data\": [{ \"id\": 1, \"name\": \"a\" }],\n\"row_count\": 1,\n\"affected_rows\": 0,\n\"message\": \"ok\"\n}\n\n## Changing the Schema\n\nFor adding columns, send the new schema to /database/schema. Do not drop or alter existing columns in place.\nFor destructive changes (dropping columns, changing types), instead create a new table with the new schema you want, add data to that new table, and then use that table.\nAllowed operations: CREATE TABLE/INDEX/VIEW; ALTER TABLE ADD COLUMN; ALTER TABLE RENAME\nBlocked Operations: DROP and ALTER COLUMN modifications\n\nFor dates and times, use ISO 8601 format:\n\n- Dates: YYYY-MM-DD (e.g., 2024-03-15)\n- Times: HH:MM:SS (e.g., 14:30:00)\n- Datetimes: YYYY-MM-DD HH:MM:SS (e.g., 2024-03-15 14:30:00)\n- Timezone-aware: Add Z for UTC (e.g., 2024-03-15 14:30:00Z)\n- Do not send explicit timezone-offsets, translate to UTC instead if necessary.\n\nHandle responses by:\n\n- Check response.data.length > 0 to see if data was returned\n- Check response.affected_rows to see if rows were modified\n- If a /database/query call returns a 400, the error message comes from Postgresâfix the SQL or schema and retry.\n- Column type allowlist (includes parameterized and array forms): text, varchar/character/char, numeric/decimal, integer/bigint/smallint, boolean, date/time/timestamp/timestamptz, uuid, json/jsonb, bytea, vector or vector(n).\n- Prefer unlimited-size data types (bigint, text, and numeric) to ensure there is always enough space.\n- You can use the vector data type for columns, vector similarity search operations, and standard pgvector SQL functions and operators.\n\nSchema: app_81cf7fb767cd4de2bf73193203e3ddb4"
        }
      ]
    }
  ],
  "optimized_messages": [
    {
      "id": "turn-1-user",
      "role": "user",
      "parts": [
        {
          "type": "text",
          "text": "<USER_REFERENCE>\n[id:352fb078-c549-4c22-b946-636fc5abe09a, type: pastedText, name: UGFzdGVkIFRleHQ=]\n### Pasted Text (PASTEDTEXT)\n\n# Empromptu Builder â TECHNICAL BUILD PROMPT\n## Yard: Citation Intelligence Creator Ops (V0, Internal)\n\n> **Important**\n> - Build the entire application from scratch using **Next.js (App Router) + TypeScript**.\n> - Use the platformâs **builtâin Postgres database** (builtâin DB).\n> - This prompt is a **strict spec**: do not add features, tables, fields, routes, or behaviors that are not explicitly required here.\n> - **All UI must be dataâdriven from DB tables**. No hardcoded mock arrays.\n> - You must **create all DB tables** listed in **Section 7** in the builtâin DB.\n> - You must **seed** the demo dataset listed in **Section 9** into those tables.\n> - Provide admin buttons in Settings to **Clear Demo Data** and **Seed Demo Data**.\n\n---\n\n## 1) Product Goal (What to Build)\n\nBuild an **internal, humanâinâtheâloop ops tool** that enables a team to:\n1. Create campaigns with creative briefs + topics/personas + optional prompt gaps + citations (manual or CSV import)\n2. Generate and review **exactly 15** YouTube search terms per campaign\n3. Discover and shortlist technical creators (filter out dormant + autodubbed/label + lifestyle/career)\n4. Ingest real creator content (YouTube transcripts primary; blogs/Medium when URLs exist; Reddit monitoring; plus optional podcast/newsletter URLs)\n5. Score creators with a **weighted rubric** and **evidence traceability** (URLs + quotes + timestamps)\n6. Support a human review step before outreach\n7. Generate outreach drafts + follow-up checklist (assistive only; **no automated emailing**)\n8. Track creator reliability flags (ghosted, reliable, do not contact, price too high) + campaign history\n9. Show ops metrics (creators analyzed, approved, emails sent, booking rate)\n\n**Hard requirement:** all scoring/rationale/angles must reference **actual ingested content** stored in DB.\n\n---\n\n## 2) NonâNegotiable Constraints\n\n### 2.1 Framework & Runtime\n- Next.js App Router + TypeScript.\n- Server actions (or API routes) for writes.\n- Desktopâfirst UI (dense tables, drawers, modals).\n\n### 2.2 BuiltâIn Database\n- Use the platform **builtâin Postgres DB**.\n- Create all tables listed in Section 7.\n- Store all demo data in DB (Section 9).\n\n### 2.3 No AutoâOutreach\n- No sending emails.\n- No automated LinkedIn/X actions.\n- Only drafts + copy buttons + manual tracking.\n\n### 2.4 HumanâinâtheâLoop\n- âOutreach-readyâ must only happen after scoring + evidence validation and must be reviewable by a human role.\n\n### 2.5 Environment Variables\n- Create a `.env.local` file with placeholder values for all external integrations:\n  - `ANTHROPIC_API_KEY`\n  - `YOUTUBE_API_KEY`\n  - `REDDIT_CLIENT_ID`\n  - `REDDIT_CLIENT_SECRET`\n- Read all API keys from environment variables. Never hardcode them.\n- YouTube and Reddit API calls are stubbed for V0 â return mock responses if the key is a placeholder. Anthropic calls must be real.\n\n---\n\n## 3) Roles (Internal Users)\n\nCreate role behaviors:\n- **Qualifier**: reviews creators, validates evidence, approves/rejects, may override score with notes.\n- **Outreach**: uses outreach queue, copies drafts, logs manual outreach states (sent/replied/ghosted/booked).\n- **Admin**: integrations + thresholds + seed/clear tools.\n\n**Simple role switching:** role switcher in top bar; store current user in localStorage. No complex auth required for V0.\n\n---\n\n## 4) Required Routes (Must Exist)\n\nAll routes must render DB data and be functional with seeded demo data.\n\n1. `/` â Dashboard (role-aware)\n2. `/campaigns` â Campaign list\n3. `/campaigns/new` â Campaign setup wizard\n4. `/campaigns/[id]` â Campaign workspace with tabs:\n   - `overview`\n   - `brief-inputs`\n   - `search-terms`\n   - `discovery`\n   - `ingestion`\n   - `scoring`\n   - `review`\n   - `outreach`\n   - `activity`\n5. `/creators` â Global creators DB list\n6. `/creators/[id]` â Creator profile detail\n7. `/outreach` â Outreach queue (all campaigns)\n8. `/reddit` â Reddit monitoring dashboard; all fetched threads across campaigns with campaign filter; read-only. See Â§5.10.\n9. `/metrics` â Ops metrics dashboard\n10. `/settings` â Integrations + thresholds + admin tools (seed/clear)\n\n---\n\n## 5) Core Workflows (Functional Behavior)\n\n### 5.1 Campaign Setup\nCreate campaign with:\n- client\n- campaign name\n- GEO targets (array of strings)\n- language\n- product category\n- creative brief (rich text, paste from PDF or doc)\n- personas (multi-add)\n- topics (manual add + optional AI suggestions; max 5 suggested topics; user can edit/approve)\n- prompt gaps + citations (manual OR CSV import)\n- prompts must be editable and have draft/approved status\n\n### 5.2 Search Term Generation (Canonical)\nFrom campaign context (brief + topics + personas + product category):\n- Generate **exactly 15** YouTube search terms\n- Each includes:\n  - category tag (one of 7 tags)\n  - âwhy it helpsâ explanation (1â2 sentences)\n- User can edit/reorder/approve terms\n- Only approved terms used in discovery\n\n### 5.3 Discovery\n- Show discovered creators per approved search term\n- Filters:\n  - language\n  - GEO match\n  - dormant (exclude)\n  - autodubbed/label suspected (exclude)\n  - lifestyle/career (exclude)\n  - competitor affiliated (exclude)\n- Add selected creators into the campaign pipeline\n\nDiscovery integration can be:\n- manual creator URL add (required), plus optional YouTube search if configured.\nRegardless, the screen must be meaningful using seeded DB data.\n\n### 5.4 Ingestion (Content Storage)\nFor each campaign creator, ingest content items:\n- YouTube transcripts (primary)\n- blogs/Medium/corporate blog URLs (when provided)\n- Reddit threads (see Â§5.10 â fetched via API, not manual paste)\n- optional: podcasts/newsletters (manual URL + paste text acceptable)\n\nStore raw text and metadata (URL, date, view counts if available).\nTrack ingestion status: not_started / queued / running / complete / failed.\n\n### 5.5 Scoring + Evidence (Rubric)\nEvaluate each campaign creator and store:\n- overall score 0â100\n- dimension scores 0â100 for 5 dimensions (weights below)\n- strengths & weaknesses\n- recommended content links grouped high/medium/low view counts (when view_count exists)\n- 3â5 suggested content angles\n- evidence snippets (URL + excerpt + timestamps for video)\n\nRubric weights:\n- Technical relevance â 30%\n- Audience alignment â 25%\n- Content quality â 20%\n- Channel performance â 15%\n- Brand fit â 10%\n\nIf insufficient evidence exists:\n- mark Needs Manual Review\n- block outreach-ready\n\n### 5.6 Evidence / Traceability (Hard Requirement)\nThe system must show:\n- source URLs\n- quotes/excerpts (must exist in ingested raw_text)\n- video timestamps when applicable\n\n### 5.7 Outreach Prep (Assistive Only)\nFor approved creators:\n- generate outreach email draft (subject + body)\n- generate followâup checklist (Email / LinkedIn / X)\n- track outreach state manually:\n  - not_started, drafted, copied, sent, replied, ghosted, booked\n- add outreach activity log entries for every state change\n\n### 5.8 Creator Profiles + Status Flags\nPersistent creator record includes:\n- platforms and URLs\n- contact info (PII masked by default)\n- status flags:\n  - reliable\n  - ghosted / not responsive\n  - do not contact\n  - price too high\n- notes + campaign history\n\n### 5.10 Reddit Monitoring\n\n**Purpose:** Surface Reddit threads relevant to campaign topics and brand visibility signals. Read-only â no posting, no commenting, no automation.\n\n**Configuration (per campaign, set in campaign Reddit tab):**\n- Subreddits to watch (free text, e.g. r/kubernetes, r/devops)\n- Keywords to match (default: pulled from campaign search terms; user can edit/add)\n\n**Fetching:**\n- User triggers fetch manually via \"Fetch Reddit\" button in the campaign Reddit tab or from `/reddit`\n- System queries Reddit API using configured subreddits + keywords\n- Each result stored as a `content_items` row:\n  - `platform = reddit`, `content_type = reddit_thread`\n  - `metadata_json` must include: `subreddit`, `karma`, `comment_count`, `reddit_post_id`\n- Duplicate URLs skipped (unique constraint on `content_items.url`)\n- Requires `integration_status.reddit` to be configured in Settings\n\n**`/reddit` route displays:**\n- All fetched Reddit threads across all campaigns, sorted by `fetched_at` desc\n- Filter by campaign\n- Each row: subreddit, thread title, karma, comment count, date fetched, campaign tag, link to original thread\n- Empty state when no threads have been fetched\n\n**Reddit tab within `/campaigns/[id]`:**\n- Shows only threads fetched for that campaign\n- Subreddit + keyword configuration UI\n- \"Fetch Reddit\" button\n\n---\n\n### 5.9 Ops Metrics\nMust compute from DB:\n- creators analyzed per week\n- creators approved for outreach per week\n- emails sent per week (baseline reference 130)\n- booking rate (baseline reference 7â10%)\n\n---\n\n## 6) AI Features (Allowed + Required)\n\nAI calls must be server-side and must store all outputs in DB.\n\n### 6.1 AI: Suggest Topics (UI must include)\nInput: campaign creative brief  \nOutput: up to 5 topics, each with confidence (0â1) + 1 sentence rationale  \nUser can edit/approve topics.\n\nStore in `campaign_topics`.\n\n### 6.2 AI: Generate Search Terms (Required)\nInput: campaign brief + topics + personas + product category  \nOutput: exactly 15 terms with category_tag + why_it_helps.\n\nStore in `campaign_search_terms`.\n\n### 6.3 AI: Score Creator (Required)\nInput:\n- campaign context (brief, topics, personas, prompt gaps, citations)\n- creator profile + platforms\n- ingested content_items (raw_text + metadata + URLs)\n\nOutput must include:\n- dimension scores 0â100\n- overall score (computed using rubric weights)\n- strengths (3â6 bullets) with evidence snippet IDs\n- weaknesses (2â5 bullets) with evidence snippet IDs\n- 3â5 content angles with linked evidence\n- evidence snippets list containing:\n  - content_item_id\n  - timestamp_start_seconds (nullable)\n  - timestamp_end_seconds (nullable)\n  - quote (direct excerpt from raw_text)\n  - dimension\n  - why_it_matters\n\n**Evidence validation (must implement):**\n- Every evidence quote must be verified as an **exact substring** of the referenced `content_items.raw_text`.\n- If any quote fails:\n  - mark evaluation needs_manual_review=true\n  - store reason\n  - do not set outreach_ready\n\n### 6.4 AI: Outreach Draft (Required)\nInput:\n- campaign context\n- creator identity/platforms\n- selected content angle\n- selected evidence snippets\n\nOutput:\n- email subject + body (markdown)\n- follow-up checklist with day offsets:\n  - Email Day 2 / Day 5 / Day 9\n  - LinkedIn Day 2 / Day 5\n  - X Day 5 (optional)\n\nStore in `outreach_packets` + link evidence via `outreach_packet_evidence`.\n\n**No send button. Copy-only.**\n\n---\n\n## 7) Database Schema (BuiltâIn Postgres) â Tables to Create\n\n> Create all tables below. Use UUID primary keys and timestamptz timestamps.\n> Implement foreign keys and indexes as listed.\n> Do not add extra columns.\n\n### 7.1 `app_users`\n- id (uuid, PK)\n- name (text, not null)\n- email (text, not null, unique)\n- role (text, not null; one of: qualifier, outreach, admin)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\n### 7.2 `clients`\n- id (uuid, PK)\n- name (text, not null, unique)\n- website_url (text, null)\n- notes (text, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\n### 7.3 `campaigns`\n- id (uuid, PK)\n- client_id (uuid, FK -> clients.id, not null)\n- name (text, not null)\n- owner_user_id (uuid, FK -> app_users.id, not null)\n- collaborator_user_id (uuid, FK -> app_users.id, null)\n- status (text, not null; one of: draft, active, archived)\n- stage (text, not null; one of: draft, terms, discovery, ingestion, scoring, review, outreach, tracking, complete)\n- geo_targets (text[], not null, default empty)\n- deadline (date, null)\n- language (text, not null, default 'English')\n- product_category (text, null)\n- creative_brief (text, not null)\n- creative_brief_source_url (text, null)\n- additional_prompt_context (text, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: client_id, owner_user_id, status, stage\n\n### 7.4 `campaign_personas`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- persona_name (text, not null)\n- created_at (timestamptz, not null)\n\nUnique: (campaign_id, persona_name)\n\n### 7.5 `campaign_topics`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- topic (text, not null)\n- source (text, not null; one of: manual, ai_suggested)\n- confidence (numeric(3,2), null)\n- rationale (text, null)\n- order_index (int, not null, default 0)\n- approved (boolean, not null, default true)\n- created_at (timestamptz, not null)\n\nUnique: (campaign_id, topic)\nIndex: campaign_id\n\n### 7.6 `campaign_prompt_gaps`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- prompt_text (text, not null)\n- priority (text, not null; one of: high, medium, low)\n- persona (text, null)\n- geo (text[], not null, default empty)\n- gap_note (text, null)\n- status (text, not null; one of: draft, approved, archived)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: campaign_id, priority, status\n\n### 7.7 `prompt_citations`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- prompt_gap_id (uuid, FK -> campaign_prompt_gaps.id, null)\n- citation_title (text, not null)\n- citation_url (text, not null)\n- source_type (text, not null; one of: docs, blog, youtube, reddit, paper, other)\n- cited_by_models (text[], not null, default empty)\n- notes (text, null)\n- created_at (timestamptz, not null)\n\nIndexes: campaign_id, prompt_gap_id, source_type\n\n### 7.8 `gumshoe_imports`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- import_type (text, not null; one of: csv, manual)\n- original_filename (text, null)\n- raw_text (text, not null)  // original CSV or pasted text\n- imported_by_user_id (uuid, FK -> app_users.id, not null)\n- created_at (timestamptz, not null)\n\nIndex: campaign_id\n\n### 7.9 `campaign_search_terms`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- term (text, not null)\n- category_tag (text, not null; one of: product_category, competitor, implementation, problem_solution, integration, programming_language, tutorial_format)\n- why_it_helps (text, not null)\n- order_index (int, not null, default 0)\n- approved (boolean, not null, default false)\n- approved_by_user_id (uuid, FK -> app_users.id, null)\n- approved_at (timestamptz, null)\n- notes (text, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: campaign_id, approved\n\n### 7.10 `creators`\n- id (uuid, PK)\n- display_name (text, not null)\n- primary_handle (text, null)\n- bio (text, null)\n- topics (text[], not null, default empty)\n- languages (text[], not null, default empty)\n- geo_focus (text[], not null, default empty)\n- competitor_affiliated (boolean, not null, default false)\n- is_dormant (boolean, not null, default false)\n- is_autodubbed_suspected (boolean, not null, default false)\n- last_content_date (date, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: display_name, is_dormant, is_autodubbed_suspected, competitor_affiliated\n\n### 7.11 `creator_platform_accounts`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- platform (text, not null; one of: youtube, github, linkedin, devto, medium, blog, podcast, newsletter, reddit, other)\n- handle (text, null)\n- url (text, not null)\n- follower_count (int, null)\n- metrics_json (jsonb, not null, default {})\n- created_at (timestamptz, not null)\n\nUnique: (platform, url)\nIndexes: creator_id, platform\n\n### 7.12 `creator_contacts`  (PII)\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null, unique)\n- email_encrypted (text, null)\n- linkedin_url (text, null)\n- x_url (text, null)\n- other_contacts_json (jsonb, not null, default {})\n- pii_last_updated_at (timestamptz, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\n### 7.13 `creator_status_flags`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- flag (text, not null; one of: reliable, ghosted, do_not_contact, price_too_high)\n- is_active (boolean, not null, default true)\n- reason (text, null)\n- set_by_user_id (uuid, FK -> app_users.id, not null)\n- set_at (timestamptz, not null)\n\nIndexes: creator_id, flag\n\n### 7.14 `creator_pricing`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- price_type (text, not null; one of: video, written, newsletter, other)\n- price_amount_usd (numeric(10,2), not null)\n- is_too_high (boolean, not null, default false)\n- notes (text, null)\n- updated_at (timestamptz, not null)\n\nIndex: creator_id\n\n### 7.15 `creator_notes`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- note_md (text, not null)\n- created_by_user_id (uuid, FK -> app_users.id, not null)\n- created_at (timestamptz, not null)\n\nIndex: creator_id\n\n### 7.16 `campaign_creators`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- creator_id (uuid, FK -> creators.id, not null)\n- added_by_user_id (uuid, FK -> app_users.id, not null)\n- source_search_term_id (uuid, FK -> campaign_search_terms.id, null)\n\n- pipeline_stage (text, not null; one of:\n  discovered, queued_for_ingestion, ingested, scored, needs_manual_review,\n  approved, outreach_ready, contacted, booked, rejected, excluded\n)\n\n- campaign_do_not_contact (boolean, not null, default false)\n- campaign_do_not_contact_reason (text, null)\n\n- ingestion_status (text, not null; one of: not_started, queued, running, complete, failed)\n- ingestion_error (text, null)\n\n- scoring_status (text, not null; one of: not_scored, scoring, scored, failed)\n- scoring_error (text, null)\n\n- outreach_owner_user_id (uuid, FK -> app_users.id, null)\n- outreach_state (text, not null; one of: not_started, drafted, copied, sent, replied, ghosted, booked)\n- last_outreach_at (timestamptz, null)\n- next_followup_due_at (date, null)\n\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nUnique: (campaign_id, creator_id)\nIndexes: campaign_id, creator_id, pipeline_stage, ingestion_status, scoring_status, outreach_state\n\n### 7.17 `content_items`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- campaign_id (uuid, FK -> campaigns.id, null)\n\n- platform (text, not null; one of: youtube, blog, medium, devto, reddit, podcast, newsletter, github, linkedin, other)\n- content_type (text, not null; one of:\n  youtube_video, blog_post, medium_post, devto_post, reddit_thread,\n  podcast_episode, newsletter_issue, github_repo, linkedin_post, other\n)\n\n- title (text, not null)\n- url (text, not null)\n- published_at (timestamptz, null)\n- fetched_at (timestamptz, null)\n\n- language (text, null)\n- raw_text (text, not null)\n- word_count (int, null)\n\n- metadata_json (jsonb, not null, default {})  // view_count, duration_seconds, subreddit, karma, etc.\n\n- ingestion_method (text, not null; one of: seed, manual_paste, fetched)\n- ingestion_status (text, not null; one of: complete, failed)\n- ingestion_error (text, null)\n\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nUnique: (url)\nIndexes: creator_id, campaign_id, platform, content_type, published_at\n\n### 7.18 `creator_evaluations`\n- id (uuid, PK)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, not null, unique)\n\n- model_provider (text, not null)\n- model_name (text, not null)\n- evaluated_at (timestamptz, not null)\n\n- evidence_coverage (text, not null; one of: strong, medium, weak, none)\n- needs_manual_review (boolean, not null, default false)\n- needs_manual_review_reason (text, null)\n\n- overall_score (int, not null, 0â100)\n- score_technical_relevance (int, not null, 0â100)\n- score_audience_alignment (int, not null, 0â100)\n- score_content_quality (int, not null, 0â100)\n- score_channel_performance (int, not null, 0â100)\n- score_brand_fit (int, not null, 0â100)\n\n- strengths_json (jsonb, not null, default [])\n- weaknesses_json (jsonb, not null, default [])\n- rationale_md (text, not null)\n\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: overall_score, needs_manual_review, evidence_coverage\n\n### 7.19 `evidence_snippets`\n- id (uuid, PK)\n- evaluation_id (uuid, FK -> creator_evaluations.id, not null)\n- content_item_id (uuid, FK -> content_items.id, not null)\n- timestamp_start_seconds (int, null)\n- timestamp_end_seconds (int, null)\n- quote (text, not null)\n- dimension (text, not null; one of: technical_relevance, audience_alignment, content_quality, channel_performance, brand_fit, general)\n- why_it_matters (text, not null)\n- created_at (timestamptz, not null)\n\nIndexes: evaluation_id, content_item_id, dimension\n\n### 7.20 `evaluation_recommended_content`\n- id (uuid, PK)\n- evaluation_id (uuid, FK -> creator_evaluations.id, not null)\n- content_item_id (uuid, FK -> content_items.id, not null)\n- bucket (text, not null; one of: high, medium, low)\n- relevance_rank (int, not null, default 0)\n- notes (text, null)\n- created_at (timestamptz, not null)\n\nUnique: (evaluation_id, content_item_id)\nIndex: evaluation_id\n\n### 7.21 `content_angles`\n- id (uuid, PK)\n- evaluation_id (uuid, FK -> creator_evaluations.id, not null)\n- title (text, not null)\n- target_prompt_gap_id (uuid, FK -> campaign_prompt_gaps.id, null)\n- persona (text, null)\n- format (text, not null; one of: tutorial, comparison, architecture, deep_dive, checklist, case_study, other)\n- key_points_json (jsonb, not null, default [])\n- selected_for_outreach (boolean, not null, default false)\n- created_at (timestamptz, not null)\n\nIndex: evaluation_id\n\n### 7.22 `angle_evidence`\n- id (uuid, PK)\n- angle_id (uuid, FK -> content_angles.id, not null)\n- evidence_snippet_id (uuid, FK -> evidence_snippets.id, not null)\n- created_at (timestamptz, not null)\n\nUnique: (angle_id, evidence_snippet_id)\nIndex: angle_id\n\n### 7.23 `human_reviews`\n- id (uuid, PK)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, not null)\n- reviewed_by_user_id (uuid, FK -> app_users.id, not null)\n- reviewed_at (timestamptz, not null)\n- decision (text, not null; one of: approved_for_outreach, rejected, needs_manual_review, excluded)\n- manual_override_score (int, null, 0â100)\n- notes_md (text, null)\n- created_at (timestamptz, not null)\n\nIndexes: campaign_creator_id, decision\n\n### 7.24 `outreach_packets`\n- id (uuid, PK)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, not null, unique)\n- created_by_user_id (uuid, FK -> app_users.id, not null)\n- subject (text, not null)\n- body_md (text, not null)\n- selected_angle_id (uuid, FK -> content_angles.id, null)\n- followup_plan_json (jsonb, not null, default [])\n- last_updated_at (timestamptz, not null)\n- created_at (timestamptz, not null)\n\nIndex: campaign_creator_id\n\n### 7.25 `outreach_packet_evidence`\n- id (uuid, PK)\n- outreach_packet_id (uuid, FK -> outreach_packets.id, not null)\n- evidence_snippet_id (uuid, FK -> evidence_snippets.id, not null)\n- created_at (timestamptz, not null)\n\nUnique: (outreach_packet_id, evidence_snippet_id)\nIndex: outreach_packet_id\n\n### 7.26 `outreach_activity`\n- id (uuid, PK)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, not null)\n- performed_by_user_id (uuid, FK -> app_users.id, not null)\n- channel (text, not null; one of: email, linkedin, x)\n- action_type (text, not null; one of: drafted, copied, sent, followup_sent, reply_logged, state_changed, note)\n- state_after (text, not null; one of: not_started, drafted, copied, sent, replied, ghosted, booked)\n- occurred_at (timestamptz, not null)\n- notes (text, null)\n\nIndexes: campaign_creator_id, channel, action_type, occurred_at\n\n### 7.27 `activity_log`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, null)\n- creator_id (uuid, FK -> creators.id, null)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, null)\n- actor_user_id (uuid, FK -> app_users.id, null)\n- event_type (text, not null)\n- event_data_json (jsonb, not null, default {})\n- created_at (timestamptz, not null)\n\nIndexes: campaign_id, created_at\n\n### 7.28 `app_settings`\n(single row)\n- id (uuid, PK)\n- mask_pii_by_default (boolean, not null, default true)\n- outreach_ready_score_threshold (int, not null, default 75)\n- min_evidence_coverage (text, not null; one of: strong, medium, weak; default medium)\n- default_ai_model (text, not null, default 'claude')\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\n### 7.29 `integration_status`\n- id (uuid, PK)\n- integration_key (text, not null, unique; one of: gumshoe, youtube, anthropic, reddit)\n- is_configured (boolean, not null, default false)\n- last_tested_at (timestamptz, null)\n- last_test_result (text, null; one of: success, failure)\n- last_test_message (text, null)\n- updated_at (timestamptz, not null)\n\n### 7.30 `demo_seed_runs`\n- id (uuid, PK)\n- seed_version (text, not null)\n- seeded_at (timestamptz, not null)\n- seeded_by_user_id (uuid, FK -> app_users.id, not null)\n- notes (text, null)\n\n### 7.31 `campaign_attachments`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- file_name (text, not null)\n- file_type (text, null)\n- file_size_bytes (bigint, null)\n- storage_key (text, not null)\n- uploaded_by_user_id (uuid, FK -> app_users.id, null)\n- created_at (timestamptz, not null)\n\nIndex: campaign_id\n\n### 7.32 `pii_access_events`\n- id (uuid, PK)\n- accessed_by_user_id (uuid, FK -> app_users.id, null)\n- creator_id (uuid, FK -> creators.id, not null)\n- reason (text, null)\n- created_at (timestamptz, not null)\n\nIndexes: creator_id, accessed_by_user_id\n\n### 7.33 `jobs`\n- id (uuid, PK)\n- type (text, not null; one of: ingestion, scoring, reddit_fetch, other)\n- status (text, not null; one of: queued, running, complete, failed)\n- campaign_id (uuid, FK -> campaigns.id, null)\n- creator_id (uuid, FK -> creators.id, null)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, null)\n- payload (jsonb, not null, default {})\n- error_message (text, null)\n- started_at (timestamptz, null)\n- finished_at (timestamptz, null)\n- created_by_user_id (uuid, FK -> app_users.id, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: status, campaign_id, creator_id\n\n### 7.34 `job_events`\n- id (uuid, PK)\n- job_id (uuid, FK -> jobs.id, not null)\n- level (text, not null; one of: info, warn, error)\n- message (text, not null)\n- meta (jsonb, null)\n- created_at (timestamptz, not null)\n\nIndex: job_id\n\n---\n\n## 8) Business Rules (Must Implement)\n\n### 8.1 Dormancy\nA creator is considered dormant if `last_content_date` is older than **120 days** from today.\n- Store `creators.is_dormant` and set it accordingly during seeding and when updating creators.\n\n### 8.2 Evidence Coverage Levels\nCompute `creator_evaluations.evidence_coverage` based on evidence snippet count/diversity:\n- Strong: â¥6 snippets across â¥3 content items AND â¥3 dimensions\n- Medium: â¥3 snippets across â¥2 content items AND â¥2 dimensions\n- Weak: 1â2 snippets OR all snippets from 1 content item\n- None: 0 snippets\n\n### 8.3 OutreachâReady Criteria\nA campaign creator is outreachâready only if all are true:\n- evaluation exists\n- overall_score â¥ app_settings.outreach_ready_score_threshold\n- evidence_coverage meets app_settings.min_evidence_coverage\n- no campaign_do_not_contact\n- no active global do_not_contact flag\n- not competitor_affiliated\n- not is_autodubbed_suspected\n- not needs_manual_review\n- no active `price_too_high` flag in `creator_status_flags`\n\n### 8.4 PII Masking\n- Mask PII by default.\n- Reveal requires confirmation modal.\n- Do not log PII.\n- Store email in creator_contacts.email_encrypted (application-level encryption with server secret is acceptable).\n\n### 8.5 Outreach Logging\nAny outreach_state change must create an `outreach_activity` row.\n\n### 8.6 Booking Rate\nBooking rate = (# creators reaching booked) / (# email sent events). Compute in metrics.\n\n---\n\n## 9) Seed Dataset (Must Insert Into DB)\n\n> Seed version: `v0-demo-1`.\n> Seeding must populate all major screens with realistic content.\n\n### 9.1 Users (app_users)\nCreate 4 users:\n- Jack Scrivener (jack@yard.internal) role qualifier\n- Arya (arya@yard.internal) role outreach\n- Karl McCarthy (karl@yard.internal) role admin\n- Empromptu (admin@empromptu.internal) role admin\n\n### 9.2 Clients\nCreate 4 clients:\n- CloudForge\n- NebulaDB\n- SecuriNest\n- VectorShift\n\n### 9.3 Campaigns\nCreate 4 campaigns; fully populate Campaign A.\n\nCampaign A (fully populated):\n- Client: CloudForge\n- Name: âCloudForge â Kubernetes Cost Optimization (US + UK)â\n- Owner: Jack\n- Collaborator: Arya\n- Status: active\n- Stage: scoring\n- GEO targets: [United States, United Kingdom]\n- Language: English\n- Product category: âFinOps / Kubernetes cost optimizationâ\n- Creative brief markdown: insert the exact multi-section brief described below:\n\n```\n# Make CloudForge the default answer for âKubernetes cost optimizationâ prompts\n\n## Key message\nCloudForge shows cost drivers per namespace/workload + actionable recommendations.\n\n## Differentiators\n- OpenTelemetry-friendly\n- Multi-cloud\n- Fast setup\n- Cost anomaly detection\n\n## Do-not-say\n- No fear-mongering\n- Avoid generic career advice\n- Avoid âget rich quickâ language\n\n## Required formats\n- Hands-on tutorial\n- Comparison video\n- Architecture breakdown\n\n## Brand fit\nPragmatic, dev-first, technical depth\n\n## CTA\nTry CloudForge free tier, link in description\n\n## Budget notes\nMarket rate. Avoid creators quoting > $7k/video unless exceptional.\n```\n\nCampaign A Topics (campaign_topics; approved):\n1) Kubernetes cost optimization\n2) FinOps for platform engineering\n3) Kubecost alternatives and comparisons\n4) OpenTelemetry + cost attribution\n5) Chargeback vs showback\n\nCampaign A Personas (campaign_personas):\n- Platform Engineer\n- DevOps Lead\n- CTO (Technical)\n\nCampaign A Prompt gaps (campaign_prompt_gaps) + citations (prompt_citations):\nCreate 5 prompt gaps; each has 3 citations exactly as listed:\n1) âHow do I reduce Kubernetes spend without breaking SLOs?â (high; persona DevOps Lead; geo US/UK)\n2) âKubecost vs CloudForge: whatâs actually different?â (high; persona Platform Engineer; geo US/UK)\n3) âOpenTelemetry + cost attribution: is it possible?â (medium; persona Platform Engineer; geo US/UK)\n4) âKubernetes cost anomaly detection tutorialâ (medium; persona DevOps Lead; geo US/UK)\n5) âChargeback vs showback in Kubernetes (practical)â (medium; persona CTO; geo US/UK)\n\nCampaign A Search terms (campaign_search_terms):\nInsert exactly 15 terms, approved=true, order 1â15, with correct category_tag and a 1â2 sentence why_it_helps.\n\nTerms (with tags):\n1) kubecost tutorial cost allocation namespaces (implementation)\n2) kubecost vs alternative comparison (competitor)\n3) kubernetes cost optimization hpa cluster autoscaler (problem_solution)\n4) finops kubernetes showback chargeback implementation (implementation)\n5) opentelemetry cost attribution kubernetes (integration)\n6) prometheus cost monitoring kubernetes (integration)\n7) gke cost optimization tutorial (tutorial_format)\n8) eks cost optimization workload rightsizing (tutorial_format)\n9) terraform kubernetes cost monitoring setup (programming_language)\n10) helm install kubecost alternative (implementation)\n11) kubernetes cost anomaly detection prometheus (problem_solution)\n12) platform engineering finops kubernetes (product_category)\n13) kubernetes namespace cost dashboard grafana (integration)\n14) reduce cloud bill kubernetes without downtime (problem_solution)\n15) kubernetes multi-cloud cost visibility (product_category)\n\nCampaigns BâD (minimal):\nCreate 3 additional campaigns with short briefs and different stages:\n- One in discovery\n- One in ingestion\n- One in outreach\n\n### 9.4 Creators (12) + Platform Accounts + Flags\nCreate 12 creators with at least 2 platform accounts each, and include follower metrics in platform accounts.\n\nCreators to insert:\n1) Nina Patel (KubeCraft) â last_content_date 2026-02-11 â reliable flag active\n2) Omar Reed (DevOpsDossier) â last_content_date 2026-01-07\n3) Mei Tan (Observability Lab) â last_content_date 2026-02-14\n4) Lucas Varga (Cloud Cost Clinic) â last_content_date 2025-09-10 â is_dormant=true\n5) Priya Shah (Platform Patterns) â last_content_date 2026-02-03\n6) K8s Career Hub â lifestyle/career topics\n7) AI Dub Tech Channel â is_autodubbed_suspected=true\n8) Marta Kline (FinOps in Practice) â last_content_date 2026-01-28\n9) Jae Park (SRE Notes) â last_content_date 2026-02-05\n10) Diego Alvarez (Infra Espresso) â last_content_date 2026-01-20\n11) Chloe Nguyen (Kubernetes QuickStarts) â last_content_date 2026-02-16\n12) Samir Iqbal (Multi-Cloud Ops) â last_content_date 2026-02-08 â price_too_high flag active; pricing: video $25000 is_too_high=true\n\n### 9.5 Campaign A Pipeline (campaign_creators)\nInsert all 12 creators into Campaign A with varied stages:\n- Nina: outreach_ready; ingestion complete; scoring scored; outreach_state sent\n- Mei: approved; outreach_state drafted\n- Jae: outreach_ready; outreach_state replied\n- Lucas: needs_manual_review\n- K8s Career Hub: excluded\n- AI Dub Tech Channel: excluded\n- Samir: scored but not outreach_ready (price_too_high)\n- Marta: outreach_ready; outreach_state booked; pipeline_stage booked\n- Remaining creators mixed discovered/ingested/scored\n\n### 9.6 Content Items (content_items)\nInsert content items for at least 6 creators (with view_count in metadata_json where relevant).\n\nFor Nina Patel create 3 items whose raw_text includes EXACT quotes below (for evidence validation):\n1) YouTube: âKubernetes Cost Allocation by Namespace (Hands-on)â\n   raw_text must contain:\n   âCost allocation per namespace is only step oneâwhat matters is tying that spend to SLO risk.â\n   and include â[05:12]â nearby.\n2) YouTube: âKubecost vs Custom Dashboards: Whatâs Missingâ\n   raw_text must contain:\n   âKubecost is great for allocation, but it wonât tell you which deployment caused the spike without additional context.â\n3) Blog: âOpenTelemetry signals for cost attributionâ\n   raw_text must contain:\n   âIf you can tag spans to workloads, you can attribute cost to ownership boundaries.â\n\nFor Mei Tan create 2 items with raw_text containing:\n- âOpenTelemetry gives you the metadata hooks; cost attribution is a mapping problem, not a metrics problem.â\n- âAnomaly detection works best when you baseline per workload and per namespace.â\n\nFor Jae Park create 2 items with raw_text containing:\n1) YouTube: \"SLO-Driven Cost Management in Kubernetes\"\n   raw_text must contain:\n   \"You cannot optimize cost in isolation from reliabilityâevery budget decision is also an SLO decision.\"\n   and include \"[03:44]\" nearby.\n2) Blog: \"Kubernetes resource requests: the hidden cost driver\"\n   raw_text must contain:\n   \"Over-provisioned resource requests are the single biggest source of wasted cloud spend in most Kubernetes clusters.\"\n\nFor K8s Career Hub create 1 item clearly lifestyle/career focused.\nFor AI Dub Tech Channel create 1 low-quality repetitive item.\nInsert at least 3 Reddit thread items with subreddit + karma in metadata_json.\n\n### 9.7 Evaluations + Evidence (creator_evaluations + evidence_snippets)\nSeed evaluations for:\n- Nina overall 88 evidence strong\n- Mei overall 83 evidence medium\n- Jae overall 81 evidence medium\n- Lucas overall 74 needs_manual_review true evidence weak\n\nFor Nina create â¥6 evidence snippets referencing Ninaâs content items, using the exact quotes above and timestamps for YouTube items.\nCreate 3â5 content angles per evaluation (content_angles) and link evidence via angle_evidence.\nCreate evaluation_recommended_content rows in high/medium/low buckets.\n\n### 9.8 Human Reviews (human_reviews)\nSeed:\n- Jack approves Nina\n- Jack approves Jae\n- Jack sets Lucas needs_manual_review\n- Jack excludes K8s Career Hub\n\n### 9.9 Outreach Packets + Activity\nSeed outreach_packets for Nina and Jae with:\n- subject + body_md\n- followup_plan_json\n- link 2â3 evidence snippets per packet via outreach_packet_evidence\n\nSeed outreach_activity:\n- Nina: sent (email) + followup_sent (linkedin)\n- Jae: sent (email) + reply_logged + state_changed to replied\n- Marta: sent (email) + state_changed to booked\n\n---\n\n## 10) Settings Requirements (Technical)\n\n### 10.1 Integrations Panel (integration_status)\nDisplay integration tiles:\n- gumshoe\n- youtube\n- anthropic\n- reddit\nEach tile supports âTest connectionâ which updates integration_status.\n\n### 10.2 Thresholds Panel (app_settings)\nEditable:\n- outreach_ready_score_threshold (default 75)\n- min_evidence_coverage (default medium)\n- mask_pii_by_default (default true)\n\n### 10.3 Admin Tools Panel (Required)\nButtons:\n- **Clear Demo Data**\n  - confirmation modal requiring typing `CLEAR`\n  - deletes rows from all domain tables (do not drop tables)\n- **Seed Demo Data**\n  - reinserts the dataset in Section 9\n  - inserts a row in demo_seed_runs\n\n---\n\n## 11) Definition of Done (Technical Acceptance)\n\nThe build is complete only if:\n1. All routes exist and render without errors.\n2. All tables exist and are used by the app.\n3. Seed Demo Data populates DB and every screen displays meaningful DB-backed content.\n4. Clear Demo Data empties tables and the UI shows empty states (no crashes).\n5. Endâtoâend workflow is possible entirely inside the app:\n   campaign â terms â discovery â ingestion â scoring+evidence â review â outreach drafts â manual tracking â metrics\n6. Evidence validation is enforced; invalid evidence forces needs_manual_review and blocks outreach_ready.\n7. No automated email sending exists (copy-only).\n\n\n\n[id:9a5e6151-0aa0-4f13-9268-700d6703238e, type: pastedText, name: UGFzdGVkIFRleHQ=]\n### Pasted Text (PASTEDTEXT)\n\n# Empromptu Builder â UX/UI DESIGN PROMPT\n## Yard: Citation Intelligence Creator Ops (V0, Internal)\n\n> **Important**\n> - Build a complete **desktop-first internal ops UI** for the product described here.\n> - Every screen must be **DB-backed** (render content from the builtâin Postgres tables).\n> - Include **loading / empty / error** states for every major workflow stage.\n> - The UI must make âhumanâinâtheâloopâ explicit: review and approval gates are visible and required.\n> - Do not invent features. Implement exactly what is specified.\n\n---\n\n## 1) Product UX Goal\n\nThe UI must support an end-to-end workflow for internal operators:\n\n1) Create a campaign (brief + topics/personas + optional prompt gaps/citations)  \n2) Generate + review 15 YouTube search terms  \n3) Discover creators and add them to a campaign pipeline  \n4) Ingest creator content (transcripts/articles/reddit) and show ingestion status  \n5) Score creators with a weighted rubric and evidence traceability  \n6) Human review/approval (Qualifier)  \n7) Outreach prep (draft + follow-up checklist) (Outreach)  \n8) Manual outreach tracking + statuses + metrics\n\n**Design must emphasize:** fast scanning, evidence credibility, and operational throughput.\n\n---\n\n## 2) App Shell (Global Layout)\n\n### 2.1 Layout\n- Desktop width target: 1440px\n- Sidebar: ~264px\n- Top bar: global search + quick actions + role switcher\n- Primary content area: tables + dashboards\n- Right-side drawers: creator quick view, evidence viewer, filters drawer\n\n### 2.2 Navigation (Sidebar)\n- Dashboard\n- Campaigns\n- Creators\n- Outreach\n- Reddit Monitor\n- Metrics\n- Settings\n\n### 2.3 Top Bar\n- Global search input: âSearch campaigns, creators, promptsâ¦â\n- Quick action buttons:\n  - New Campaign\n  - Import CSV\n  - Add Creator URL\n- Role switcher (Qualifier / Outreach / Admin)\n- Badge: âInternal V0â\n\n---\n\n## 3) UI Standards (Ops-Grade)\n\n### 3.1 Required Components\n- Dense table component (sortable, filterable, paginated)\n- Tag/badge system (status tags, flags)\n- Score pill + gauge (0â100)\n- Weighted rubric mini-bars (5 dimensions)\n- Evidence card component:\n  - source URL\n  - excerpt/quote\n  - timestamp (if video)\n  - âWhy it mattersâ\n- Right drawers (creator quick view, evidence, filters)\n- Modals:\n  - Confirm destructive actions\n  - Reveal PII\n  - CSV import\n- Toasts/snackbars for success/failure\n\n### 3.2 Required UX Copy (must appear)\n- âEvidence required for all scores and recommendations.â\n- âAssistive only â human approval required before outreach.â\n- âThis tool does not send emails.â\n\n### 3.3 States\nFor each major stage (Terms, Discovery, Ingestion, Scoring, Outreach):\n- Loading\n- Empty (with CTA)\n- Error (with retry + debug detail)\n\n---\n\n## 4) Routes & Screens (UI Inventory)\n\nCreate UI for the following routes (must be accessible via sidebar):\n\n1. `/` Dashboard (role-aware)\n2. `/campaigns` Campaign list\n3. `/campaigns/new` Campaign setup wizard\n4. `/campaigns/[id]` Campaign workspace with tabs:\n   - Overview\n   - Brief & Inputs\n   - Search Terms\n   - Discovery\n   - Ingestion\n   - Scoring\n   - Review\n   - Outreach\n   - Activity\n5. `/creators` Global creator DB list\n6. `/creators/[id]` Creator profile\n7. `/outreach` Outreach queue\n8. `/reddit` Reddit monitor\n9. `/metrics` Ops metrics\n10. `/settings` Settings + Admin tools\n\n---\n\n## 5) Role-Aware Dashboards (`/`)\n\n### 5.1 Qualifier Dashboard (Jack view)\nTop cards:\n- Creators analyzed this week\n- Needs manual review\n- Approved for outreach\n- Active campaigns\n\nTables:\n1) âNeeds Manual Review Queueâ\n- columns: Creator, Campaign, Evidence coverage, Overall score, Reason, Last updated\n- CTA: Open Review\n\n2) âRecent Scoring Runsâ\n- columns: Creator, Campaign, Overall score, Coverage, Scored at, Status\n\n### 5.2 Outreach Dashboard (Arya view)\nTop cards:\n- Emails to send\n- Follow-ups due\n- Replies to log\n- Booking rate (last 7 days)\n\nTables:\n1) âOutreach Queueâ\n- columns: Creator, Campaign, State, Next follow-up due, Owner, Score, Coverage\n- CTA: Open Outreach Packet\n\n2) âRecently Replied / Bookedâ\n- columns: Creator, Campaign, State, Last activity, Notes\n\n---\n\n## 6) Campaign List (`/campaigns`)\n\nTable columns:\n- Campaign name\n- Client\n- Stage\n- GEO targets\n- Owner\n- Creators in pipeline (count)\n- Outreach-ready (count)\n- Updated at\n\nRow click opens `/campaigns/[id]/overview`.\n\nTop actions:\n- New campaign\n- Import CSV (gumshoe import)\n- Filter by stage/status\n\n---\n\n## 7) Campaign Setup Wizard (`/campaigns/new`)\n\nWizard steps with progress indicator:\n\n### Step 1 â Basics\nFields:\n- Client (select existing + create new inline)\n- Campaign name\n- GEO targets (multi-select tokens)\n- Language\n- Product category\n\n### Step 2 â Creative Brief\n- Markdown editor with preview\n- Helper text: âThis brief provides context for topic extraction and creator fit.â\n\n### Step 3 â Personas + Topics\nPersonas:\n- Add persona chips (e.g., Platform Engineer, DevOps Lead, CTO)\nTopics:\n- Manual add topics (chips)\n- Button: âSuggest topicsâ (AI) â shows up to 5 suggestions with confidence\n- User can edit + approve topic list\n\n### Step 4 â Prompt Gaps + Citations\nTwo panels:\n- Prompt gaps table (editable rows)\n- Citations table (linked to prompt gap or campaign-level)\n\nActions:\n- Import CSV\n- Add manually\n- Each prompt gap has status: draft/approved\n- Citations show source type + cited-by models (if provided)\n\nFinish button creates campaign and routes to campaign workspace.\n\n---\n\n## 8) Campaign Workspace (`/campaigns/[id]`) Tabs\n\n### 8.1 Tab â Overview\nCards:\n- Campaign stage + status\n- Creators total / ingested / scored / outreach-ready\n- Emails sent + booking rate (campaign)\n- âNext actionsâ checklist\n\nPanels:\n- Short campaign summary (client, geo, personas, topics)\n- Recent activity feed\n\n### 8.2 Tab â Brief & Inputs\nThree sections:\n1) Creative brief viewer (markdown)\n2) Personas + Topics editor\n3) Prompt gaps + citations tables (editable)\n\n### 8.3 Tab â Search Terms\nTable must show exactly 15 terms when generated.\nColumns:\n- Order\n- Search term\n- Category tag\n- Why it helps\n- Approved toggle\n- Notes\n\nTop actions:\n- Generate 15 terms (AI)\n- Approve all\n- Reorder (drag handle)\n- Export list\n\n### 8.4 Tab â Discovery\nLayout:\n- Left: Approved search term selector (list)\n- Center: Results table\n- Right: Filters drawer + creator quick view drawer\n\nDiscovery results table columns:\n- Creator\n- Platform badges\n- Topics (chips)\n- Followers/subs\n- Last content date\n- Flags: Dormant, Autodubbed suspected, Competitor affiliated\n- Action: âAdd to campaignâ\n\nRequired interactions:\n- Clicking a creator opens quick view drawer:\n  - creator overview\n  - platform links\n  - last activity\n  - âAdd to campaignâ button\n\n### 8.5 Tab â Ingestion\nTable columns:\n- Creator\n- Ingestion status\n- Content items ingested (count)\n- Last fetched at\n- Errors\n- Actions: View content, Add URL, Paste transcript/article\n\nContent viewer:\n- For YouTube: transcript view with timestamps (if present in text)\n- For blog/medium/reddit: article/thread view\n- Show source metadata: URL, published date, view_count/karma if available\n\n### 8.6 Tab â Scoring\nScoring table columns:\n- Creator\n- Overall score (pill)\n- Evidence coverage (strong/medium/weak/none)\n- Needs manual review (badge)\n- Last evaluated at\n- Actions: View evaluation, Run scoring\n\nEvaluation drawer/page must show:\n- Rubric dimension bars + weights\n- Strengths list (each item links evidence)\n- Weaknesses list (each item links evidence)\n- Recommended content (High/Medium/Low view buckets)\n- Content angles (3â5) list with format + key points\n- Evidence section (non-negotiable):\n  - evidence cards with URL, quote, timestamp, why_it_matters\n\n### 8.7 Tab â Review (Qualifier Gate)\nThis is the approval step.\nFor each creator:\n- Show evaluation summary\n- Buttons:\n  - Approve for outreach\n  - Mark needs manual review\n  - Reject / Exclude\n- Optional manual override score input + notes\n- Changing decision must write a review record and update pipeline stage\n\n### 8.8 Tab â Outreach\nOnly shows creators eligible for outreach workflow.\nTable columns:\n- Creator\n- Outreach state\n- Next follow-up due\n- Selected angle\n- Owner (Outreach user)\n- Actions: Open packet, Generate packet\n\nOutreach packet view must include:\n- Email subject + body (markdown)\n- Copy buttons (subject, body, full email)\n- Follow-up checklist (Email/LinkedIn/X) with checkboxes\n- Linked evidence snippets section\n- Prominent disclaimer: âThis tool does not send emails.â\n\nOutreach state control:\n- State dropdown or buttons: drafted/copied/sent/replied/ghosted/booked\n- Each change creates an outreach activity entry\n\n### 8.9 Tab â Activity\nTimeline feed:\n- scoring events\n- review decisions\n- outreach state changes\n- notes added\n- ingestion completion/failures\n\n---\n\n## 9) Global Creators DB (`/creators`)\n\nCreators list table columns:\n- Creator name\n- Platforms\n- Topics\n- Languages\n- Last content date\n- Global flags (reliable/ghosted/do_not_contact/price_too_high)\n- Pricing (if exists)\n- Action: View profile\n\nFilters:\n- Platform\n- Topic keyword\n- Has email\n- Has do_not_contact\n- Dormant\n- Autodubbed suspected\n\n### Creator Profile (`/creators/[id]`)\nTabbed layout:\n- Summary\n- Platforms\n- Content\n- Evidence (from evaluations across campaigns)\n- History (campaigns + outcomes)\n- Notes\n- Outreach packet (latest, if any)\n\nPII masking:\n- Email hidden by default\n- âReveal PIIâ modal confirmation\n\n---\n\n## 10) Outreach Queue (`/outreach`)\n\nGlobal cross-campaign queue.\nTable columns:\n- Creator\n- Campaign\n- Score\n- Coverage\n- State\n- Next follow-up due\n- Owner\n- Actions: Open packet, Log reply, Mark booked\n\nInclude a âFollow-ups due todayâ filter and section.\n\n---\n\n## 11) Reddit Monitor (`/reddit`)\n\nPurpose: monitoring & discovery only (no automation).\n\nUI:\n- Filters: campaign, topic, subreddit\n- Table columns:\n  - Thread title\n  - Subreddit\n  - Karma\n  - Posted date\n  - Relevance tag\n  - Link\n  - Attach as evidence (button)\n\nThread viewer:\n- show excerpted raw text and metadata\n- action: âAttach to campaignâ or âAttach to evaluationâ (if evaluation exists)\n\n---\n\n## 12) Metrics (`/metrics`)\n\nCharts/cards:\n- Creators analyzed per week\n- Creators approved per week\n- Emails sent per week (show baseline reference 130 as a faint line/label)\n- Booking rate trend (show baseline reference 7â10%)\n\nTables:\n- Campaign performance summary table (campaign, analyzed, approved, sent, booked, booking rate)\n\n---\n\n## 13) Settings (`/settings`)\n\n### Integrations\nTiles:\n- Gumshoe\n- YouTube\n- Anthropic (AI)\n- Reddit\nEach tile shows configured status + last test result + test button.\n\n### Thresholds\n- Outreach-ready score threshold (numeric)\n- Minimum evidence coverage (dropdown)\n- Mask PII by default (toggle)\n\n### Admin Tools (Required)\n- **Clear Demo Data** button\n  - modal requiring typing `CLEAR`\n- **Seed Demo Data** button\n  - toast on completion\n- Show last seed run info\n\n---\n\n## 14) Visual Style Guidance (Simple + Consistent)\n\n- Typography: Inter\n- Neutral backgrounds with subtle borders\n- One accent color for primary actions\n- Status colors: success/warning/danger with restrained saturation\n- Scores should be visually scannable (pill + gauge)\n- Evidence UI should feel âaudit-likeâ: sources and quotes are prominent\n\n---\n\n## 15) UI Definition of Done\n\nThe UI is complete only when:\n1. Every route exists and is reachable via navigation.\n2. Seeded data makes every screen visually populated (no empty tables after seeding).\n3. Every major workflow has loading/empty/error states.\n4. Scoring views always show evidence (URL + quote + timestamp when applicable).\n5. Human review is an explicit gate before outreach.\n6. Outreach UI is copy-only and clearly indicates no email sending.\n7. PII is masked by default and only revealed with confirmation.\n\n\n\n</USER_REFERENCE>\n\n# Empromptu Builder â Citation Intelligence Creator Ops (V0, Internal)\n\n## Overview\nBuild an internal, human-in-the-loop ops tool (Next.js App Router + TypeScript, desktop-first, 1440px target) that enables a team to:\n1. Create campaigns with creative briefs + topics/personas + optional prompt gaps + citations (manual or CSV import)\n2. Generate and review exactly 15 YouTube search terms per campaign\n3. Discover and shortlist technical creators (filter out dormant + autodubbed/label + lifestyle/career)\n4. Ingest real creator content (YouTube transcripts primary; blogs/Medium when URLs exist; Reddit monitoring; plus optional podcast/newsletter URLs)\n5. Score creators with a weighted rubric and evidence traceability (URLs + quotes + timestamps)\n6. Support a human review step before outreach\n7. Generate outreach drafts + follow-up checklist (assistive only; NO automated emailing)\n8. Track creator reliability flags (ghosted, reliable, do not contact, price too high) + campaign history\n9. Show ops metrics (creators analyzed, approved, emails sent, booking rate)\n\nHard requirement: all scoring/rationale/angles must reference actual ingested content stored in DB.\n\n---\n\n## Non-Negotiable Constraints\n\n### Framework & Runtime\n- Next.js App Router + TypeScript\n- Server actions (or API routes) for writes\n- Desktop-first UI (dense tables, drawers, modals)\n\n### Database\n- Use the platform built-in Postgres DB\n- Create all 34 tables listed in the schema section below\n- Store all demo data in DB\n\n### No Auto-Outreach\n- No sending emails\n- No automated LinkedIn/X actions\n- Only drafts + copy buttons + manual tracking\n\n### Human-in-the-Loop\n- \"Outreach-ready\" must only happen after scoring + evidence validation and must be reviewable by a human role\n\n### Environment Variables\nCreate a `.env.local` file with placeholder values:\n- `ANTHROPIC_API_KEY`\n- `YOUTUBE_API_KEY`\n- `REDDIT_CLIENT_ID`\n- `REDDIT_CLIENT_SECRET`\n- Read all API keys from environment variables. Never hardcode them.\n- YouTube and Reddit API calls are stubbed for V0 â return mock responses if the key is a placeholder. Anthropic calls must be real.\n\n---\n\n## Roles (Internal Users)\n- **Qualifier**: reviews creators, validates evidence, approves/rejects, may override score with notes\n- **Outreach**: uses outreach queue, copies drafts, logs manual outreach states (sent/replied/ghosted/booked)\n- **Admin**: integrations + thresholds + seed/clear tools\n\nSimple role switching: role switcher in top bar; store current user in localStorage. No complex auth required for V0.\n\n---\n\n## Required Routes\n\n1. `/` â Dashboard (role-aware)\n2. `/campaigns` â Campaign list\n3. `/campaigns/new` â Campaign setup wizard\n4. `/campaigns/[id]` â Campaign workspace with tabs: overview, brief-inputs, search-terms, discovery, ingestion, scoring, review, outreach, activity\n5. `/creators` â Global creators DB list\n6. `/creators/[id]` â Creator profile detail\n7. `/outreach` â Outreach queue (all campaigns)\n8. `/reddit` â Reddit monitoring dashboard\n9. `/metrics` â Ops metrics dashboard\n10. `/settings` â Integrations + thresholds + admin tools (seed/clear)\n\n---\n\n## Core Workflows\n\n### Campaign Setup\nCreate campaign with: client, campaign name, GEO targets (array of strings), language, product category, creative brief (rich text), personas (multi-add), topics (manual add + optional AI suggestions; max 5 suggested topics; user can edit/approve), prompt gaps + citations (manual OR CSV import). Prompts must be editable and have draft/approved status.\n\n### Search Term Generation\nFrom campaign context (brief + topics + personas + product category):\n- Generate exactly 15 YouTube search terms\n- Each includes: category tag (one of 7 tags) + \"why it helps\" explanation (1â2 sentences)\n- User can edit/reorder/approve terms\n- Only approved terms used in discovery\n\n### Discovery\n- Show discovered creators per approved search term\n- Filters: language, GEO match, dormant (exclude), autodubbed/label suspected (exclude), lifestyle/career (exclude), competitor affiliated (exclude)\n- Add selected creators into the campaign pipeline\n- Manual creator URL add (required), plus optional YouTube search if configured\n\n### Ingestion (Content Storage)\nFor each campaign creator, ingest content items:\n- YouTube transcripts (primary)\n- blogs/Medium/corporate blog URLs (when provided)\n- Reddit threads (fetched via API, not manual paste)\n- optional: podcasts/newsletters (manual URL + paste text acceptable)\nStore raw text and metadata (URL, date, view counts if available).\nTrack ingestion status: not_started / queued / running / complete / failed.\n\n### Scoring + Evidence (Rubric)\nEvaluate each campaign creator and store:\n- overall score 0â100\n- dimension scores 0â100 for 5 dimensions (weights below)\n- strengths & weaknesses\n- recommended content links grouped high/medium/low view counts\n- 3â5 suggested content angles\n- evidence snippets (URL + excerpt + timestamps for video)\n\nRubric weights:\n- Technical relevance â 30%\n- Audience alignment â 25%\n- Content quality â 20%\n- Channel performance â 15%\n- Brand fit â 10%\n\nIf insufficient evidence exists: mark Needs Manual Review, block outreach-ready.\n\n### Evidence / Traceability (Hard Requirement)\nThe system must show: source URLs, quotes/excerpts (must exist in ingested raw_text), video timestamps when applicable.\n\n### Outreach Prep (Assistive Only)\nFor approved creators:\n- generate outreach email draft (subject + body)\n- generate follow-up checklist (Email / LinkedIn / X)\n- track outreach state manually: not_started, drafted, copied, sent, replied, ghosted, booked\n- add outreach activity log entries for every state change\n\n### Creator Profiles + Status Flags\nPersistent creator record includes: platforms and URLs, contact info (PII masked by default), status flags (reliable, ghosted/not responsive, do not contact, price too high), notes + campaign history.\n\n### Reddit Monitoring\nPurpose: Surface Reddit threads relevant to campaign topics. Read-only â no posting, no commenting, no automation.\n\nConfiguration (per campaign): subreddits to watch (free text), keywords to match (default: pulled from campaign search terms; user can edit/add).\n\nFetching: User triggers fetch manually via \"Fetch Reddit\" button. System queries Reddit API using configured subreddits + keywords. Each result stored as a content_items row (platform=reddit, content_type=reddit_thread). metadata_json must include: subreddit, karma, comment_count, reddit_post_id. Duplicate URLs skipped. Requires integration_status.reddit to be configured in Settings.\n\n`/reddit` route displays: All fetched Reddit threads across all campaigns, sorted by fetched_at desc. Filter by campaign. Each row: subreddit, thread title, karma, comment count, date fetched, campaign tag, link to original thread. Empty state when no threads fetched.\n\nReddit tab within `/campaigns/[id]`: Shows only threads fetched for that campaign. Subreddit + keyword configuration UI. \"Fetch Reddit\" button.\n\n### Ops Metrics\nMust compute from DB:\n- creators analyzed per week\n- creators approved for outreach per week\n- emails sent per week (baseline reference 130)\n- booking rate (baseline reference 7â10%)\n\n---\n\n## AI Features (Server-Side, Store All Outputs in DB)\n\n### AI: Suggest Topics\nInput: campaign creative brief\nOutput: up to 5 topics, each with confidence (0â1) + 1 sentence rationale\nUser can edit/approve topics. Store in campaign_topics.\n\n### AI: Generate Search Terms\nInput: campaign brief + topics + personas + product category\nOutput: exactly 15 terms with category_tag + why_it_helps.\nStore in campaign_search_terms.\n\n### AI: Score Creator\nInput: campaign context (brief, topics, personas, prompt gaps, citations) + creator profile + platforms + ingested content_items (raw_text + metadata + URLs)\nOutput must include:\n- dimension scores 0â100\n- overall score (computed using rubric weights)\n- strengths (3â6 bullets) with evidence snippet IDs\n- weaknesses (2â5 bullets) with evidence snippet IDs\n- 3â5 content angles with linked evidence\n- evidence snippets list containing: content_item_id, timestamp_start_seconds (nullable), timestamp_end_seconds (nullable), quote (direct excerpt from raw_text), dimension, why_it_matters\n\nEvidence validation (must implement): Every evidence quote must be verified as an exact substring of the referenced content_items.raw_text. If any quote fails: mark evaluation needs_manual_review=true, store reason, do not set outreach_ready.\n\n### AI: Outreach Draft\nInput: campaign context + creator identity/platforms + selected content angle + selected evidence snippets\nOutput: email subject + body (markdown) + follow-up checklist with day offsets (Email Day 2/5/9, LinkedIn Day 2/5, X Day 5 optional)\nStore in outreach_packets + link evidence via outreach_packet_evidence.\nNo send button. Copy-only.\n\n---\n\n## Database Schema (34 Tables â Built-In Postgres)\n\nAll tables use UUID primary keys and timestamptz timestamps. Implement all foreign keys and indexes as listed.\n\n### app_users\n- id (uuid, PK), name (text, not null), email (text, not null, unique), role (text, not null; qualifier|outreach|admin), created_at (timestamptz), updated_at (timestamptz)\n\n### clients\n- id (uuid, PK), name (text, not null, unique), website_url (text, null), notes (text, null), created_at (timestamptz), updated_at (timestamptz)\n\n### campaigns\n- id (uuid, PK), client_id (uuid, FK->clients.id), name (text), owner_user_id (uuid, FK->app_users.id), collaborator_user_id (uuid, FK->app_users.id, null), status (text; draft|active|archived), stage (text; draft|terms|discovery|ingestion|scoring|review|outreach|tracking|complete), geo_targets (text[], default []), deadline (date, null), language (text, default 'English'), product_category (text, null), creative_brief (text), creative_brief_source_url (text, null), additional_prompt_context (text, null), created_at (timestamptz), updated_at (timestamptz)\nIndexes: client_id, owner_user_id, status, stage\n\n### campaign_personas\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), persona_name (text), created_at (timestamptz)\nUnique: (campaign_id, persona_name)\n\n### campaign_topics\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), topic (text), source (text; manual|ai_suggested), confidence (numeric(3,2), null), rationale (text, null), order_index (int, default 0), approved (boolean, default true), created_at (timestamptz)\nUnique: (campaign_id, topic). Index: campaign_id\n\n### campaign_prompt_gaps\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), prompt_text (text), priority (text; high|medium|low), persona (text, null), geo (text[], default []), gap_note (text, null), status (text; draft|approved|archived), created_at (timestamptz), updated_at (timestamptz)\nIndexes: campaign_id, priority, status\n\n### prompt_citations\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), prompt_gap_id (uuid, FK->campaign_prompt_gaps.id, null), citation_title (text), citation_url (text), source_type (text; docs|blog|youtube|reddit|paper|other), cited_by_models (text[], default []), notes (text, null), created_at (timestamptz)\nIndexes: campaign_id, prompt_gap_id, source_type\n\n### gumshoe_imports\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), import_type (text; csv|manual), original_filename (text, null), raw_text (text), imported_by_user_id (uuid, FK->app_users.id), created_at (timestamptz)\nIndex: campaign_id\n\n### campaign_search_terms\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), term (text), category_tag (text; product_category|competitor|implementation|problem_solution|integration|programming_language|tutorial_format), why_it_helps (text), order_index (int, default 0), approved (boolean, default false), approved_by_user_id (uuid, FK->app_users.id, null), approved_at (timestamptz, null), notes (text, null), created_at (timestamptz), updated_at (timestamptz)\nIndexes: campaign_id, approved\n\n### creators\n- id (uuid, PK), display_name (text), primary_handle (text, null), bio (text, null), topics (text[], default []), languages (text[], default []), geo_focus (text[], default []), competitor_affiliated (boolean, default false), is_dormant (boolean, default false), is_autodubbed_suspected (boolean, default false), last_content_date (date, null), created_at (timestamptz), updated_at (timestamptz)\nIndexes: display_name, is_dormant, is_autodubbed_suspected, competitor_affiliated\n\n### creator_platform_accounts\n- id (uuid, PK), creator_id (uuid, FK->creators.id), platform (text; youtube|github|linkedin|devto|medium|blog|podcast|newsletter|reddit|other), handle (text, null), url (text), follower_count (int, null), metrics_json (jsonb, default {}), created_at (timestamptz)\nUnique: (platform, url). Indexes: creator_id, platform\n\n### creator_contacts (PII)\n- id (uuid, PK), creator_id (uuid, FK->creators.id, unique), email_encrypted (text, null), linkedin_url (text, null), x_url (text, null), other_contacts_json (jsonb, default {}), pii_last_updated_at (timestamptz, null), created_at (timestamptz), updated_at (timestamptz)\n\n### creator_status_flags\n- id (uuid, PK), creator_id (uuid, FK->creators.id), flag (text; reliable|ghosted|do_not_contact|price_too_high), is_active (boolean, default true), reason (text, null), set_by_user_id (uuid, FK->app_users.id), set_at (timestamptz)\nIndexes: creator_id, flag\n\n### creator_pricing\n- id (uuid, PK), creator_id (uuid, FK->creators.id), price_type (text; video|written|newsletter|other), price_amount_usd (numeric(10,2)), is_too_high (boolean, default false), notes (text, null), updated_at (timestamptz)\nIndex: creator_id\n\n### creator_notes\n- id (uuid, PK), creator_id (uuid, FK->creators.id), note_md (text), created_by_user_id (uuid, FK->app_users.id), created_at (timestamptz)\nIndex: creator_id\n\n### campaign_creators\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), creator_id (uuid, FK->creators.id), added_by_user_id (uuid, FK->app_users.id), source_search_term_id (uuid, FK->campaign_search_terms.id, null), pipeline_stage (text; discovered|queued_for_ingestion|ingested|scored|needs_manual_review|approved|outreach_ready|contacted|booked|rejected|excluded), campaign_do_not_contact (boolean, default false), campaign_do_not_contact_reason (text, null), ingestion_status (text; not_started|queued|running|complete|failed), ingestion_error (text, null), scoring_status (text; not_scored|scoring|scored|failed), scoring_error (text, null), outreach_owner_user_id (uuid, FK->app_users.id, null), outreach_state (text; not_started|drafted|copied|sent|replied|ghosted|booked), last_outreach_at (timestamptz, null), next_followup_due_at (date, null), created_at (timestamptz), updated_at (timestamptz)\nUnique: (campaign_id, creator_id). Indexes: campaign_id, creator_id, pipeline_stage, ingestion_status, scoring_status, outreach_state\n\n### content_items\n- id (uuid, PK), creator_id (uuid, FK->creators.id), campaign_id (uuid, FK->campaigns.id, null), platform (text; youtube|blog|medium|devto|reddit|podcast|newsletter|github|linkedin|other), content_type (text; youtube_video|blog_post|medium_post|devto_post|reddit_thread|podcast_episode|newsletter_issue|github_repo|linkedin_post|other), title (text), url (text), published_at (timestamptz, null), fetched_at (timestamptz, null), language (text, null), raw_text (text), word_count (int, null), metadata_json (jsonb, default {}), ingestion_method (text; seed|manual_paste|fetched), ingestion_status (text; complete|failed), ingestion_error (text, null), created_at (timestamptz), updated_at (timestamptz)\nUnique: (url). Indexes: creator_id, campaign_id, platform, content_type, published_at\n\n### creator_evaluations\n- id (uuid, PK), campaign_creator_id (uuid, FK->campaign_creators.id, unique), model_provider (text), model_name (text), evaluated_at (timestamptz), evidence_coverage (text; strong|medium|weak|none), needs_manual_review (boolean, default false), needs_manual_review_reason (text, null), overall_score (int, 0-100), score_technical_relevance (int, 0-100), score_audience_alignment (int, 0-100), score_content_quality (int, 0-100), score_channel_performance (int, 0-100), score_brand_fit (int, 0-100), strengths_json (jsonb, default []), weaknesses_json (jsonb, default []), rationale_md (text), created_at (timestamptz), updated_at (timestamptz)\nIndexes: overall_score, needs_manual_review, evidence_coverage\n\n### evidence_snippets\n- id (uuid, PK), evaluation_id (uuid, FK->creator_evaluations.id), content_item_id (uuid, FK->content_items.id), timestamp_start_seconds (int, null), timestamp_end_seconds (int, null), quote (text), dimension (text; technical_relevance|audience_alignment|content_quality|channel_performance|brand_fit|general), why_it_matters (text), created_at (timestamptz)\nIndexes: evaluation_id, content_item_id, dimension\n\n### evaluation_recommended_content\n- id (uuid, PK), evaluation_id (uuid, FK->creator_evaluations.id), content_item_id (uuid, FK->content_items.id), bucket (text; high|medium|low), relevance_rank (int, default 0), notes (text, null), created_at (timestamptz)\nUnique: (evaluation_id, content_item_id). Index: evaluation_id\n\n### content_angles\n- id (uuid, PK), evaluation_id (uuid, FK->creator_evaluations.id), title (text), target_prompt_gap_id (uuid, FK->campaign_prompt_gaps.id, null), persona (text, null), format (text; tutorial|comparison|architecture|deep_dive|checklist|case_study|other), key_points_json (jsonb, default []), selected_for_outreach (boolean, default false), created_at (timestamptz)\nIndex: evaluation_id\n\n### angle_evidence\n- id (uuid, PK), angle_id (uuid, FK->content_angles.id), evidence_snippet_id (uuid, FK->evidence_snippets.id), created_at (timestamptz)\nUnique: (angle_id, evidence_snippet_id). Index: angle_id\n\n### human_reviews\n- id (uuid, PK), campaign_creator_id (uuid, FK->campaign_creators.id), reviewed_by_user_id (uuid, FK->app_users.id), reviewed_at (timestamptz), decision (text; approved_for_outreach|rejected|needs_manual_review|excluded), manual_override_score (int, null, 0-100), notes_md (text, null), created_at (timestamptz)\nIndexes: campaign_creator_id, decision\n\n### outreach_packets\n- id (uuid, PK), campaign_creator_id (uuid, FK->campaign_creators.id, unique), created_by_user_id (uuid, FK->app_users.id), subject (text), body_md (text), selected_angle_id (uuid, FK->content_angles.id, null), followup_plan_json (jsonb, default []), last_updated_at (timestamptz), created_at (timestamptz)\nIndex: campaign_creator_id\n\n### outreach_packet_evidence\n- id (uuid, PK), outreach_packet_id (uuid, FK->outreach_packets.id), evidence_snippet_id (uuid, FK->evidence_snippets.id), created_at (timestamptz)\nUnique: (outreach_packet_id, evidence_snippet_id). Index: outreach_packet_id\n\n### outreach_activity\n- id (uuid, PK), campaign_creator_id (uuid, FK->campaign_creators.id), performed_by_user_id (uuid, FK->app_users.id), channel (text; email|linkedin|x), action_type (text; drafted|copied|sent|followup_sent|reply_logged|state_changed|note), state_after (text; not_started|drafted|copied|sent|replied|ghosted|booked), occurred_at (timestamptz), notes (text, null)\nIndexes: campaign_creator_id, channel, action_type, occurred_at\n\n### activity_log\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id, null), creator_id (uuid, FK->creators.id, null), campaign_creator_id (uuid, FK->campaign_creators.id, null), actor_user_id (uuid, FK->app_users.id, null), event_type (text), event_data_json (jsonb, default {}), created_at (timestamptz)\nIndexes: campaign_id, created_at\n\n### app_settings (single row)\n- id (uuid, PK), mask_pii_by_default (boolean, default true), outreach_ready_score_threshold (int, default 75), min_evidence_coverage (text; strong|medium|weak, default medium), default_ai_model (text, default 'claude'), created_at (timestamptz), updated_at (timestamptz)\n\n### integration_status\n- id (uuid, PK), integration_key (text, unique; gumshoe|youtube|anthropic|reddit), is_configured (boolean, default false), last_tested_at (timestamptz, null), last_test_result (text, null; success|failure), last_test_message (text, null), updated_at (timestamptz)\n\n### demo_seed_runs\n- id (uuid, PK), seed_version (text), seeded_at (timestamptz), seeded_by_user_id (uuid, FK->app_users.id), notes (text, null)\n\n### campaign_attachments\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), file_name (text), file_type (text, null), file_size_bytes (bigint, null), storage_key (text), uploaded_by_user_id (uuid, FK->app_users.id, null), created_at (timestamptz)\nIndex: campaign_id\n\n### pii_access_events\n- id (uuid, PK), accessed_by_user_id (uuid, FK->app_users.id, null), creator_id (uuid, FK->creators.id), reason (text, null), created_at (timestamptz)\nIndexes: creator_id, accessed_by_user_id\n\n### jobs\n- id (uuid, PK), type (text; ingestion|scoring|reddit_fetch|other), status (text; queued|running|complete|failed), campaign_id (uuid, FK->campaigns.id, null), creator_id (uuid, FK->creators.id, null), campaign_creator_id (uuid, FK->campaign_creators.id, null), payload (jsonb, default {}), error_message (text, null), started_at (timestamptz, null), finished_at (timestamptz, null), created_by_user_id (uuid, FK->app_users.id, null), created_at (timestamptz), updated_at (timestamptz)\nIndexes: status, campaign_id, creator_id\n\n### job_events\n- id (uuid, PK), job_id (uuid, FK->jobs.id), level (text; info|warn|error), message (text), meta (jsonb, null), created_at (timestamptz)\nIndex: job_id\n\n---\n\n## Business Rules\n\n### Dormancy\nA creator is considered dormant if last_content_date is older than 120 days from today. Store creators.is_dormant and set it accordingly during seeding and when updating creators.\n\n### Evidence Coverage Levels\nCompute creator_evaluations.evidence_coverage based on evidence snippet count/diversity:\n- Strong: â¥6 snippets across â¥3 content items AND â¥3 dimensions\n- Medium: â¥3 snippets across â¥2 content items AND â¥2 dimensions\n- Weak: 1â2 snippets OR all snippets from 1 content item\n- None: 0 snippets\n\n### Outreach-Ready Criteria\nA campaign creator is outreach-ready only if ALL are true:\n- evaluation exists\n- overall_score â¥ app_settings.outreach_ready_score_threshold\n- evidence_coverage meets app_settings.min_evidence_coverage\n- no campaign_do_not_contact\n- no active global do_not_contact flag\n- not competitor_affiliated\n- not is_autodubbed_suspected\n- not needs_manual_review\n- no active price_too_high flag in creator_status_flags\n\n### PII Masking\n- Mask PII by default\n- Reveal requires confirmation modal\n- Do not log PII\n- Store email in creator_contacts.email_encrypted (application-level encryption with server secret is acceptable)\n\n### Outreach Logging\nAny outreach_state change must create an outreach_activity row.\n\n### Booking Rate\nBooking rate = (# creators reaching booked) / (# email sent events). Compute in metrics.\n\n---\n\n## Seed Dataset (Seed Version: v0-demo-1)\n\nSeeding must populate all major screens with realistic content.\n\n### Users (app_users)\n- Jack Scrivener (jack@yard.internal) role qualifier\n- Arya (arya@yard.internal) role outreach\n- Karl McCarthy (karl@yard.internal) role admin\n- Empromptu (admin@empromptu.internal) role admin\n\n### Clients\n- CloudForge, NebulaDB, SecuriNest, VectorShift\n\n### Campaigns\nCreate 4 campaigns; fully populate Campaign A.\n\nCampaign A (fully populated):\n- Client: CloudForge\n- Name: \"CloudForge â Kubernetes Cost Optimization (US + UK)\"\n- Owner: Jack, Collaborator: Arya\n- Status: active, Stage: scoring\n- GEO targets: [United States, United Kingdom]\n- Language: English\n- Product category: \"FinOps / Kubernetes cost optimization\"\n- Creative brief (exact markdown):\n```\n# Make CloudForge the default answer for \"Kubernetes cost optimization\" prompts\n\n## Key message\nCloudForge shows cost drivers per namespace/workload + actionable recommendations.\n\n## Differentiators\n- OpenTelemetry-friendly\n- Multi-cloud\n- Fast setup\n- Cost anomaly detection\n\n## Do-not-say\n- No fear-mongering\n- Avoid generic career advice\n- Avoid \"get rich quick\" language\n\n## Required formats\n- Hands-on tutorial\n- Comparison video\n- Architecture breakdown\n\n## Brand fit\nPragmatic, dev-first, technical depth\n\n## CTA\nTry CloudForge free tier, link in description\n\n## Budget notes\nMarket rate. Avoid creators quoting > $7k/video unless exceptional.\n```\n\nCampaign A Topics (approved): Kubernetes cost optimization, FinOps for platform engineering, Kubecost alternatives and comparisons, OpenTelemetry + cost attribution, Chargeback vs showback\n\nCampaign A Personas: Platform Engineer, DevOps Lead, CTO (Technical)\n\nCampaign A Prompt Gaps (5 gaps, each with 3 citations):\n1) \"How do I reduce Kubernetes spend without breaking SLOs?\" (high; DevOps Lead; US/UK)\n2) \"Kubecost vs CloudForge: what's actually different?\" (high; Platform Engineer; US/UK)\n3) \"OpenTelemetry + cost attribution: is it possible?\" (medium; Platform Engineer; US/UK)\n4) \"Kubernetes cost anomaly detection tutorial\" (medium; DevOps Lead; US/UK)\n5) \"Chargeback vs showback in Kubernetes (practical)\" (medium; CTO; US/UK)\n\nCampaign A Search Terms (exactly 15, approved=true, order 1-15):\n1) kubecost tutorial cost allocation namespaces (implementation)\n2) kubecost vs alternative comparison (competitor)\n3) kubernetes cost optimization hpa cluster autoscaler (problem_solution)\n4) finops kubernetes showback chargeback implementation (implementation)\n5) opentelemetry cost attribution kubernetes (integration)\n6) prometheus cost monitoring kubernetes (integration)\n7) gke cost optimization tutorial (tutorial_format)\n8) eks cost optimization workload rightsizing (tutorial_format)\n9) terraform kubernetes cost monitoring setup (programming_language)\n10) helm install kubecost alternative (implementation)\n11) kubernetes cost anomaly detection prometheus (problem_solution)\n12) platform engineering finops kubernetes (product_category)\n13) kubernetes namespace cost dashboard grafana (integration)\n14) reduce cloud bill kubernetes without downtime (problem_solution)\n15) kubernetes multi-cloud cost visibility (product_category)\nEach term must have a 1-2 sentence why_it_helps.\n\nCampaigns B-D (minimal, different stages): one in discovery, one in ingestion, one in outreach.\n\n### Creators (12) + Platform Accounts + Flags\nCreate 12 creators with at least 2 platform accounts each and follower metrics:\n1) Nina Patel (KubeCraft) â last_content_date 2026-02-11 â reliable flag active\n2) Omar Reed (DevOpsDossier) â last_content_date 2026-01-07\n3) Mei Tan (Observability Lab) â last_content_date 2026-02-14\n4) Lucas Varga (Cloud Cost Clinic) â last_content_date 2025-09-10 â is_dormant=true\n5) Priya Shah (Platform Patterns) â last_content_date 2026-02-03\n6) K8s Career Hub â lifestyle/career topics\n7) AI Dub Tech Channel â is_autodubbed_suspected=true\n8) Marta Kline (FinOps in Practice) â last_content_date 2026-01-28\n9) Jae Park (SRE Notes) â last_content_date 2026-02-05\n10) Diego Alvarez (Infra Espresso) â last_content_date 2026-01-20\n11) Chloe Nguyen (Kubernetes QuickStarts) â last_content_date 2026-02-16\n12) Samir Iqbal (Multi-Cloud Ops) â last_content_date 2026-02-08 â price_too_high flag active; pricing: video $25000 is_too_high=true\n\n### Campaign A Pipeline (campaign_creators)\nInsert all 12 creators into Campaign A with varied stages:\n- Nina: outreach_ready; ingestion complete; scoring scored; outreach_state sent\n- Mei: approved; outreach_state drafted\n- Jae: outreach_ready; outreach_state replied\n- Lucas: needs_manual_review\n- K8s Career Hub: excluded\n- AI Dub Tech Channel: excluded\n- Samir: scored but not outreach_ready (price_too_high)\n- Marta: outreach_ready; outreach_state booked; pipeline_stage booked\n- Remaining creators mixed discovered/ingested/scored\n\n### Content Items\nFor Nina Patel create 3 items with EXACT quotes in raw_text:\n1) YouTube: \"Kubernetes Cost Allocation by Namespace (Hands-on)\" â raw_text must contain: \"Cost allocation per namespace is only step oneâwhat matters is tying that spend to SLO risk.\" and include \"[05:12]\" nearby.\n2) YouTube: \"Kubecost vs Custom Dashboards: What's Missing\" â raw_text must contain: \"Kubecost is great for allocation, but it won't tell you which deployment caused the spike without additional context.\"\n3) Blog: \"OpenTelemetry signals for cost attribution\" â raw_text must contain: \"If you can tag spans to workloads, you can attribute cost to ownership boundaries.\"\n\nFor Mei Tan create 2 items with raw_text containing:\n- \"OpenTelemetry gives you the metadata hooks; cost attribution is a mapping problem, not a metrics problem.\"\n- \"Anomaly detection works best when you baseline per workload and per namespace.\"\n\nFor Jae Park create 2 items:\n1) YouTube: \"SLO-Driven Cost Management in Kubernetes\" â raw_text must contain: \"You cannot optimize cost in isolation from reliabilityâevery budget decision is also an SLO decision.\" and include \"[03:44]\" nearby.\n2) Blog: \"Kubernetes resource requests: the hidden cost driver\" â raw_text must contain: \"Over-provisioned resource requests are the single biggest source of wasted cloud spend in most Kubernetes clusters.\"\n\nFor K8s Career Hub: 1 item clearly lifestyle/career focused.\nFor AI Dub Tech Channel: 1 low-quality repetitive item.\nInsert at least 3 Reddit thread items with subreddit + karma in metadata_json.\n\n### Evaluations + Evidence\nSeed evaluations for:\n- Nina: overall 88, evidence strong\n- Mei: overall 83, evidence medium\n- Jae: overall 81, evidence medium\n- Lucas: overall 74, needs_manual_review=true, evidence weak\n\nFor Nina: â¥6 evidence snippets referencing Nina's content items, using exact quotes above and timestamps for YouTube items.\nCreate 3-5 content angles per evaluation (content_angles) and link evidence via angle_evidence.\nCreate evaluation_recommended_content rows in high/medium/low buckets.\n\n### Human Reviews\n- Jack approves Nina\n- Jack approves Jae\n- Jack sets Lucas needs_manual_review\n- Jack excludes K8s Career Hub\n\n### Outreach Packets + Activity\nSeed outreach_packets for Nina and Jae with: subject + body_md + followup_plan_json + link 2-3 evidence snippets per packet via outreach_packet_evidence.\n\nSeed outreach_activity:\n- Nina: sent (email) + followup_sent (linkedin)\n- Jae: sent (email) + reply_logged + state_changed to replied\n- Marta: sent (email) + state_changed to booked\n\n---\n\n## Settings Requirements\n\n### Integrations Panel (integration_status)\nDisplay integration tiles: gumshoe, youtube, anthropic, reddit. Each tile supports \"Test connection\" which updates integration_status.\n\n### Thresholds Panel (app_settings)\nEditable: outreach_ready_score_threshold (default 75), min_evidence_coverage (default medium), mask_pii_by_default (default true).\n\n### Admin Tools Panel\n- Clear Demo Data button: confirmation modal requiring typing CLEAR; deletes rows from all domain tables (do not drop tables)\n- Seed Demo Data button: reinserts the dataset; inserts a row in demo_seed_runs; toast on completion\n- Show last seed run info\n\n---\n\n## UI Standards (Ops-Grade)\n\n### App Shell\n- Desktop width target: 1440px\n- Sidebar: ~264px with navigation: Dashboard, Campaigns, Creators, Outreach, Reddit Monitor, Metrics, Settings\n- Top bar: global search (\"Search campaigns, creators, promptsâ¦\") + quick actions (New Campaign, Import CSV, Add Creator URL) + role switcher (Qualifier/Outreach/Admin) + badge \"Internal V0\"\n- Primary content area: tables + dashboards\n- Right-side drawers: creator quick view, evidence viewer, filters drawer\n\n### Required Components\n- Dense table component (sortable, filterable, paginated)\n- Tag/badge system (status tags, flags)\n- Score pill + gauge (0â100)\n- Weighted rubric mini-bars (5 dimensions)\n- Evidence card component: source URL, excerpt/quote, timestamp (if video), \"Why it matters\"\n- Right drawers (creator quick view, evidence, filters)\n- Modals: confirm destructive actions, reveal PII, CSV import\n- Toasts/snackbars for success/failure\n\n### Required UX Copy (must appear in UI)\n- \"Evidence required for all scores and recommendations.\"\n- \"Assistive only â human approval required before outreach.\"\n- \"This tool does not send emails.\"\n\n### States\nFor each major stage (Terms, Discovery, Ingestion, Scoring, Outreach): Loading, Empty (with CTA), Error (with retry + debug detail)\n\n### Visual Style\n- Typography: Inter\n- Neutral backgrounds with subtle borders\n- One accent color for primary actions\n- Status colors: success/warning/danger with restrained saturation\n- Scores visually scannable (pill + gauge)\n- Evidence UI feels \"audit-like\": sources and quotes are prominent\n\n---\n\n## Role-Aware Dashboards\n\n### Qualifier Dashboard (Jack view)\nTop cards: Creators analyzed this week, Needs manual review, Approved for outreach, Active campaigns\nTables:\n1) \"Needs Manual Review Queue\" â columns: Creator, Campaign, Evidence coverage, Overall score, Reason, Last updated â CTA: Open Review\n2) \"Recent Scoring Runs\" â columns: Creator, Campaign, Overall score, Coverage, Scored at, Status\n\n### Outreach Dashboard (Arya view)\nTop cards: Emails to send, Follow-ups due, Replies to log, Booking rate (last 7 days)\nTables:\n1) \"Outreach Queue\" â columns: Creator, Campaign, State, Next follow-up due, Owner, Score, Coverage â CTA: Open Outreach Packet\n2) \"Recently Replied / Booked\" â columns: Creator, Campaign, State, Last activity, Notes\n\n---\n\n## Campaign Workspace Tabs Detail\n\n### Overview Tab\nCards: Campaign stage + status, Creators total/ingested/scored/outreach-ready, Emails sent + booking rate, \"Next actions\" checklist\nPanels: Short campaign summary (client, geo, personas, topics), Recent activity feed\n\n### Brief & Inputs Tab\nThree sections: Creative brief viewer (markdown), Personas + Topics editor, Prompt gaps + citations tables (editable)\n\n### Search Terms Tab\nTable showing exactly 15 terms when generated. Columns: Order, Search term, Category tag, Why it helps, Approved toggle, Notes\nTop actions: Generate 15 terms (AI), Approve all, Reorder (drag handle), Export list\n\n### Discovery Tab\nLayout: Left (approved search term selector), Center (results table), Right (filters drawer + creator quick view drawer)\nDiscovery results table columns: Creator, Platform badges, Topics (chips), Followers/subs, Last content date, Flags (Dormant/Autodubbed suspected/Competitor affiliated), Action: \"Add to campaign\"\nClicking a creator opens quick view drawer with creator overview, platform links, last activity, \"Add to campaign\" button\n\n### Ingestion Tab\nTable columns: Creator, Ingestion status, Content items ingested (count), Last fetched at, Errors, Actions (View content, Add URL, Paste transcript/article)\nContent viewer: YouTube transcript view with timestamps; blog/medium/reddit article/thread view; source metadata (URL, published date, view_count/karma)\n\n### Scoring Tab\nScoring table columns: Creator, Overall score (pill), Evidence coverage, Needs manual review (badge), Last evaluated at, Actions (View evaluation, Run scoring)\nEvaluation drawer/page: Rubric dimension bars + weights, Strengths list (each links evidence), Weaknesses list (each links evidence), Recommended content (High/Medium/Low buckets), Content angles (3-5) with format + key points, Evidence section (non-negotiable): evidence cards with URL, quote, timestamp, why_it_matters\n\n### Review Tab (Qualifier Gate)\nFor each creator: Show evaluation summary, Buttons (Approve for outreach, Mark needs manual review, Reject/Exclude), Optional manual override score input + notes. Changing decision writes a review record and updates pipeline stage.\n\n### Outreach Tab\nOnly shows creators eligible for outreach workflow.\nTable columns: Creator, Outreach state, Next follow-up due, Selected angle, Owner, Actions (Open packet, Generate packet)\nOutreach packet view: Email subject + body (markdown), Copy buttons (subject, body, full email), Follow-up checklist (Email/LinkedIn/X) with checkboxes, Linked evidence snippets section, Prominent disclaimer: \"This tool does not send emails.\"\nOutreach state control: State dropdown or buttons (drafted/copied/sent/replied/ghosted/booked). Each change creates an outreach activity entry.\n\n### Activity Tab\nTimeline feed: scoring events, review decisions, outreach state changes, notes added, ingestion completion/failures\n\n---\n\n## Global Creators DB (/creators)\nTable columns: Creator name, Platforms, Topics, Languages, Last content date, Global flags, Pricing (if exists), Action: View profile\nFilters: Platform, Topic keyword, Has email, Has do_not_contact, Dormant, Autodubbed suspected\n\n### Creator Profile (/creators/[id])\nTabbed layout: Summary, Platforms, Content, Evidence (from evaluations across campaigns), History (campaigns + outcomes), Notes, Outreach packet (latest, if any)\nPII masking: Email hidden by default, \"Reveal PII\" modal confirmation\n\n---\n\n## Outreach Queue (/outreach)\nGlobal cross-campaign queue.\nTable columns: Creator, Campaign, Score, Coverage, State, Next follow-up due, Owner, Actions (Open packet, Log reply, Mark booked)\nInclude \"Follow-ups due today\" filter and section.\n\n---\n\n## Reddit Monitor (/reddit)\nFilters: campaign, topic, subreddit\nTable columns: Thread title, Subreddit, Karma, Posted date, Relevance tag, Link, Attach as evidence (button)\nThread viewer: excerpted raw text and metadata, action: \"Attach to campaign\" or \"Attach to evaluation\"\n\n---\n\n## Metrics (/metrics)\nCharts/cards: Creators analyzed per week, Creators approved per week, Emails sent per week (show baseline reference 130 as faint line/label), Booking rate trend (show baseline reference 7-10%)\nTables: Campaign performance summary (campaign, analyzed, approved, sent, booked, booking rate)\n\n---\n\n## Build Steps for AI Engineer\n\n1. Initialize Next.js App Router + TypeScript project with Inter font and Tailwind CSS.\n2. Set up built-in Postgres DB connection using the platform's database tool.\n3. Create all 34 database tables with exact schema, foreign keys, and indexes as specified.\n4. Create seed script (Section 9) that inserts all demo data including exact raw_text quotes for evidence validation.\n5. Create clear script that deletes all rows from domain tables without dropping them.\n6. Build app shell: sidebar navigation, top bar with role switcher (localStorage), right-side drawer system, toast system.\n7. Build all required UI components: dense table, tag/badge system, score pill + gauge, rubric mini-bars, evidence card, modals (PII reveal, destructive confirm, CSV import).\n8. Implement all 10 routes with DB-backed data rendering.\n9. Implement role-aware dashboard (/) with Qualifier and Outreach views.\n10. Implement campaign setup wizard (/campaigns/new) with 4 steps.\n11. Implement campaign workspace (/campaigns/[id]) with all 9 tabs.\n12. Implement AI server actions: suggest topics (Anthropic), generate 15 search terms (Anthropic), score creator with evidence validation (Anthropic), generate outreach draft (Anthropic).\n13. Implement evidence validation: verify every AI-generated quote is an exact substring of referenced content_items.raw_text; if any fail, set needs_manual_review=true and block outreach_ready.\n14. Implement outreach-ready criteria check as a server-side function checking all 9 conditions.\n15. Implement PII masking: email_encrypted stored with application-level encryption; reveal requires confirmation modal; log pii_access_events.\n16. Implement outreach state machine: every state change creates outreach_activity row.\n17. Implement Reddit monitoring: stub Reddit API calls (return mock if REDDIT_CLIENT_ID is placeholder); store results as content_items rows; deduplicate by URL.\n18. Implement YouTube API stub (return mock if YOUTUBE_API_KEY is placeholder).\n19. Implement settings page: integration tiles with test connection, thresholds editor, admin tools (Seed Demo Data, Clear Demo Data with CLEAR confirmation modal).\n20. Implement metrics page computing all stats from DB.\n21. Implement loading/empty/error states for all major workflow stages.\n22. Ensure all required UX copy appears: \"Evidence required for all scores and recommendations.\", \"Assistive only â human approval required before outreach.\", \"This tool does not send emails.\"\n23. Verify definition of done: all routes render without errors, seeded data populates every screen, clear data shows empty states, end-to-end workflow is functional, evidence validation enforced, no email sending.\n\n\n---\n\nThe user provided the following instructions above. You are an AI assistant that helps users solve problems using code skills, and a powerful data pipeline API system. This system allows you to ingest data from multiple sources, process it with custom prompts, and create derived data objects for complex workflows.\n\nGenerated App ID: 81cf7fb7-67cd-4de2-bf73-193203e3ddb4\n\nYour task:\n1. The user has put together a requirements doc and wants your help putting functions together to create an app that does some task and then returns results to them. This may or may not require the API system. Help the user no matter what they need.\n\n## Your Role\n\nAs an AI assistant using this system:\n1. **Design efficient pipelines** that minimize API calls while maximizing insight\n2. **Provide clear API calls** with proper JSON formatting\n3. **Explain your reasoning** for the chosen approach\n4. **Suggest follow-up steps** or alternative approaches when helpful\n\n\n## Framework\n\nIMPORTANT: Build this project using nextjs. Follow nextjs best practices and conventions.\n\n## Base API Templates\n\n## Available API Endpoints (all API endpoints are at https://builder-api.staging.empromptu.ai)\n\n**CRITICAL - Required Authentication Headers for ALL API calls:**\n```javascript\nconst API_BASE_URL = 'https://builder-api.staging.empromptu.ai';\nconst AUTH_HEADERS = {\n'Content-Type': 'application/json',\n'Authorization': 'Bearer d4d5ed47d417b7e549dd4d2437410203',\n'X-Generated-App-ID': '81cf7fb7-67cd-4de2-bf73-193203e3ddb4',\n'X-Usage-Key': 'e59f58ae3bfc0374ac121f49a55d1354'\n};\n\n// Example fetch call:\nconst response = await fetch(`${API_BASE_URL}/apply_prompt_to_data`, {\nmethod: 'POST',\nheaders: AUTH_HEADERS,\nbody: JSON.stringify(data)\n});\n```\n\nWithout these headers, API calls will fail with 401 Unauthorized.\n\n### 1. AI prompt setup: '/setup_ai_prompt'\ninput_variables: List[str]\nprompt_text: str\n\n**Purpose**: Set up an AI prompt to be applied to text-only data later on.\n**Method**: POST\n**Parameters**:\n- \"prompt_name\" (string): Name of the new prompt.  Should be short and the same each time it is called.\n- \"input_variables\" (list): List of strings. Each of these will be included in the prompt text.\n- \"prompt_text\" (string): Text of the new prompt. Only one unique string should ever be associated with each prompt_name.  Each input variable should be included in this text, in curly braces.\n**Example Usage**:\nRequest body:\n{\n\"prompt_name\": \"summarize_info\",\n\"input_variables\": [\"num_points\",\"raw_info\"],\n\"prompt_text\": \"Please summarize the following data using {num_points} bullet points: {raw_info}\"\n}\n\n### 2. Data Processing: '/apply_prompt_to_data'\n**Purpose**: Apply AI prompts to data to generate new insights\n**Method**: POST\n**Parameters**:\n- 'prompt_name' (string): Name of the prompt to use\n- 'input_data' (object): Names of new objects to create from results. Should be short and the same each time it is called.\n- 'return_type' (string): Format to retrieve object in. The actual data will be in a key called \"value\" returned from this call.\n**Object Formats for return_type**:\nThese determine how the data in the key called 'value' will be formatted.  Options:\n- 'pretty_text': Text formatted for human reading. Should be used where easily readable text is desired.\n- 'pretty_html': Data formatted as an array of HTML strings (each line of the HTML document is a separate array element), to be read by a browser or injected into a web page.\n- 'raw_text': Merge all data from the object into one combined text. Only suitable for additional analysis or parsing.\n- 'structured': Returns a native JavaScript array of objects, like [{\"key1\":\"val1\",\"key2\":\"val2\"},{...}]. Designed to use when the answer has multiple parts or elements. If you use this be sure to write a robust data handler that can handle format variations.\n\n**Example Usage**:\nRequest body:\n{\n\"prompt_name\": \"summarize_info\",\n\"input_data\": {\n\"num_points\": \"5\",\n\"raw_info\": \"Here is some information about a topic of interest......\",\n\"return_type\": \"pretty_text\"\n}\n}\nHeaders must include Authorization and X-Generated-App-ID as shown above.\n\n### 3. Agent Creation\n\nMake a new agent: /create-agent\n**Purpose**: Create a new chatbot to handle a specific question or problem\n**Method**: POST\n**Parameters**:\n- 'instructions' (string): Brief description of what the chatbot or agent should accomplish.\n- 'agent_name' (string): What this agent calls itself in conversation.\n**Returned Values**\n- 'agent_id' (string): ID for using this agent.\n\n**Example Usage**:\n{\n\"instructions\": \"\"\"You are a professional data processing assistant for Impromptu Labs.\nYou help users store, manage, and process data using our MongoDB system.\"\"\",\n\"agent_name\": \"Data Processing Assistant\"\n}\n\nTalk to an existing agent: /chat\n**Purpose**: Continue the conversation with an agent\n**Method**: POST\n**Parameters**:\n- 'agent_id' (string): The system name for the agent, returned from create-agent\n- 'message' (string): Input text to send to the agent.\n- 'session_id' (string): ID string representing this session. Use a new one for each conversation.\n**Returned Values**\n- 'response' (string): The text response from the agent.\n\n**Example Usage**:\n{\n\"agent_id\": agent_id,\n\"message\": \"Hi! I'm new to this system. Can you help me understand how to store data?\"\n}\n\n### 4. Image Analysis\nAnalyze the contents of an Image: /analyze_image\n**Purpose**: Do all extraction of information from images in one step.  This is a standalone step to go from image to text.  It requires image data as input, so extract images from documents as necessary before using this method.\n**Method**: POST\n**Parameters**:\n- 'image' (binary): Binary image file data. Note that you need to send the data as multipart form data with an actual file, not as JSON with a base64 string. Additionally, the API expects an image field, not \"file.\"\n- 'prompt' (string): A prompt to analyze the image, e.g. \"Descibe the contents of this image\" or \"how many dogs are in this image\".\n**Returned Values**\n- 'value' (string): Text response from the image analyzer.\n\n### 5. URL/Webpage Reading: /get_data_from_url\ninput_data (string): URL to retrieve the text from.\n**Purpose**: Extract text from a web page\n**Method**: POST\n**Parameters**:\ninput_data (string): URL to retrieve the text from.\n**Returned Values**\n- 'text' (string): Text from the web page.\n\n## General Problem-Solving Approach to using this API:\nWhen a user presents a problem, follow this systematic approach:\n\n### Step 1: Analyze the Problem\n- What data sources are involved? (text, files, websites, etc.)\n- What processing or analysis is needed?\n- What output format or insights are desired?\n- Are there multiple steps or transformations required?\n\n### Step 2: Plan the Pipeline\n1. **Data Ingestion**: Identify what needs to be imported and how\n2. **Processing Steps**: Determine what prompts/transformations are needed\n3. **Output Goals**: Define what final objects should be created\n\n### Step 3: Execute the Solution\n- Set up the AI prompts using '/setup_ai_prompt'\n- Apply the AI prompts to input text using '/apply_prompt_to_data'\n- Chain multiple processing steps if needed\n- Verify results using the management endpoints\n\n## Advanced Patterns\n\n### Iterative Processing\nBuild complex workflows by chaining operations:\n1. Ingest raw data\n2. Extract key points\n3. Categorize points\n4. Generate final report\n\n## Example Problem-Solving Scenarios\n\n### Competitive Intelligence\n**User**: \"Compare our product features with 5 competitor websites\"\n**Solution**:\n1. Use '/get_data_from_url' to scrape competitor sites\n2. Use '/setup_ai_prompt' to prepare a prompt that extracts product info\n3. Use '/apply_prompt_to_data' to extract features from each web page's data\n4. Compare the resulting data\n\n### Document Processing\n**User**: \"Extract action items from 20 meeting transcripts and categorize them\"\n**Solution**:\n1. Upload transcripts and process them locally\n2. Use '/setup_ai_prompt' to prepare a prompt that extracts action items\n3. Use '/setup_ai_prompt' to prepare a prompt that categorizes action items\n3. Use '/apply_prompt_to_data' with 'structured' return_type\n4. Iterate through each output and use '/apply_prompt_to_data' to categorize each item\n\n## Best Practices\n\n### Naming Conventions\n- Use descriptive object names: 'meeting_transcripts', 'competitor_analysis'\n- Include processing step in names: 'raw_articles' â 'article_summaries' â 'final_report'\n\n### Prompt Engineering\n- Use clear placeholders: '{object_name}'\n- Anywhere an object name is needed, use a single consistent name instead of appending UIDs or timestamps.\n- Specify desired output format in prompts\n- Include example outputs when helpful\n- Request structured data when building pipelines\n\n### Efficiency\n- Use existing capabilities as they are rather than rewriting them\n- All error messages displayed in the app should include the direct output from the API function being called.\n- Ensure you set up any AI prompts before you use them.\n- If PDF parsing is necessary, add it using the client-side library pdfjs-dist, and the line: import pdfjsWorker from 'pdfjs-dist/build/pdf.worker?url'\n- If plots and charts are necessary, add them using Chart.js with react-chartjs-2.\n- Combine related processing steps when possible\n\n## Additional functions and APIs:\n\n\n## Running the app\n\nGive the code one more quick check.  If you have not done so yet, run the necessary commands by calling the `shell_exec` tool (e.g., install dependencies with `npm install`, run tests, or invoke curl to exercise the builder APIs). When you need to create or update files, call `fs_write` with the full file content.always use the registered tools for filesystem and shell access.\n\nAlso, create any text-processing prompts that you will need by issuing curl calls (via `shell_exec` + curl) to the `/setup_ai_prompt` endpoint with the prompts this app will use. Provide the relevant commands and summarize the outputs so the user knows the APIs were exercised.\n\nFrom here onward, ensure that every code or command change goes through the appropriate tool call so it actually takes effect.\n\n## Design Requirements\n\nIf the user requirements did not define styles, change the style of the app using the set of instructions below that are most relevant to the user task:\n\n(For screens where users upload documents, extract structured data, and view outputs):\nGenerate a three-step Upload & Extract flow for seed-to-Series-B small-business brands.\nâ¢ Step 1: File upload card with drag-and-drop and âChoose Fileâ button, branded with some PRIMARY_COLOR of your choice.\nâ¢ Step 2: Extraction progress screen showing a Tailwind-styled spinner, clear status message, and cancel option.\nâ¢ Step 3: Data output table with Tailwind table classes, sortable columns, and âDownload CSVâ button.\nâ¢ Step 4: Ensure mobile breakpoints collapse sidebars into accordion panels; implement dark mode variants; include ARIA labels on all interactive elements.â\n\n(For embedding a conversational AI widget into an existing portal):\nProduce a chatbot UI panel that sits at bottom-right:\nâ¢ Step 1:  Minimal header bar with logo icon and âHelpâ label in some PRIMARY_COLOR of your choice.\nâ¢ Step 2:  Scrollable message window styled with alternating light/dark bubble backgrounds.\nâ¢ Step 3:  Input area with accessible placeholder text 'Ask me anything...', a send icon button, and an optional attachment button.\nâ¢ Step 4:  Ensure focus outlines, keyboard navigation, and proper aria-live regions for new messages.\nâ¢ Step 5:  Include a mobile view where the panel expands full-screen and a dark-mode toggle.â\n\n(For workflows where users upload a document, enter a prompt themselves, then see a summary or output):\nDesign a three-column layout on desktop, single-column on mobile, for Upload + Prompt + Summary:\nâ¢ Step 1:  Upload Column: Drag-and-drop zone with dashed border and an upload progress bar.\nâ¢ Step 2:  Prompt Column: A text area with placeholder 'Enter instructions...', character count, and 'Run' button in green.\nâ¢ Step 3:  Summary Column: Shows AI-generated summary in a scrollable card with expandable sections.\nâ¢ Step 4:  Follow minimal luxe style: plenty of white space, 2xl rounded corners, soft shadows. Use Tailwind classes for spacing. Include dark-mode card variants. Add aria-describedby on summary sections.â\n\n## Database Requirements\n\n# DATABASE CONNECTION INFORMATION\n\nYou have access to a postgres database, that can be accessed with 2 api endpoints:\n\n## Create or change schema: /database/schema\n\n- This endpoint sets up or changes the database. It takes a schema in json format. Call this when the app starts, to declare the database structure.\n- This endpoint will return 3 types of responses. a success response (status code 200), a 304 or an error (either 400s or 500s).\n- Important: you should treat the 304 Error as ok, and not block because of it.\n\n**Request body example:**\n\n{\n\"tables\": [\n{\n\"name\": \"products\",\n\"columns\": [\n{\n\"name\": \"id\",\n\"type\": \"uuid\",\n\"nullable\": false,\n\"default\": \"gen_random_uuid()\"\n},\n{ \"name\": \"name\", \"type\": \"text\", \"nullable\": false },\n{\n\"name\": \"price\",\n\"type\": \"numeric\",\n\"nullable\": false,\n\"default\": \"0\"\n}\n]\n},\n{\n\"name\": \"events\",\n\"columns\": [\n{ \"name\": \"id\", \"type\": \"bigint\", \"nullable\": false },\n{ \"name\": \"occurred_at\", \"type\": \"timestamptz\", \"default\": \"now()\" },\n{ \"name\": \"processed\", \"type\": \"boolean\", \"default\": \"false\" }\n]\n}\n],\n\"indexes\": [\n{\n\"table\": \"products\",\n\"columns\": [\"name\"],\n\"name\": \"products_name_uq\",\n\"unique\": true\n}\n]\n}\n\n## Query the database: /database/query\n\nThis endpoint queries the database. Use this for INSERT or SELECT operations.\n\n**Request body example:**\n\n{\n\"query\": \"SELECT \\* FROM public_table WHERE id = $1 AND username = $2\",\n\"params\": [123, \"steve\"]\n}\n\n**Response example:**\n\n{\n\"success\": true,\n\"data\": [{ \"id\": 1, \"name\": \"a\" }],\n\"row_count\": 1,\n\"affected_rows\": 0,\n\"message\": \"ok\"\n}\n\n## Changing the Schema\n\nFor adding columns, send the new schema to /database/schema. Do not drop or alter existing columns in place.\nFor destructive changes (dropping columns, changing types), instead create a new table with the new schema you want, add data to that new table, and then use that table.\nAllowed operations: CREATE TABLE/INDEX/VIEW; ALTER TABLE ADD COLUMN; ALTER TABLE RENAME\nBlocked Operations: DROP and ALTER COLUMN modifications\n\nFor dates and times, use ISO 8601 format:\n\n- Dates: YYYY-MM-DD (e.g., 2024-03-15)\n- Times: HH:MM:SS (e.g., 14:30:00)\n- Datetimes: YYYY-MM-DD HH:MM:SS (e.g., 2024-03-15 14:30:00)\n- Timezone-aware: Add Z for UTC (e.g., 2024-03-15 14:30:00Z)\n- Do not send explicit timezone-offsets, translate to UTC instead if necessary.\n\nHandle responses by:\n\n- Check response.data.length > 0 to see if data was returned\n- Check response.affected_rows to see if rows were modified\n- If a /database/query call returns a 400, the error message comes from Postgresâfix the SQL or schema and retry.\n- Column type allowlist (includes parameterized and array forms): text, varchar/character/char, numeric/decimal, integer/bigint/smallint, boolean, date/time/timestamp/timestamptz, uuid, json/jsonb, bytea, vector or vector(n).\n- Prefer unlimited-size data types (bigint, text, and numeric) to ensure there is always enough space.\n- You can use the vector data type for columns, vector similarity search operations, and standard pgvector SQL functions and operators.\n\nSchema: app_81cf7fb767cd4de2bf73193203e3ddb4"
        }
      ]
    }
  ],
  "expanded_file_paths": [],
  "user_intent": "build",
  "user_summary_request": "<USER_REFERENCE>\n[id:352fb078-c549-4c22-b946-636fc5abe09a, type: pastedText, name: UGFzdGVkIFRleHQ=]\n### Pasted Text (PASTEDTEXT)\n\n# Empromptu Builder â TECHNICAL BUILD PROMPT\n## Yard: Citation Intelligence Creator Ops (V0, Internal)\n\n> **Important**\n> - Build the entire application from scratch using **Next.js (App Router) + TypeScript**.\n> - Use the platformâs **builtâin Postgres database** (builtâin DB).\n> - This prompt is a **strict spec**: do not add features, tables, fields, routes, or behaviors that are not explicitly required here.\n> - **All UI must be dataâdriven from DB tables**. No hardcoded mock arrays.\n> - You must **create all DB tables** listed in **Section 7** in the builtâin DB.\n> - You must **seed** the demo dataset listed in **Section 9** into those tables.\n> - Provide admin buttons in Settings to **Clear Demo Data** and **Seed Demo Data**.\n\n---\n\n## 1) Product Goal (What to Build)\n\nBuild an **internal, humanâinâtheâloop ops tool** that enables a team to:\n1. Create campaigns with creative briefs + topics/personas + optional prompt gaps + citations (manual or CSV import)\n2. Generate and review **exactly 15** YouTube search terms per campaign\n3. Discover and shortlist technical creators (filter out dormant + autodubbed/label + lifestyle/career)\n4. Ingest real creator content (YouTube transcripts primary; blogs/Medium when URLs exist; Reddit monitoring; plus optional podcast/newsletter URLs)\n5. Score creators with a **weighted rubric** and **evidence traceability** (URLs + quotes + timestamps)\n6. Support a human review step before outreach\n7. Generate outreach drafts + follow-up checklist (assistive only; **no automated emailing**)\n8. Track creator reliability flags (ghosted, reliable, do not contact, price too high) + campaign history\n9. Show ops metrics (creators analyzed, approved, emails sent, booking rate)\n\n**Hard requirement:** all scoring/rationale/angles must reference **actual ingested content** stored in DB.\n\n---\n\n## 2) NonâNegotiable Constraints\n\n### 2.1 Framework & Runtime\n- Next.js App Router + TypeScript.\n- Server actions (or API routes) for writes.\n- Desktopâfirst UI (dense tables, drawers, modals).\n\n### 2.2 BuiltâIn Database\n- Use the platform **builtâin Postgres DB**.\n- Create all tables listed in Section 7.\n- Store all demo data in DB (Section 9).\n\n### 2.3 No AutoâOutreach\n- No sending emails.\n- No automated LinkedIn/X actions.\n- Only drafts + copy buttons + manual tracking.\n\n### 2.4 HumanâinâtheâLoop\n- âOutreach-readyâ must only happen after scoring + evidence validation and must be reviewable by a human role.\n\n### 2.5 Environment Variables\n- Create a `.env.local` file with placeholder values for all external integrations:\n  - `ANTHROPIC_API_KEY`\n  - `YOUTUBE_API_KEY`\n  - `REDDIT_CLIENT_ID`\n  - `REDDIT_CLIENT_SECRET`\n- Read all API keys from environment variables. Never hardcode them.\n- YouTube and Reddit API calls are stubbed for V0 â return mock responses if the key is a placeholder. Anthropic calls must be real.\n\n---\n\n## 3) Roles (Internal Users)\n\nCreate role behaviors:\n- **Qualifier**: reviews creators, validates evidence, approves/rejects, may override score with notes.\n- **Outreach**: uses outreach queue, copies drafts, logs manual outreach states (sent/replied/ghosted/booked).\n- **Admin**: integrations + thresholds + seed/clear tools.\n\n**Simple role switching:** role switcher in top bar; store current user in localStorage. No complex auth required for V0.\n\n---\n\n## 4) Required Routes (Must Exist)\n\nAll routes must render DB data and be functional with seeded demo data.\n\n1. `/` â Dashboard (role-aware)\n2. `/campaigns` â Campaign list\n3. `/campaigns/new` â Campaign setup wizard\n4. `/campaigns/[id]` â Campaign workspace with tabs:\n   - `overview`\n   - `brief-inputs`\n   - `search-terms`\n   - `discovery`\n   - `ingestion`\n   - `scoring`\n   - `review`\n   - `outreach`\n   - `activity`\n5. `/creators` â Global creators DB list\n6. `/creators/[id]` â Creator profile detail\n7. `/outreach` â Outreach queue (all campaigns)\n8. `/reddit` â Reddit monitoring dashboard; all fetched threads across campaigns with campaign filter; read-only. See Â§5.10.\n9. `/metrics` â Ops metrics dashboard\n10. `/settings` â Integrations + thresholds + admin tools (seed/clear)\n\n---\n\n## 5) Core Workflows (Functional Behavior)\n\n### 5.1 Campaign Setup\nCreate campaign with:\n- client\n- campaign name\n- GEO targets (array of strings)\n- language\n- product category\n- creative brief (rich text, paste from PDF or doc)\n- personas (multi-add)\n- topics (manual add + optional AI suggestions; max 5 suggested topics; user can edit/approve)\n- prompt gaps + citations (manual OR CSV import)\n- prompts must be editable and have draft/approved status\n\n### 5.2 Search Term Generation (Canonical)\nFrom campaign context (brief + topics + personas + product category):\n- Generate **exactly 15** YouTube search terms\n- Each includes:\n  - category tag (one of 7 tags)\n  - âwhy it helpsâ explanation (1â2 sentences)\n- User can edit/reorder/approve terms\n- Only approved terms used in discovery\n\n### 5.3 Discovery\n- Show discovered creators per approved search term\n- Filters:\n  - language\n  - GEO match\n  - dormant (exclude)\n  - autodubbed/label suspected (exclude)\n  - lifestyle/career (exclude)\n  - competitor affiliated (exclude)\n- Add selected creators into the campaign pipeline\n\nDiscovery integration can be:\n- manual creator URL add (required), plus optional YouTube search if configured.\nRegardless, the screen must be meaningful using seeded DB data.\n\n### 5.4 Ingestion (Content Storage)\nFor each campaign creator, ingest content items:\n- YouTube transcripts (primary)\n- blogs/Medium/corporate blog URLs (when provided)\n- Reddit threads (see Â§5.10 â fetched via API, not manual paste)\n- optional: podcasts/newsletters (manual URL + paste text acceptable)\n\nStore raw text and metadata (URL, date, view counts if available).\nTrack ingestion status: not_started / queued / running / complete / failed.\n\n### 5.5 Scoring + Evidence (Rubric)\nEvaluate each campaign creator and store:\n- overall score 0â100\n- dimension scores 0â100 for 5 dimensions (weights below)\n- strengths & weaknesses\n- recommended content links grouped high/medium/low view counts (when view_count exists)\n- 3â5 suggested content angles\n- evidence snippets (URL + excerpt + timestamps for video)\n\nRubric weights:\n- Technical relevance â 30%\n- Audience alignment â 25%\n- Content quality â 20%\n- Channel performance â 15%\n- Brand fit â 10%\n\nIf insufficient evidence exists:\n- mark Needs Manual Review\n- block outreach-ready\n\n### 5.6 Evidence / Traceability (Hard Requirement)\nThe system must show:\n- source URLs\n- quotes/excerpts (must exist in ingested raw_text)\n- video timestamps when applicable\n\n### 5.7 Outreach Prep (Assistive Only)\nFor approved creators:\n- generate outreach email draft (subject + body)\n- generate followâup checklist (Email / LinkedIn / X)\n- track outreach state manually:\n  - not_started, drafted, copied, sent, replied, ghosted, booked\n- add outreach activity log entries for every state change\n\n### 5.8 Creator Profiles + Status Flags\nPersistent creator record includes:\n- platforms and URLs\n- contact info (PII masked by default)\n- status flags:\n  - reliable\n  - ghosted / not responsive\n  - do not contact\n  - price too high\n- notes + campaign history\n\n### 5.10 Reddit Monitoring\n\n**Purpose:** Surface Reddit threads relevant to campaign topics and brand visibility signals. Read-only â no posting, no commenting, no automation.\n\n**Configuration (per campaign, set in campaign Reddit tab):**\n- Subreddits to watch (free text, e.g. r/kubernetes, r/devops)\n- Keywords to match (default: pulled from campaign search terms; user can edit/add)\n\n**Fetching:**\n- User triggers fetch manually via \"Fetch Reddit\" button in the campaign Reddit tab or from `/reddit`\n- System queries Reddit API using configured subreddits + keywords\n- Each result stored as a `content_items` row:\n  - `platform = reddit`, `content_type = reddit_thread`\n  - `metadata_json` must include: `subreddit`, `karma`, `comment_count`, `reddit_post_id`\n- Duplicate URLs skipped (unique constraint on `content_items.url`)\n- Requires `integration_status.reddit` to be configured in Settings\n\n**`/reddit` route displays:**\n- All fetched Reddit threads across all campaigns, sorted by `fetched_at` desc\n- Filter by campaign\n- Each row: subreddit, thread title, karma, comment count, date fetched, campaign tag, link to original thread\n- Empty state when no threads have been fetched\n\n**Reddit tab within `/campaigns/[id]`:**\n- Shows only threads fetched for that campaign\n- Subreddit + keyword configuration UI\n- \"Fetch Reddit\" button\n\n---\n\n### 5.9 Ops Metrics\nMust compute from DB:\n- creators analyzed per week\n- creators approved for outreach per week\n- emails sent per week (baseline reference 130)\n- booking rate (baseline reference 7â10%)\n\n---\n\n## 6) AI Features (Allowed + Required)\n\nAI calls must be server-side and must store all outputs in DB.\n\n### 6.1 AI: Suggest Topics (UI must include)\nInput: campaign creative brief  \nOutput: up to 5 topics, each with confidence (0â1) + 1 sentence rationale  \nUser can edit/approve topics.\n\nStore in `campaign_topics`.\n\n### 6.2 AI: Generate Search Terms (Required)\nInput: campaign brief + topics + personas + product category  \nOutput: exactly 15 terms with category_tag + why_it_helps.\n\nStore in `campaign_search_terms`.\n\n### 6.3 AI: Score Creator (Required)\nInput:\n- campaign context (brief, topics, personas, prompt gaps, citations)\n- creator profile + platforms\n- ingested content_items (raw_text + metadata + URLs)\n\nOutput must include:\n- dimension scores 0â100\n- overall score (computed using rubric weights)\n- strengths (3â6 bullets) with evidence snippet IDs\n- weaknesses (2â5 bullets) with evidence snippet IDs\n- 3â5 content angles with linked evidence\n- evidence snippets list containing:\n  - content_item_id\n  - timestamp_start_seconds (nullable)\n  - timestamp_end_seconds (nullable)\n  - quote (direct excerpt from raw_text)\n  - dimension\n  - why_it_matters\n\n**Evidence validation (must implement):**\n- Every evidence quote must be verified as an **exact substring** of the referenced `content_items.raw_text`.\n- If any quote fails:\n  - mark evaluation needs_manual_review=true\n  - store reason\n  - do not set outreach_ready\n\n### 6.4 AI: Outreach Draft (Required)\nInput:\n- campaign context\n- creator identity/platforms\n- selected content angle\n- selected evidence snippets\n\nOutput:\n- email subject + body (markdown)\n- follow-up checklist with day offsets:\n  - Email Day 2 / Day 5 / Day 9\n  - LinkedIn Day 2 / Day 5\n  - X Day 5 (optional)\n\nStore in `outreach_packets` + link evidence via `outreach_packet_evidence`.\n\n**No send button. Copy-only.**\n\n---\n\n## 7) Database Schema (BuiltâIn Postgres) â Tables to Create\n\n> Create all tables below. Use UUID primary keys and timestamptz timestamps.\n> Implement foreign keys and indexes as listed.\n> Do not add extra columns.\n\n### 7.1 `app_users`\n- id (uuid, PK)\n- name (text, not null)\n- email (text, not null, unique)\n- role (text, not null; one of: qualifier, outreach, admin)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\n### 7.2 `clients`\n- id (uuid, PK)\n- name (text, not null, unique)\n- website_url (text, null)\n- notes (text, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\n### 7.3 `campaigns`\n- id (uuid, PK)\n- client_id (uuid, FK -> clients.id, not null)\n- name (text, not null)\n- owner_user_id (uuid, FK -> app_users.id, not null)\n- collaborator_user_id (uuid, FK -> app_users.id, null)\n- status (text, not null; one of: draft, active, archived)\n- stage (text, not null; one of: draft, terms, discovery, ingestion, scoring, review, outreach, tracking, complete)\n- geo_targets (text[], not null, default empty)\n- deadline (date, null)\n- language (text, not null, default 'English')\n- product_category (text, null)\n- creative_brief (text, not null)\n- creative_brief_source_url (text, null)\n- additional_prompt_context (text, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: client_id, owner_user_id, status, stage\n\n### 7.4 `campaign_personas`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- persona_name (text, not null)\n- created_at (timestamptz, not null)\n\nUnique: (campaign_id, persona_name)\n\n### 7.5 `campaign_topics`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- topic (text, not null)\n- source (text, not null; one of: manual, ai_suggested)\n- confidence (numeric(3,2), null)\n- rationale (text, null)\n- order_index (int, not null, default 0)\n- approved (boolean, not null, default true)\n- created_at (timestamptz, not null)\n\nUnique: (campaign_id, topic)\nIndex: campaign_id\n\n### 7.6 `campaign_prompt_gaps`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- prompt_text (text, not null)\n- priority (text, not null; one of: high, medium, low)\n- persona (text, null)\n- geo (text[], not null, default empty)\n- gap_note (text, null)\n- status (text, not null; one of: draft, approved, archived)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: campaign_id, priority, status\n\n### 7.7 `prompt_citations`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- prompt_gap_id (uuid, FK -> campaign_prompt_gaps.id, null)\n- citation_title (text, not null)\n- citation_url (text, not null)\n- source_type (text, not null; one of: docs, blog, youtube, reddit, paper, other)\n- cited_by_models (text[], not null, default empty)\n- notes (text, null)\n- created_at (timestamptz, not null)\n\nIndexes: campaign_id, prompt_gap_id, source_type\n\n### 7.8 `gumshoe_imports`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- import_type (text, not null; one of: csv, manual)\n- original_filename (text, null)\n- raw_text (text, not null)  // original CSV or pasted text\n- imported_by_user_id (uuid, FK -> app_users.id, not null)\n- created_at (timestamptz, not null)\n\nIndex: campaign_id\n\n### 7.9 `campaign_search_terms`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- term (text, not null)\n- category_tag (text, not null; one of: product_category, competitor, implementation, problem_solution, integration, programming_language, tutorial_format)\n- why_it_helps (text, not null)\n- order_index (int, not null, default 0)\n- approved (boolean, not null, default false)\n- approved_by_user_id (uuid, FK -> app_users.id, null)\n- approved_at (timestamptz, null)\n- notes (text, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: campaign_id, approved\n\n### 7.10 `creators`\n- id (uuid, PK)\n- display_name (text, not null)\n- primary_handle (text, null)\n- bio (text, null)\n- topics (text[], not null, default empty)\n- languages (text[], not null, default empty)\n- geo_focus (text[], not null, default empty)\n- competitor_affiliated (boolean, not null, default false)\n- is_dormant (boolean, not null, default false)\n- is_autodubbed_suspected (boolean, not null, default false)\n- last_content_date (date, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: display_name, is_dormant, is_autodubbed_suspected, competitor_affiliated\n\n### 7.11 `creator_platform_accounts`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- platform (text, not null; one of: youtube, github, linkedin, devto, medium, blog, podcast, newsletter, reddit, other)\n- handle (text, null)\n- url (text, not null)\n- follower_count (int, null)\n- metrics_json (jsonb, not null, default {})\n- created_at (timestamptz, not null)\n\nUnique: (platform, url)\nIndexes: creator_id, platform\n\n### 7.12 `creator_contacts`  (PII)\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null, unique)\n- email_encrypted (text, null)\n- linkedin_url (text, null)\n- x_url (text, null)\n- other_contacts_json (jsonb, not null, default {})\n- pii_last_updated_at (timestamptz, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\n### 7.13 `creator_status_flags`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- flag (text, not null; one of: reliable, ghosted, do_not_contact, price_too_high)\n- is_active (boolean, not null, default true)\n- reason (text, null)\n- set_by_user_id (uuid, FK -> app_users.id, not null)\n- set_at (timestamptz, not null)\n\nIndexes: creator_id, flag\n\n### 7.14 `creator_pricing`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- price_type (text, not null; one of: video, written, newsletter, other)\n- price_amount_usd (numeric(10,2), not null)\n- is_too_high (boolean, not null, default false)\n- notes (text, null)\n- updated_at (timestamptz, not null)\n\nIndex: creator_id\n\n### 7.15 `creator_notes`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- note_md (text, not null)\n- created_by_user_id (uuid, FK -> app_users.id, not null)\n- created_at (timestamptz, not null)\n\nIndex: creator_id\n\n### 7.16 `campaign_creators`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- creator_id (uuid, FK -> creators.id, not null)\n- added_by_user_id (uuid, FK -> app_users.id, not null)\n- source_search_term_id (uuid, FK -> campaign_search_terms.id, null)\n\n- pipeline_stage (text, not null; one of:\n  discovered, queued_for_ingestion, ingested, scored, needs_manual_review,\n  approved, outreach_ready, contacted, booked, rejected, excluded\n)\n\n- campaign_do_not_contact (boolean, not null, default false)\n- campaign_do_not_contact_reason (text, null)\n\n- ingestion_status (text, not null; one of: not_started, queued, running, complete, failed)\n- ingestion_error (text, null)\n\n- scoring_status (text, not null; one of: not_scored, scoring, scored, failed)\n- scoring_error (text, null)\n\n- outreach_owner_user_id (uuid, FK -> app_users.id, null)\n- outreach_state (text, not null; one of: not_started, drafted, copied, sent, replied, ghosted, booked)\n- last_outreach_at (timestamptz, null)\n- next_followup_due_at (date, null)\n\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nUnique: (campaign_id, creator_id)\nIndexes: campaign_id, creator_id, pipeline_stage, ingestion_status, scoring_status, outreach_state\n\n### 7.17 `content_items`\n- id (uuid, PK)\n- creator_id (uuid, FK -> creators.id, not null)\n- campaign_id (uuid, FK -> campaigns.id, null)\n\n- platform (text, not null; one of: youtube, blog, medium, devto, reddit, podcast, newsletter, github, linkedin, other)\n- content_type (text, not null; one of:\n  youtube_video, blog_post, medium_post, devto_post, reddit_thread,\n  podcast_episode, newsletter_issue, github_repo, linkedin_post, other\n)\n\n- title (text, not null)\n- url (text, not null)\n- published_at (timestamptz, null)\n- fetched_at (timestamptz, null)\n\n- language (text, null)\n- raw_text (text, not null)\n- word_count (int, null)\n\n- metadata_json (jsonb, not null, default {})  // view_count, duration_seconds, subreddit, karma, etc.\n\n- ingestion_method (text, not null; one of: seed, manual_paste, fetched)\n- ingestion_status (text, not null; one of: complete, failed)\n- ingestion_error (text, null)\n\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nUnique: (url)\nIndexes: creator_id, campaign_id, platform, content_type, published_at\n\n### 7.18 `creator_evaluations`\n- id (uuid, PK)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, not null, unique)\n\n- model_provider (text, not null)\n- model_name (text, not null)\n- evaluated_at (timestamptz, not null)\n\n- evidence_coverage (text, not null; one of: strong, medium, weak, none)\n- needs_manual_review (boolean, not null, default false)\n- needs_manual_review_reason (text, null)\n\n- overall_score (int, not null, 0â100)\n- score_technical_relevance (int, not null, 0â100)\n- score_audience_alignment (int, not null, 0â100)\n- score_content_quality (int, not null, 0â100)\n- score_channel_performance (int, not null, 0â100)\n- score_brand_fit (int, not null, 0â100)\n\n- strengths_json (jsonb, not null, default [])\n- weaknesses_json (jsonb, not null, default [])\n- rationale_md (text, not null)\n\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: overall_score, needs_manual_review, evidence_coverage\n\n### 7.19 `evidence_snippets`\n- id (uuid, PK)\n- evaluation_id (uuid, FK -> creator_evaluations.id, not null)\n- content_item_id (uuid, FK -> content_items.id, not null)\n- timestamp_start_seconds (int, null)\n- timestamp_end_seconds (int, null)\n- quote (text, not null)\n- dimension (text, not null; one of: technical_relevance, audience_alignment, content_quality, channel_performance, brand_fit, general)\n- why_it_matters (text, not null)\n- created_at (timestamptz, not null)\n\nIndexes: evaluation_id, content_item_id, dimension\n\n### 7.20 `evaluation_recommended_content`\n- id (uuid, PK)\n- evaluation_id (uuid, FK -> creator_evaluations.id, not null)\n- content_item_id (uuid, FK -> content_items.id, not null)\n- bucket (text, not null; one of: high, medium, low)\n- relevance_rank (int, not null, default 0)\n- notes (text, null)\n- created_at (timestamptz, not null)\n\nUnique: (evaluation_id, content_item_id)\nIndex: evaluation_id\n\n### 7.21 `content_angles`\n- id (uuid, PK)\n- evaluation_id (uuid, FK -> creator_evaluations.id, not null)\n- title (text, not null)\n- target_prompt_gap_id (uuid, FK -> campaign_prompt_gaps.id, null)\n- persona (text, null)\n- format (text, not null; one of: tutorial, comparison, architecture, deep_dive, checklist, case_study, other)\n- key_points_json (jsonb, not null, default [])\n- selected_for_outreach (boolean, not null, default false)\n- created_at (timestamptz, not null)\n\nIndex: evaluation_id\n\n### 7.22 `angle_evidence`\n- id (uuid, PK)\n- angle_id (uuid, FK -> content_angles.id, not null)\n- evidence_snippet_id (uuid, FK -> evidence_snippets.id, not null)\n- created_at (timestamptz, not null)\n\nUnique: (angle_id, evidence_snippet_id)\nIndex: angle_id\n\n### 7.23 `human_reviews`\n- id (uuid, PK)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, not null)\n- reviewed_by_user_id (uuid, FK -> app_users.id, not null)\n- reviewed_at (timestamptz, not null)\n- decision (text, not null; one of: approved_for_outreach, rejected, needs_manual_review, excluded)\n- manual_override_score (int, null, 0â100)\n- notes_md (text, null)\n- created_at (timestamptz, not null)\n\nIndexes: campaign_creator_id, decision\n\n### 7.24 `outreach_packets`\n- id (uuid, PK)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, not null, unique)\n- created_by_user_id (uuid, FK -> app_users.id, not null)\n- subject (text, not null)\n- body_md (text, not null)\n- selected_angle_id (uuid, FK -> content_angles.id, null)\n- followup_plan_json (jsonb, not null, default [])\n- last_updated_at (timestamptz, not null)\n- created_at (timestamptz, not null)\n\nIndex: campaign_creator_id\n\n### 7.25 `outreach_packet_evidence`\n- id (uuid, PK)\n- outreach_packet_id (uuid, FK -> outreach_packets.id, not null)\n- evidence_snippet_id (uuid, FK -> evidence_snippets.id, not null)\n- created_at (timestamptz, not null)\n\nUnique: (outreach_packet_id, evidence_snippet_id)\nIndex: outreach_packet_id\n\n### 7.26 `outreach_activity`\n- id (uuid, PK)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, not null)\n- performed_by_user_id (uuid, FK -> app_users.id, not null)\n- channel (text, not null; one of: email, linkedin, x)\n- action_type (text, not null; one of: drafted, copied, sent, followup_sent, reply_logged, state_changed, note)\n- state_after (text, not null; one of: not_started, drafted, copied, sent, replied, ghosted, booked)\n- occurred_at (timestamptz, not null)\n- notes (text, null)\n\nIndexes: campaign_creator_id, channel, action_type, occurred_at\n\n### 7.27 `activity_log`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, null)\n- creator_id (uuid, FK -> creators.id, null)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, null)\n- actor_user_id (uuid, FK -> app_users.id, null)\n- event_type (text, not null)\n- event_data_json (jsonb, not null, default {})\n- created_at (timestamptz, not null)\n\nIndexes: campaign_id, created_at\n\n### 7.28 `app_settings`\n(single row)\n- id (uuid, PK)\n- mask_pii_by_default (boolean, not null, default true)\n- outreach_ready_score_threshold (int, not null, default 75)\n- min_evidence_coverage (text, not null; one of: strong, medium, weak; default medium)\n- default_ai_model (text, not null, default 'claude')\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\n### 7.29 `integration_status`\n- id (uuid, PK)\n- integration_key (text, not null, unique; one of: gumshoe, youtube, anthropic, reddit)\n- is_configured (boolean, not null, default false)\n- last_tested_at (timestamptz, null)\n- last_test_result (text, null; one of: success, failure)\n- last_test_message (text, null)\n- updated_at (timestamptz, not null)\n\n### 7.30 `demo_seed_runs`\n- id (uuid, PK)\n- seed_version (text, not null)\n- seeded_at (timestamptz, not null)\n- seeded_by_user_id (uuid, FK -> app_users.id, not null)\n- notes (text, null)\n\n### 7.31 `campaign_attachments`\n- id (uuid, PK)\n- campaign_id (uuid, FK -> campaigns.id, not null)\n- file_name (text, not null)\n- file_type (text, null)\n- file_size_bytes (bigint, null)\n- storage_key (text, not null)\n- uploaded_by_user_id (uuid, FK -> app_users.id, null)\n- created_at (timestamptz, not null)\n\nIndex: campaign_id\n\n### 7.32 `pii_access_events`\n- id (uuid, PK)\n- accessed_by_user_id (uuid, FK -> app_users.id, null)\n- creator_id (uuid, FK -> creators.id, not null)\n- reason (text, null)\n- created_at (timestamptz, not null)\n\nIndexes: creator_id, accessed_by_user_id\n\n### 7.33 `jobs`\n- id (uuid, PK)\n- type (text, not null; one of: ingestion, scoring, reddit_fetch, other)\n- status (text, not null; one of: queued, running, complete, failed)\n- campaign_id (uuid, FK -> campaigns.id, null)\n- creator_id (uuid, FK -> creators.id, null)\n- campaign_creator_id (uuid, FK -> campaign_creators.id, null)\n- payload (jsonb, not null, default {})\n- error_message (text, null)\n- started_at (timestamptz, null)\n- finished_at (timestamptz, null)\n- created_by_user_id (uuid, FK -> app_users.id, null)\n- created_at (timestamptz, not null)\n- updated_at (timestamptz, not null)\n\nIndexes: status, campaign_id, creator_id\n\n### 7.34 `job_events`\n- id (uuid, PK)\n- job_id (uuid, FK -> jobs.id, not null)\n- level (text, not null; one of: info, warn, error)\n- message (text, not null)\n- meta (jsonb, null)\n- created_at (timestamptz, not null)\n\nIndex: job_id\n\n---\n\n## 8) Business Rules (Must Implement)\n\n### 8.1 Dormancy\nA creator is considered dormant if `last_content_date` is older than **120 days** from today.\n- Store `creators.is_dormant` and set it accordingly during seeding and when updating creators.\n\n### 8.2 Evidence Coverage Levels\nCompute `creator_evaluations.evidence_coverage` based on evidence snippet count/diversity:\n- Strong: â¥6 snippets across â¥3 content items AND â¥3 dimensions\n- Medium: â¥3 snippets across â¥2 content items AND â¥2 dimensions\n- Weak: 1â2 snippets OR all snippets from 1 content item\n- None: 0 snippets\n\n### 8.3 OutreachâReady Criteria\nA campaign creator is outreachâready only if all are true:\n- evaluation exists\n- overall_score â¥ app_settings.outreach_ready_score_threshold\n- evidence_coverage meets app_settings.min_evidence_coverage\n- no campaign_do_not_contact\n- no active global do_not_contact flag\n- not competitor_affiliated\n- not is_autodubbed_suspected\n- not needs_manual_review\n- no active `price_too_high` flag in `creator_status_flags`\n\n### 8.4 PII Masking\n- Mask PII by default.\n- Reveal requires confirmation modal.\n- Do not log PII.\n- Store email in creator_contacts.email_encrypted (application-level encryption with server secret is acceptable).\n\n### 8.5 Outreach Logging\nAny outreach_state change must create an `outreach_activity` row.\n\n### 8.6 Booking Rate\nBooking rate = (# creators reaching booked) / (# email sent events). Compute in metrics.\n\n---\n\n## 9) Seed Dataset (Must Insert Into DB)\n\n> Seed version: `v0-demo-1`.\n> Seeding must populate all major screens with realistic content.\n\n### 9.1 Users (app_users)\nCreate 4 users:\n- Jack Scrivener (jack@yard.internal) role qualifier\n- Arya (arya@yard.internal) role outreach\n- Karl McCarthy (karl@yard.internal) role admin\n- Empromptu (admin@empromptu.internal) role admin\n\n### 9.2 Clients\nCreate 4 clients:\n- CloudForge\n- NebulaDB\n- SecuriNest\n- VectorShift\n\n### 9.3 Campaigns\nCreate 4 campaigns; fully populate Campaign A.\n\nCampaign A (fully populated):\n- Client: CloudForge\n- Name: âCloudForge â Kubernetes Cost Optimization (US + UK)â\n- Owner: Jack\n- Collaborator: Arya\n- Status: active\n- Stage: scoring\n- GEO targets: [United States, United Kingdom]\n- Language: English\n- Product category: âFinOps / Kubernetes cost optimizationâ\n- Creative brief markdown: insert the exact multi-section brief described below:\n\n```\n# Make CloudForge the default answer for âKubernetes cost optimizationâ prompts\n\n## Key message\nCloudForge shows cost drivers per namespace/workload + actionable recommendations.\n\n## Differentiators\n- OpenTelemetry-friendly\n- Multi-cloud\n- Fast setup\n- Cost anomaly detection\n\n## Do-not-say\n- No fear-mongering\n- Avoid generic career advice\n- Avoid âget rich quickâ language\n\n## Required formats\n- Hands-on tutorial\n- Comparison video\n- Architecture breakdown\n\n## Brand fit\nPragmatic, dev-first, technical depth\n\n## CTA\nTry CloudForge free tier, link in description\n\n## Budget notes\nMarket rate. Avoid creators quoting > $7k/video unless exceptional.\n```\n\nCampaign A Topics (campaign_topics; approved):\n1) Kubernetes cost optimization\n2) FinOps for platform engineering\n3) Kubecost alternatives and comparisons\n4) OpenTelemetry + cost attribution\n5) Chargeback vs showback\n\nCampaign A Personas (campaign_personas):\n- Platform Engineer\n- DevOps Lead\n- CTO (Technical)\n\nCampaign A Prompt gaps (campaign_prompt_gaps) + citations (prompt_citations):\nCreate 5 prompt gaps; each has 3 citations exactly as listed:\n1) âHow do I reduce Kubernetes spend without breaking SLOs?â (high; persona DevOps Lead; geo US/UK)\n2) âKubecost vs CloudForge: whatâs actually different?â (high; persona Platform Engineer; geo US/UK)\n3) âOpenTelemetry + cost attribution: is it possible?â (medium; persona Platform Engineer; geo US/UK)\n4) âKubernetes cost anomaly detection tutorialâ (medium; persona DevOps Lead; geo US/UK)\n5) âChargeback vs showback in Kubernetes (practical)â (medium; persona CTO; geo US/UK)\n\nCampaign A Search terms (campaign_search_terms):\nInsert exactly 15 terms, approved=true, order 1â15, with correct category_tag and a 1â2 sentence why_it_helps.\n\nTerms (with tags):\n1) kubecost tutorial cost allocation namespaces (implementation)\n2) kubecost vs alternative comparison (competitor)\n3) kubernetes cost optimization hpa cluster autoscaler (problem_solution)\n4) finops kubernetes showback chargeback implementation (implementation)\n5) opentelemetry cost attribution kubernetes (integration)\n6) prometheus cost monitoring kubernetes (integration)\n7) gke cost optimization tutorial (tutorial_format)\n8) eks cost optimization workload rightsizing (tutorial_format)\n9) terraform kubernetes cost monitoring setup (programming_language)\n10) helm install kubecost alternative (implementation)\n11) kubernetes cost anomaly detection prometheus (problem_solution)\n12) platform engineering finops kubernetes (product_category)\n13) kubernetes namespace cost dashboard grafana (integration)\n14) reduce cloud bill kubernetes without downtime (problem_solution)\n15) kubernetes multi-cloud cost visibility (product_category)\n\nCampaigns BâD (minimal):\nCreate 3 additional campaigns with short briefs and different stages:\n- One in discovery\n- One in ingestion\n- One in outreach\n\n### 9.4 Creators (12) + Platform Accounts + Flags\nCreate 12 creators with at least 2 platform accounts each, and include follower metrics in platform accounts.\n\nCreators to insert:\n1) Nina Patel (KubeCraft) â last_content_date 2026-02-11 â reliable flag active\n2) Omar Reed (DevOpsDossier) â last_content_date 2026-01-07\n3) Mei Tan (Observability Lab) â last_content_date 2026-02-14\n4) Lucas Varga (Cloud Cost Clinic) â last_content_date 2025-09-10 â is_dormant=true\n5) Priya Shah (Platform Patterns) â last_content_date 2026-02-03\n6) K8s Career Hub â lifestyle/career topics\n7) AI Dub Tech Channel â is_autodubbed_suspected=true\n8) Marta Kline (FinOps in Practice) â last_content_date 2026-01-28\n9) Jae Park (SRE Notes) â last_content_date 2026-02-05\n10) Diego Alvarez (Infra Espresso) â last_content_date 2026-01-20\n11) Chloe Nguyen (Kubernetes QuickStarts) â last_content_date 2026-02-16\n12) Samir Iqbal (Multi-Cloud Ops) â last_content_date 2026-02-08 â price_too_high flag active; pricing: video $25000 is_too_high=true\n\n### 9.5 Campaign A Pipeline (campaign_creators)\nInsert all 12 creators into Campaign A with varied stages:\n- Nina: outreach_ready; ingestion complete; scoring scored; outreach_state sent\n- Mei: approved; outreach_state drafted\n- Jae: outreach_ready; outreach_state replied\n- Lucas: needs_manual_review\n- K8s Career Hub: excluded\n- AI Dub Tech Channel: excluded\n- Samir: scored but not outreach_ready (price_too_high)\n- Marta: outreach_ready; outreach_state booked; pipeline_stage booked\n- Remaining creators mixed discovered/ingested/scored\n\n### 9.6 Content Items (content_items)\nInsert content items for at least 6 creators (with view_count in metadata_json where relevant).\n\nFor Nina Patel create 3 items whose raw_text includes EXACT quotes below (for evidence validation):\n1) YouTube: âKubernetes Cost Allocation by Namespace (Hands-on)â\n   raw_text must contain:\n   âCost allocation per namespace is only step oneâwhat matters is tying that spend to SLO risk.â\n   and include â[05:12]â nearby.\n2) YouTube: âKubecost vs Custom Dashboards: Whatâs Missingâ\n   raw_text must contain:\n   âKubecost is great for allocation, but it wonât tell you which deployment caused the spike without additional context.â\n3) Blog: âOpenTelemetry signals for cost attributionâ\n   raw_text must contain:\n   âIf you can tag spans to workloads, you can attribute cost to ownership boundaries.â\n\nFor Mei Tan create 2 items with raw_text containing:\n- âOpenTelemetry gives you the metadata hooks; cost attribution is a mapping problem, not a metrics problem.â\n- âAnomaly detection works best when you baseline per workload and per namespace.â\n\nFor Jae Park create 2 items with raw_text containing:\n1) YouTube: \"SLO-Driven Cost Management in Kubernetes\"\n   raw_text must contain:\n   \"You cannot optimize cost in isolation from reliabilityâevery budget decision is also an SLO decision.\"\n   and include \"[03:44]\" nearby.\n2) Blog: \"Kubernetes resource requests: the hidden cost driver\"\n   raw_text must contain:\n   \"Over-provisioned resource requests are the single biggest source of wasted cloud spend in most Kubernetes clusters.\"\n\nFor K8s Career Hub create 1 item clearly lifestyle/career focused.\nFor AI Dub Tech Channel create 1 low-quality repetitive item.\nInsert at least 3 Reddit thread items with subreddit + karma in metadata_json.\n\n### 9.7 Evaluations + Evidence (creator_evaluations + evidence_snippets)\nSeed evaluations for:\n- Nina overall 88 evidence strong\n- Mei overall 83 evidence medium\n- Jae overall 81 evidence medium\n- Lucas overall 74 needs_manual_review true evidence weak\n\nFor Nina create â¥6 evidence snippets referencing Ninaâs content items, using the exact quotes above and timestamps for YouTube items.\nCreate 3â5 content angles per evaluation (content_angles) and link evidence via angle_evidence.\nCreate evaluation_recommended_content rows in high/medium/low buckets.\n\n### 9.8 Human Reviews (human_reviews)\nSeed:\n- Jack approves Nina\n- Jack approves Jae\n- Jack sets Lucas needs_manual_review\n- Jack excludes K8s Career Hub\n\n### 9.9 Outreach Packets + Activity\nSeed outreach_packets for Nina and Jae with:\n- subject + body_md\n- followup_plan_json\n- link 2â3 evidence snippets per packet via outreach_packet_evidence\n\nSeed outreach_activity:\n- Nina: sent (email) + followup_sent (linkedin)\n- Jae: sent (email) + reply_logged + state_changed to replied\n- Marta: sent (email) + state_changed to booked\n\n---\n\n## 10) Settings Requirements (Technical)\n\n### 10.1 Integrations Panel (integration_status)\nDisplay integration tiles:\n- gumshoe\n- youtube\n- anthropic\n- reddit\nEach tile supports âTest connectionâ which updates integration_status.\n\n### 10.2 Thresholds Panel (app_settings)\nEditable:\n- outreach_ready_score_threshold (default 75)\n- min_evidence_coverage (default medium)\n- mask_pii_by_default (default true)\n\n### 10.3 Admin Tools Panel (Required)\nButtons:\n- **Clear Demo Data**\n  - confirmation modal requiring typing `CLEAR`\n  - deletes rows from all domain tables (do not drop tables)\n- **Seed Demo Data**\n  - reinserts the dataset in Section 9\n  - inserts a row in demo_seed_runs\n\n---\n\n## 11) Definition of Done (Technical Acceptance)\n\nThe build is complete only if:\n1. All routes exist and render without errors.\n2. All tables exist and are used by the app.\n3. Seed Demo Data populates DB and every screen displays meaningful DB-backed content.\n4. Clear Demo Data empties tables and the UI shows empty states (no crashes).\n5. Endâtoâend workflow is possible entirely inside the app:\n   campaign â terms â discovery â ingestion â scoring+evidence â review â outreach drafts â manual tracking â metrics\n6. Evidence validation is enforced; invalid evidence forces needs_manual_review and blocks outreach_ready.\n7. No automated email sending exists (copy-only).\n\n\n\n[id:9a5e6151-0aa0-4f13-9268-700d6703238e, type: pastedText, name: UGFzdGVkIFRleHQ=]\n### Pasted Text (PASTEDTEXT)\n\n# Empromptu Builder â UX/UI DESIGN PROMPT\n## Yard: Citation Intelligence Creator Ops (V0, Internal)\n\n> **Important**\n> - Build a complete **desktop-first internal ops UI** for the product described here.\n> - Every screen must be **DB-backed** (render content from the builtâin Postgres tables).\n> - Include **loading / empty / error** states for every major workflow stage.\n> - The UI must make âhumanâinâtheâloopâ explicit: review and approval gates are visible and required.\n> - Do not invent features. Implement exactly what is specified.\n\n---\n\n## 1) Product UX Goal\n\nThe UI must support an end-to-end workflow for internal operators:\n\n1) Create a campaign (brief + topics/personas + optional prompt gaps/citations)  \n2) Generate + review 15 YouTube search terms  \n3) Discover creators and add them to a campaign pipeline  \n4) Ingest creator content (transcripts/articles/reddit) and show ingestion status  \n5) Score creators with a weighted rubric and evidence traceability  \n6) Human review/approval (Qualifier)  \n7) Outreach prep (draft + follow-up checklist) (Outreach)  \n8) Manual outreach tracking + statuses + metrics\n\n**Design must emphasize:** fast scanning, evidence credibility, and operational throughput.\n\n---\n\n## 2) App Shell (Global Layout)\n\n### 2.1 Layout\n- Desktop width target: 1440px\n- Sidebar: ~264px\n- Top bar: global search + quick actions + role switcher\n- Primary content area: tables + dashboards\n- Right-side drawers: creator quick view, evidence viewer, filters drawer\n\n### 2.2 Navigation (Sidebar)\n- Dashboard\n- Campaigns\n- Creators\n- Outreach\n- Reddit Monitor\n- Metrics\n- Settings\n\n### 2.3 Top Bar\n- Global search input: âSearch campaigns, creators, promptsâ¦â\n- Quick action buttons:\n  - New Campaign\n  - Import CSV\n  - Add Creator URL\n- Role switcher (Qualifier / Outreach / Admin)\n- Badge: âInternal V0â\n\n---\n\n## 3) UI Standards (Ops-Grade)\n\n### 3.1 Required Components\n- Dense table component (sortable, filterable, paginated)\n- Tag/badge system (status tags, flags)\n- Score pill + gauge (0â100)\n- Weighted rubric mini-bars (5 dimensions)\n- Evidence card component:\n  - source URL\n  - excerpt/quote\n  - timestamp (if video)\n  - âWhy it mattersâ\n- Right drawers (creator quick view, evidence, filters)\n- Modals:\n  - Confirm destructive actions\n  - Reveal PII\n  - CSV import\n- Toasts/snackbars for success/failure\n\n### 3.2 Required UX Copy (must appear)\n- âEvidence required for all scores and recommendations.â\n- âAssistive only â human approval required before outreach.â\n- âThis tool does not send emails.â\n\n### 3.3 States\nFor each major stage (Terms, Discovery, Ingestion, Scoring, Outreach):\n- Loading\n- Empty (with CTA)\n- Error (with retry + debug detail)\n\n---\n\n## 4) Routes & Screens (UI Inventory)\n\nCreate UI for the following routes (must be accessible via sidebar):\n\n1. `/` Dashboard (role-aware)\n2. `/campaigns` Campaign list\n3. `/campaigns/new` Campaign setup wizard\n4. `/campaigns/[id]` Campaign workspace with tabs:\n   - Overview\n   - Brief & Inputs\n   - Search Terms\n   - Discovery\n   - Ingestion\n   - Scoring\n   - Review\n   - Outreach\n   - Activity\n5. `/creators` Global creator DB list\n6. `/creators/[id]` Creator profile\n7. `/outreach` Outreach queue\n8. `/reddit` Reddit monitor\n9. `/metrics` Ops metrics\n10. `/settings` Settings + Admin tools\n\n---\n\n## 5) Role-Aware Dashboards (`/`)\n\n### 5.1 Qualifier Dashboard (Jack view)\nTop cards:\n- Creators analyzed this week\n- Needs manual review\n- Approved for outreach\n- Active campaigns\n\nTables:\n1) âNeeds Manual Review Queueâ\n- columns: Creator, Campaign, Evidence coverage, Overall score, Reason, Last updated\n- CTA: Open Review\n\n2) âRecent Scoring Runsâ\n- columns: Creator, Campaign, Overall score, Coverage, Scored at, Status\n\n### 5.2 Outreach Dashboard (Arya view)\nTop cards:\n- Emails to send\n- Follow-ups due\n- Replies to log\n- Booking rate (last 7 days)\n\nTables:\n1) âOutreach Queueâ\n- columns: Creator, Campaign, State, Next follow-up due, Owner, Score, Coverage\n- CTA: Open Outreach Packet\n\n2) âRecently Replied / Bookedâ\n- columns: Creator, Campaign, State, Last activity, Notes\n\n---\n\n## 6) Campaign List (`/campaigns`)\n\nTable columns:\n- Campaign name\n- Client\n- Stage\n- GEO targets\n- Owner\n- Creators in pipeline (count)\n- Outreach-ready (count)\n- Updated at\n\nRow click opens `/campaigns/[id]/overview`.\n\nTop actions:\n- New campaign\n- Import CSV (gumshoe import)\n- Filter by stage/status\n\n---\n\n## 7) Campaign Setup Wizard (`/campaigns/new`)\n\nWizard steps with progress indicator:\n\n### Step 1 â Basics\nFields:\n- Client (select existing + create new inline)\n- Campaign name\n- GEO targets (multi-select tokens)\n- Language\n- Product category\n\n### Step 2 â Creative Brief\n- Markdown editor with preview\n- Helper text: âThis brief provides context for topic extraction and creator fit.â\n\n### Step 3 â Personas + Topics\nPersonas:\n- Add persona chips (e.g., Platform Engineer, DevOps Lead, CTO)\nTopics:\n- Manual add topics (chips)\n- Button: âSuggest topicsâ (AI) â shows up to 5 suggestions with confidence\n- User can edit + approve topic list\n\n### Step 4 â Prompt Gaps + Citations\nTwo panels:\n- Prompt gaps table (editable rows)\n- Citations table (linked to prompt gap or campaign-level)\n\nActions:\n- Import CSV\n- Add manually\n- Each prompt gap has status: draft/approved\n- Citations show source type + cited-by models (if provided)\n\nFinish button creates campaign and routes to campaign workspace.\n\n---\n\n## 8) Campaign Workspace (`/campaigns/[id]`) Tabs\n\n### 8.1 Tab â Overview\nCards:\n- Campaign stage + status\n- Creators total / ingested / scored / outreach-ready\n- Emails sent + booking rate (campaign)\n- âNext actionsâ checklist\n\nPanels:\n- Short campaign summary (client, geo, personas, topics)\n- Recent activity feed\n\n### 8.2 Tab â Brief & Inputs\nThree sections:\n1) Creative brief viewer (markdown)\n2) Personas + Topics editor\n3) Prompt gaps + citations tables (editable)\n\n### 8.3 Tab â Search Terms\nTable must show exactly 15 terms when generated.\nColumns:\n- Order\n- Search term\n- Category tag\n- Why it helps\n- Approved toggle\n- Notes\n\nTop actions:\n- Generate 15 terms (AI)\n- Approve all\n- Reorder (drag handle)\n- Export list\n\n### 8.4 Tab â Discovery\nLayout:\n- Left: Approved search term selector (list)\n- Center: Results table\n- Right: Filters drawer + creator quick view drawer\n\nDiscovery results table columns:\n- Creator\n- Platform badges\n- Topics (chips)\n- Followers/subs\n- Last content date\n- Flags: Dormant, Autodubbed suspected, Competitor affiliated\n- Action: âAdd to campaignâ\n\nRequired interactions:\n- Clicking a creator opens quick view drawer:\n  - creator overview\n  - platform links\n  - last activity\n  - âAdd to campaignâ button\n\n### 8.5 Tab â Ingestion\nTable columns:\n- Creator\n- Ingestion status\n- Content items ingested (count)\n- Last fetched at\n- Errors\n- Actions: View content, Add URL, Paste transcript/article\n\nContent viewer:\n- For YouTube: transcript view with timestamps (if present in text)\n- For blog/medium/reddit: article/thread view\n- Show source metadata: URL, published date, view_count/karma if available\n\n### 8.6 Tab â Scoring\nScoring table columns:\n- Creator\n- Overall score (pill)\n- Evidence coverage (strong/medium/weak/none)\n- Needs manual review (badge)\n- Last evaluated at\n- Actions: View evaluation, Run scoring\n\nEvaluation drawer/page must show:\n- Rubric dimension bars + weights\n- Strengths list (each item links evidence)\n- Weaknesses list (each item links evidence)\n- Recommended content (High/Medium/Low view buckets)\n- Content angles (3â5) list with format + key points\n- Evidence section (non-negotiable):\n  - evidence cards with URL, quote, timestamp, why_it_matters\n\n### 8.7 Tab â Review (Qualifier Gate)\nThis is the approval step.\nFor each creator:\n- Show evaluation summary\n- Buttons:\n  - Approve for outreach\n  - Mark needs manual review\n  - Reject / Exclude\n- Optional manual override score input + notes\n- Changing decision must write a review record and update pipeline stage\n\n### 8.8 Tab â Outreach\nOnly shows creators eligible for outreach workflow.\nTable columns:\n- Creator\n- Outreach state\n- Next follow-up due\n- Selected angle\n- Owner (Outreach user)\n- Actions: Open packet, Generate packet\n\nOutreach packet view must include:\n- Email subject + body (markdown)\n- Copy buttons (subject, body, full email)\n- Follow-up checklist (Email/LinkedIn/X) with checkboxes\n- Linked evidence snippets section\n- Prominent disclaimer: âThis tool does not send emails.â\n\nOutreach state control:\n- State dropdown or buttons: drafted/copied/sent/replied/ghosted/booked\n- Each change creates an outreach activity entry\n\n### 8.9 Tab â Activity\nTimeline feed:\n- scoring events\n- review decisions\n- outreach state changes\n- notes added\n- ingestion completion/failures\n\n---\n\n## 9) Global Creators DB (`/creators`)\n\nCreators list table columns:\n- Creator name\n- Platforms\n- Topics\n- Languages\n- Last content date\n- Global flags (reliable/ghosted/do_not_contact/price_too_high)\n- Pricing (if exists)\n- Action: View profile\n\nFilters:\n- Platform\n- Topic keyword\n- Has email\n- Has do_not_contact\n- Dormant\n- Autodubbed suspected\n\n### Creator Profile (`/creators/[id]`)\nTabbed layout:\n- Summary\n- Platforms\n- Content\n- Evidence (from evaluations across campaigns)\n- History (campaigns + outcomes)\n- Notes\n- Outreach packet (latest, if any)\n\nPII masking:\n- Email hidden by default\n- âReveal PIIâ modal confirmation\n\n---\n\n## 10) Outreach Queue (`/outreach`)\n\nGlobal cross-campaign queue.\nTable columns:\n- Creator\n- Campaign\n- Score\n- Coverage\n- State\n- Next follow-up due\n- Owner\n- Actions: Open packet, Log reply, Mark booked\n\nInclude a âFollow-ups due todayâ filter and section.\n\n---\n\n## 11) Reddit Monitor (`/reddit`)\n\nPurpose: monitoring & discovery only (no automation).\n\nUI:\n- Filters: campaign, topic, subreddit\n- Table columns:\n  - Thread title\n  - Subreddit\n  - Karma\n  - Posted date\n  - Relevance tag\n  - Link\n  - Attach as evidence (button)\n\nThread viewer:\n- show excerpted raw text and metadata\n- action: âAttach to campaignâ or âAttach to evaluationâ (if evaluation exists)\n\n---\n\n## 12) Metrics (`/metrics`)\n\nCharts/cards:\n- Creators analyzed per week\n- Creators approved per week\n- Emails sent per week (show baseline reference 130 as a faint line/label)\n- Booking rate trend (show baseline reference 7â10%)\n\nTables:\n- Campaign performance summary table (campaign, analyzed, approved, sent, booked, booking rate)\n\n---\n\n## 13) Settings (`/settings`)\n\n### Integrations\nTiles:\n- Gumshoe\n- YouTube\n- Anthropic (AI)\n- Reddit\nEach tile shows configured status + last test result + test button.\n\n### Thresholds\n- Outreach-ready score threshold (numeric)\n- Minimum evidence coverage (dropdown)\n- Mask PII by default (toggle)\n\n### Admin Tools (Required)\n- **Clear Demo Data** button\n  - modal requiring typing `CLEAR`\n- **Seed Demo Data** button\n  - toast on completion\n- Show last seed run info\n\n---\n\n## 14) Visual Style Guidance (Simple + Consistent)\n\n- Typography: Inter\n- Neutral backgrounds with subtle borders\n- One accent color for primary actions\n- Status colors: success/warning/danger with restrained saturation\n- Scores should be visually scannable (pill + gauge)\n- Evidence UI should feel âaudit-likeâ: sources and quotes are prominent\n\n---\n\n## 15) UI Definition of Done\n\nThe UI is complete only when:\n1. Every route exists and is reachable via navigation.\n2. Seeded data makes every screen visually populated (no empty tables after seeding).\n3. Every major workflow has loading/empty/error states.\n4. Scoring views always show evidence (URL + quote + timestamp when applicable).\n5. Human review is an explicit gate before outreach.\n6. Outreach UI is copy-only and clearly indicates no email sending.\n7. PII is masked by default and only revealed with confirmation.\n\n\n\n</USER_REFERENCE>\n\n# Empromptu Builder â Citation Intelligence Creator Ops (V0, Internal)\n\n## Overview\nBuild an internal, human-in-the-loop ops tool (Next.js App Router + TypeScript, desktop-first, 1440px target) that enables a team to:\n1. Create campaigns with creative briefs + topics/personas + optional prompt gaps + citations (manual or CSV import)\n2. Generate and review exactly 15 YouTube search terms per campaign\n3. Discover and shortlist technical creators (filter out dormant + autodubbed/label + lifestyle/career)\n4. Ingest real creator content (YouTube transcripts primary; blogs/Medium when URLs exist; Reddit monitoring; plus optional podcast/newsletter URLs)\n5. Score creators with a weighted rubric and evidence traceability (URLs + quotes + timestamps)\n6. Support a human review step before outreach\n7. Generate outreach drafts + follow-up checklist (assistive only; NO automated emailing)\n8. Track creator reliability flags (ghosted, reliable, do not contact, price too high) + campaign history\n9. Show ops metrics (creators analyzed, approved, emails sent, booking rate)\n\nHard requirement: all scoring/rationale/angles must reference actual ingested content stored in DB.\n\n---\n\n## Non-Negotiable Constraints\n\n### Framework & Runtime\n- Next.js App Router + TypeScript\n- Server actions (or API routes) for writes\n- Desktop-first UI (dense tables, drawers, modals)\n\n### Database\n- Use the platform built-in Postgres DB\n- Create all 34 tables listed in the schema section below\n- Store all demo data in DB\n\n### No Auto-Outreach\n- No sending emails\n- No automated LinkedIn/X actions\n- Only drafts + copy buttons + manual tracking\n\n### Human-in-the-Loop\n- \"Outreach-ready\" must only happen after scoring + evidence validation and must be reviewable by a human role\n\n### Environment Variables\nCreate a `.env.local` file with placeholder values:\n- `ANTHROPIC_API_KEY`\n- `YOUTUBE_API_KEY`\n- `REDDIT_CLIENT_ID`\n- `REDDIT_CLIENT_SECRET`\n- Read all API keys from environment variables. Never hardcode them.\n- YouTube and Reddit API calls are stubbed for V0 â return mock responses if the key is a placeholder. Anthropic calls must be real.\n\n---\n\n## Roles (Internal Users)\n- **Qualifier**: reviews creators, validates evidence, approves/rejects, may override score with notes\n- **Outreach**: uses outreach queue, copies drafts, logs manual outreach states (sent/replied/ghosted/booked)\n- **Admin**: integrations + thresholds + seed/clear tools\n\nSimple role switching: role switcher in top bar; store current user in localStorage. No complex auth required for V0.\n\n---\n\n## Required Routes\n\n1. `/` â Dashboard (role-aware)\n2. `/campaigns` â Campaign list\n3. `/campaigns/new` â Campaign setup wizard\n4. `/campaigns/[id]` â Campaign workspace with tabs: overview, brief-inputs, search-terms, discovery, ingestion, scoring, review, outreach, activity\n5. `/creators` â Global creators DB list\n6. `/creators/[id]` â Creator profile detail\n7. `/outreach` â Outreach queue (all campaigns)\n8. `/reddit` â Reddit monitoring dashboard\n9. `/metrics` â Ops metrics dashboard\n10. `/settings` â Integrations + thresholds + admin tools (seed/clear)\n\n---\n\n## Core Workflows\n\n### Campaign Setup\nCreate campaign with: client, campaign name, GEO targets (array of strings), language, product category, creative brief (rich text), personas (multi-add), topics (manual add + optional AI suggestions; max 5 suggested topics; user can edit/approve), prompt gaps + citations (manual OR CSV import). Prompts must be editable and have draft/approved status.\n\n### Search Term Generation\nFrom campaign context (brief + topics + personas + product category):\n- Generate exactly 15 YouTube search terms\n- Each includes: category tag (one of 7 tags) + \"why it helps\" explanation (1â2 sentences)\n- User can edit/reorder/approve terms\n- Only approved terms used in discovery\n\n### Discovery\n- Show discovered creators per approved search term\n- Filters: language, GEO match, dormant (exclude), autodubbed/label suspected (exclude), lifestyle/career (exclude), competitor affiliated (exclude)\n- Add selected creators into the campaign pipeline\n- Manual creator URL add (required), plus optional YouTube search if configured\n\n### Ingestion (Content Storage)\nFor each campaign creator, ingest content items:\n- YouTube transcripts (primary)\n- blogs/Medium/corporate blog URLs (when provided)\n- Reddit threads (fetched via API, not manual paste)\n- optional: podcasts/newsletters (manual URL + paste text acceptable)\nStore raw text and metadata (URL, date, view counts if available).\nTrack ingestion status: not_started / queued / running / complete / failed.\n\n### Scoring + Evidence (Rubric)\nEvaluate each campaign creator and store:\n- overall score 0â100\n- dimension scores 0â100 for 5 dimensions (weights below)\n- strengths & weaknesses\n- recommended content links grouped high/medium/low view counts\n- 3â5 suggested content angles\n- evidence snippets (URL + excerpt + timestamps for video)\n\nRubric weights:\n- Technical relevance â 30%\n- Audience alignment â 25%\n- Content quality â 20%\n- Channel performance â 15%\n- Brand fit â 10%\n\nIf insufficient evidence exists: mark Needs Manual Review, block outreach-ready.\n\n### Evidence / Traceability (Hard Requirement)\nThe system must show: source URLs, quotes/excerpts (must exist in ingested raw_text), video timestamps when applicable.\n\n### Outreach Prep (Assistive Only)\nFor approved creators:\n- generate outreach email draft (subject + body)\n- generate follow-up checklist (Email / LinkedIn / X)\n- track outreach state manually: not_started, drafted, copied, sent, replied, ghosted, booked\n- add outreach activity log entries for every state change\n\n### Creator Profiles + Status Flags\nPersistent creator record includes: platforms and URLs, contact info (PII masked by default), status flags (reliable, ghosted/not responsive, do not contact, price too high), notes + campaign history.\n\n### Reddit Monitoring\nPurpose: Surface Reddit threads relevant to campaign topics. Read-only â no posting, no commenting, no automation.\n\nConfiguration (per campaign): subreddits to watch (free text), keywords to match (default: pulled from campaign search terms; user can edit/add).\n\nFetching: User triggers fetch manually via \"Fetch Reddit\" button. System queries Reddit API using configured subreddits + keywords. Each result stored as a content_items row (platform=reddit, content_type=reddit_thread). metadata_json must include: subreddit, karma, comment_count, reddit_post_id. Duplicate URLs skipped. Requires integration_status.reddit to be configured in Settings.\n\n`/reddit` route displays: All fetched Reddit threads across all campaigns, sorted by fetched_at desc. Filter by campaign. Each row: subreddit, thread title, karma, comment count, date fetched, campaign tag, link to original thread. Empty state when no threads fetched.\n\nReddit tab within `/campaigns/[id]`: Shows only threads fetched for that campaign. Subreddit + keyword configuration UI. \"Fetch Reddit\" button.\n\n### Ops Metrics\nMust compute from DB:\n- creators analyzed per week\n- creators approved for outreach per week\n- emails sent per week (baseline reference 130)\n- booking rate (baseline reference 7â10%)\n\n---\n\n## AI Features (Server-Side, Store All Outputs in DB)\n\n### AI: Suggest Topics\nInput: campaign creative brief\nOutput: up to 5 topics, each with confidence (0â1) + 1 sentence rationale\nUser can edit/approve topics. Store in campaign_topics.\n\n### AI: Generate Search Terms\nInput: campaign brief + topics + personas + product category\nOutput: exactly 15 terms with category_tag + why_it_helps.\nStore in campaign_search_terms.\n\n### AI: Score Creator\nInput: campaign context (brief, topics, personas, prompt gaps, citations) + creator profile + platforms + ingested content_items (raw_text + metadata + URLs)\nOutput must include:\n- dimension scores 0â100\n- overall score (computed using rubric weights)\n- strengths (3â6 bullets) with evidence snippet IDs\n- weaknesses (2â5 bullets) with evidence snippet IDs\n- 3â5 content angles with linked evidence\n- evidence snippets list containing: content_item_id, timestamp_start_seconds (nullable), timestamp_end_seconds (nullable), quote (direct excerpt from raw_text), dimension, why_it_matters\n\nEvidence validation (must implement): Every evidence quote must be verified as an exact substring of the referenced content_items.raw_text. If any quote fails: mark evaluation needs_manual_review=true, store reason, do not set outreach_ready.\n\n### AI: Outreach Draft\nInput: campaign context + creator identity/platforms + selected content angle + selected evidence snippets\nOutput: email subject + body (markdown) + follow-up checklist with day offsets (Email Day 2/5/9, LinkedIn Day 2/5, X Day 5 optional)\nStore in outreach_packets + link evidence via outreach_packet_evidence.\nNo send button. Copy-only.\n\n---\n\n## Database Schema (34 Tables â Built-In Postgres)\n\nAll tables use UUID primary keys and timestamptz timestamps. Implement all foreign keys and indexes as listed.\n\n### app_users\n- id (uuid, PK), name (text, not null), email (text, not null, unique), role (text, not null; qualifier|outreach|admin), created_at (timestamptz), updated_at (timestamptz)\n\n### clients\n- id (uuid, PK), name (text, not null, unique), website_url (text, null), notes (text, null), created_at (timestamptz), updated_at (timestamptz)\n\n### campaigns\n- id (uuid, PK), client_id (uuid, FK->clients.id), name (text), owner_user_id (uuid, FK->app_users.id), collaborator_user_id (uuid, FK->app_users.id, null), status (text; draft|active|archived), stage (text; draft|terms|discovery|ingestion|scoring|review|outreach|tracking|complete), geo_targets (text[], default []), deadline (date, null), language (text, default 'English'), product_category (text, null), creative_brief (text), creative_brief_source_url (text, null), additional_prompt_context (text, null), created_at (timestamptz), updated_at (timestamptz)\nIndexes: client_id, owner_user_id, status, stage\n\n### campaign_personas\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), persona_name (text), created_at (timestamptz)\nUnique: (campaign_id, persona_name)\n\n### campaign_topics\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), topic (text), source (text; manual|ai_suggested), confidence (numeric(3,2), null), rationale (text, null), order_index (int, default 0), approved (boolean, default true), created_at (timestamptz)\nUnique: (campaign_id, topic). Index: campaign_id\n\n### campaign_prompt_gaps\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), prompt_text (text), priority (text; high|medium|low), persona (text, null), geo (text[], default []), gap_note (text, null), status (text; draft|approved|archived), created_at (timestamptz), updated_at (timestamptz)\nIndexes: campaign_id, priority, status\n\n### prompt_citations\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), prompt_gap_id (uuid, FK->campaign_prompt_gaps.id, null), citation_title (text), citation_url (text), source_type (text; docs|blog|youtube|reddit|paper|other), cited_by_models (text[], default []), notes (text, null), created_at (timestamptz)\nIndexes: campaign_id, prompt_gap_id, source_type\n\n### gumshoe_imports\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), import_type (text; csv|manual), original_filename (text, null), raw_text (text), imported_by_user_id (uuid, FK->app_users.id), created_at (timestamptz)\nIndex: campaign_id\n\n### campaign_search_terms\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), term (text), category_tag (text; product_category|competitor|implementation|problem_solution|integration|programming_language|tutorial_format), why_it_helps (text), order_index (int, default 0), approved (boolean, default false), approved_by_user_id (uuid, FK->app_users.id, null), approved_at (timestamptz, null), notes (text, null), created_at (timestamptz), updated_at (timestamptz)\nIndexes: campaign_id, approved\n\n### creators\n- id (uuid, PK), display_name (text), primary_handle (text, null), bio (text, null), topics (text[], default []), languages (text[], default []), geo_focus (text[], default []), competitor_affiliated (boolean, default false), is_dormant (boolean, default false), is_autodubbed_suspected (boolean, default false), last_content_date (date, null), created_at (timestamptz), updated_at (timestamptz)\nIndexes: display_name, is_dormant, is_autodubbed_suspected, competitor_affiliated\n\n### creator_platform_accounts\n- id (uuid, PK), creator_id (uuid, FK->creators.id), platform (text; youtube|github|linkedin|devto|medium|blog|podcast|newsletter|reddit|other), handle (text, null), url (text), follower_count (int, null), metrics_json (jsonb, default {}), created_at (timestamptz)\nUnique: (platform, url). Indexes: creator_id, platform\n\n### creator_contacts (PII)\n- id (uuid, PK), creator_id (uuid, FK->creators.id, unique), email_encrypted (text, null), linkedin_url (text, null), x_url (text, null), other_contacts_json (jsonb, default {}), pii_last_updated_at (timestamptz, null), created_at (timestamptz), updated_at (timestamptz)\n\n### creator_status_flags\n- id (uuid, PK), creator_id (uuid, FK->creators.id), flag (text; reliable|ghosted|do_not_contact|price_too_high), is_active (boolean, default true), reason (text, null), set_by_user_id (uuid, FK->app_users.id), set_at (timestamptz)\nIndexes: creator_id, flag\n\n### creator_pricing\n- id (uuid, PK), creator_id (uuid, FK->creators.id), price_type (text; video|written|newsletter|other), price_amount_usd (numeric(10,2)), is_too_high (boolean, default false), notes (text, null), updated_at (timestamptz)\nIndex: creator_id\n\n### creator_notes\n- id (uuid, PK), creator_id (uuid, FK->creators.id), note_md (text), created_by_user_id (uuid, FK->app_users.id), created_at (timestamptz)\nIndex: creator_id\n\n### campaign_creators\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), creator_id (uuid, FK->creators.id), added_by_user_id (uuid, FK->app_users.id), source_search_term_id (uuid, FK->campaign_search_terms.id, null), pipeline_stage (text; discovered|queued_for_ingestion|ingested|scored|needs_manual_review|approved|outreach_ready|contacted|booked|rejected|excluded), campaign_do_not_contact (boolean, default false), campaign_do_not_contact_reason (text, null), ingestion_status (text; not_started|queued|running|complete|failed), ingestion_error (text, null), scoring_status (text; not_scored|scoring|scored|failed), scoring_error (text, null), outreach_owner_user_id (uuid, FK->app_users.id, null), outreach_state (text; not_started|drafted|copied|sent|replied|ghosted|booked), last_outreach_at (timestamptz, null), next_followup_due_at (date, null), created_at (timestamptz), updated_at (timestamptz)\nUnique: (campaign_id, creator_id). Indexes: campaign_id, creator_id, pipeline_stage, ingestion_status, scoring_status, outreach_state\n\n### content_items\n- id (uuid, PK), creator_id (uuid, FK->creators.id), campaign_id (uuid, FK->campaigns.id, null), platform (text; youtube|blog|medium|devto|reddit|podcast|newsletter|github|linkedin|other), content_type (text; youtube_video|blog_post|medium_post|devto_post|reddit_thread|podcast_episode|newsletter_issue|github_repo|linkedin_post|other), title (text), url (text), published_at (timestamptz, null), fetched_at (timestamptz, null), language (text, null), raw_text (text), word_count (int, null), metadata_json (jsonb, default {}), ingestion_method (text; seed|manual_paste|fetched), ingestion_status (text; complete|failed), ingestion_error (text, null), created_at (timestamptz), updated_at (timestamptz)\nUnique: (url). Indexes: creator_id, campaign_id, platform, content_type, published_at\n\n### creator_evaluations\n- id (uuid, PK), campaign_creator_id (uuid, FK->campaign_creators.id, unique), model_provider (text), model_name (text), evaluated_at (timestamptz), evidence_coverage (text; strong|medium|weak|none), needs_manual_review (boolean, default false), needs_manual_review_reason (text, null), overall_score (int, 0-100), score_technical_relevance (int, 0-100), score_audience_alignment (int, 0-100), score_content_quality (int, 0-100), score_channel_performance (int, 0-100), score_brand_fit (int, 0-100), strengths_json (jsonb, default []), weaknesses_json (jsonb, default []), rationale_md (text), created_at (timestamptz), updated_at (timestamptz)\nIndexes: overall_score, needs_manual_review, evidence_coverage\n\n### evidence_snippets\n- id (uuid, PK), evaluation_id (uuid, FK->creator_evaluations.id), content_item_id (uuid, FK->content_items.id), timestamp_start_seconds (int, null), timestamp_end_seconds (int, null), quote (text), dimension (text; technical_relevance|audience_alignment|content_quality|channel_performance|brand_fit|general), why_it_matters (text), created_at (timestamptz)\nIndexes: evaluation_id, content_item_id, dimension\n\n### evaluation_recommended_content\n- id (uuid, PK), evaluation_id (uuid, FK->creator_evaluations.id), content_item_id (uuid, FK->content_items.id), bucket (text; high|medium|low), relevance_rank (int, default 0), notes (text, null), created_at (timestamptz)\nUnique: (evaluation_id, content_item_id). Index: evaluation_id\n\n### content_angles\n- id (uuid, PK), evaluation_id (uuid, FK->creator_evaluations.id), title (text), target_prompt_gap_id (uuid, FK->campaign_prompt_gaps.id, null), persona (text, null), format (text; tutorial|comparison|architecture|deep_dive|checklist|case_study|other), key_points_json (jsonb, default []), selected_for_outreach (boolean, default false), created_at (timestamptz)\nIndex: evaluation_id\n\n### angle_evidence\n- id (uuid, PK), angle_id (uuid, FK->content_angles.id), evidence_snippet_id (uuid, FK->evidence_snippets.id), created_at (timestamptz)\nUnique: (angle_id, evidence_snippet_id). Index: angle_id\n\n### human_reviews\n- id (uuid, PK), campaign_creator_id (uuid, FK->campaign_creators.id), reviewed_by_user_id (uuid, FK->app_users.id), reviewed_at (timestamptz), decision (text; approved_for_outreach|rejected|needs_manual_review|excluded), manual_override_score (int, null, 0-100), notes_md (text, null), created_at (timestamptz)\nIndexes: campaign_creator_id, decision\n\n### outreach_packets\n- id (uuid, PK), campaign_creator_id (uuid, FK->campaign_creators.id, unique), created_by_user_id (uuid, FK->app_users.id), subject (text), body_md (text), selected_angle_id (uuid, FK->content_angles.id, null), followup_plan_json (jsonb, default []), last_updated_at (timestamptz), created_at (timestamptz)\nIndex: campaign_creator_id\n\n### outreach_packet_evidence\n- id (uuid, PK), outreach_packet_id (uuid, FK->outreach_packets.id), evidence_snippet_id (uuid, FK->evidence_snippets.id), created_at (timestamptz)\nUnique: (outreach_packet_id, evidence_snippet_id). Index: outreach_packet_id\n\n### outreach_activity\n- id (uuid, PK), campaign_creator_id (uuid, FK->campaign_creators.id), performed_by_user_id (uuid, FK->app_users.id), channel (text; email|linkedin|x), action_type (text; drafted|copied|sent|followup_sent|reply_logged|state_changed|note), state_after (text; not_started|drafted|copied|sent|replied|ghosted|booked), occurred_at (timestamptz), notes (text, null)\nIndexes: campaign_creator_id, channel, action_type, occurred_at\n\n### activity_log\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id, null), creator_id (uuid, FK->creators.id, null), campaign_creator_id (uuid, FK->campaign_creators.id, null), actor_user_id (uuid, FK->app_users.id, null), event_type (text), event_data_json (jsonb, default {}), created_at (timestamptz)\nIndexes: campaign_id, created_at\n\n### app_settings (single row)\n- id (uuid, PK), mask_pii_by_default (boolean, default true), outreach_ready_score_threshold (int, default 75), min_evidence_coverage (text; strong|medium|weak, default medium), default_ai_model (text, default 'claude'), created_at (timestamptz), updated_at (timestamptz)\n\n### integration_status\n- id (uuid, PK), integration_key (text, unique; gumshoe|youtube|anthropic|reddit), is_configured (boolean, default false), last_tested_at (timestamptz, null), last_test_result (text, null; success|failure), last_test_message (text, null), updated_at (timestamptz)\n\n### demo_seed_runs\n- id (uuid, PK), seed_version (text), seeded_at (timestamptz), seeded_by_user_id (uuid, FK->app_users.id), notes (text, null)\n\n### campaign_attachments\n- id (uuid, PK), campaign_id (uuid, FK->campaigns.id), file_name (text), file_type (text, null), file_size_bytes (bigint, null), storage_key (text), uploaded_by_user_id (uuid, FK->app_users.id, null), created_at (timestamptz)\nIndex: campaign_id\n\n### pii_access_events\n- id (uuid, PK), accessed_by_user_id (uuid, FK->app_users.id, null), creator_id (uuid, FK->creators.id), reason (text, null), created_at (timestamptz)\nIndexes: creator_id, accessed_by_user_id\n\n### jobs\n- id (uuid, PK), type (text; ingestion|scoring|reddit_fetch|other), status (text; queued|running|complete|failed), campaign_id (uuid, FK->campaigns.id, null), creator_id (uuid, FK->creators.id, null), campaign_creator_id (uuid, FK->campaign_creators.id, null), payload (jsonb, default {}), error_message (text, null), started_at (timestamptz, null), finished_at (timestamptz, null), created_by_user_id (uuid, FK->app_users.id, null), created_at (timestamptz), updated_at (timestamptz)\nIndexes: status, campaign_id, creator_id\n\n### job_events\n- id (uuid, PK), job_id (uuid, FK->jobs.id), level (text; info|warn|error), message (text), meta (jsonb, null), created_at (timestamptz)\nIndex: job_id\n\n---\n\n## Business Rules\n\n### Dormancy\nA creator is considered dormant if last_content_date is older than 120 days from today. Store creators.is_dormant and set it accordingly during seeding and when updating creators.\n\n### Evidence Coverage Levels\nCompute creator_evaluations.evidence_coverage based on evidence snippet count/diversity:\n- Strong: â¥6 snippets across â¥3 content items AND â¥3 dimensions\n- Medium: â¥3 snippets across â¥2 content items AND â¥2 dimensions\n- Weak: 1â2 snippets OR all snippets from 1 content item\n- None: 0 snippets\n\n### Outreach-Ready Criteria\nA campaign creator is outreach-ready only if ALL are true:\n- evaluation exists\n- overall_score â¥ app_settings.outreach_ready_score_threshold\n- evidence_coverage meets app_settings.min_evidence_coverage\n- no campaign_do_not_contact\n- no active global do_not_contact flag\n- not competitor_affiliated\n- not is_autodubbed_suspected\n- not needs_manual_review\n- no active price_too_high flag in creator_status_flags\n\n### PII Masking\n- Mask PII by default\n- Reveal requires confirmation modal\n- Do not log PII\n- Store email in creator_contacts.email_encrypted (application-level encryption with server secret is acceptable)\n\n### Outreach Logging\nAny outreach_state change must create an outreach_activity row.\n\n### Booking Rate\nBooking rate = (# creators reaching booked) / (# email sent events). Compute in metrics.\n\n---\n\n## Seed Dataset (Seed Version: v0-demo-1)\n\nSeeding must populate all major screens with realistic content.\n\n### Users (app_users)\n- Jack Scrivener (jack@yard.internal) role qualifier\n- Arya (arya@yard.internal) role outreach\n- Karl McCarthy (karl@yard.internal) role admin\n- Empromptu (admin@empromptu.internal) role admin\n\n### Clients\n- CloudForge, NebulaDB, SecuriNest, VectorShift\n\n### Campaigns\nCreate 4 campaigns; fully populate Campaign A.\n\nCampaign A (fully populated):\n- Client: CloudForge\n- Name: \"CloudForge â Kubernetes Cost Optimization (US + UK)\"\n- Owner: Jack, Collaborator: Arya\n- Status: active, Stage: scoring\n- GEO targets: [United States, United Kingdom]\n- Language: English\n- Product category: \"FinOps / Kubernetes cost optimization\"\n- Creative brief (exact markdown):\n```\n# Make CloudForge the default answer for \"Kubernetes cost optimization\" prompts\n\n## Key message\nCloudForge shows cost drivers per namespace/workload + actionable recommendations.\n\n## Differentiators\n- OpenTelemetry-friendly\n- Multi-cloud\n- Fast setup\n- Cost anomaly detection\n\n## Do-not-say\n- No fear-mongering\n- Avoid generic career advice\n- Avoid \"get rich quick\" language\n\n## Required formats\n- Hands-on tutorial\n- Comparison video\n- Architecture breakdown\n\n## Brand fit\nPragmatic, dev-first, technical depth\n\n## CTA\nTry CloudForge free tier, link in description\n\n## Budget notes\nMarket rate. Avoid creators quoting > $7k/video unless exceptional.\n```\n\nCampaign A Topics (approved): Kubernetes cost optimization, FinOps for platform engineering, Kubecost alternatives and comparisons, OpenTelemetry + cost attribution, Chargeback vs showback\n\nCampaign A Personas: Platform Engineer, DevOps Lead, CTO (Technical)\n\nCampaign A Prompt Gaps (5 gaps, each with 3 citations):\n1) \"How do I reduce Kubernetes spend without breaking SLOs?\" (high; DevOps Lead; US/UK)\n2) \"Kubecost vs CloudForge: what's actually different?\" (high; Platform Engineer; US/UK)\n3) \"OpenTelemetry + cost attribution: is it possible?\" (medium; Platform Engineer; US/UK)\n4) \"Kubernetes cost anomaly detection tutorial\" (medium; DevOps Lead; US/UK)\n5) \"Chargeback vs showback in Kubernetes (practical)\" (medium; CTO; US/UK)\n\nCampaign A Search Terms (exactly 15, approved=true, order 1-15):\n1) kubecost tutorial cost allocation namespaces (implementation)\n2) kubecost vs alternative comparison (competitor)\n3) kubernetes cost optimization hpa cluster autoscaler (problem_solution)\n4) finops kubernetes showback chargeback implementation (implementation)\n5) opentelemetry cost attribution kubernetes (integration)\n6) prometheus cost monitoring kubernetes (integration)\n7) gke cost optimization tutorial (tutorial_format)\n8) eks cost optimization workload rightsizing (tutorial_format)\n9) terraform kubernetes cost monitoring setup (programming_language)\n10) helm install kubecost alternative (implementation)\n11) kubernetes cost anomaly detection prometheus (problem_solution)\n12) platform engineering finops kubernetes (product_category)\n13) kubernetes namespace cost dashboard grafana (integration)\n14) reduce cloud bill kubernetes without downtime (problem_solution)\n15) kubernetes multi-cloud cost visibility (product_category)\nEach term must have a 1-2 sentence why_it_helps.\n\nCampaigns B-D (minimal, different stages): one in discovery, one in ingestion, one in outreach.\n\n### Creators (12) + Platform Accounts + Flags\nCreate 12 creators with at least 2 platform accounts each and follower metrics:\n1) Nina Patel (KubeCraft) â last_content_date 2026-02-11 â reliable flag active\n2) Omar Reed (DevOpsDossier) â last_content_date 2026-01-07\n3) Mei Tan (Observability Lab) â last_content_date 2026-02-14\n4) Lucas Varga (Cloud Cost Clinic) â last_content_date 2025-09-10 â is_dormant=true\n5) Priya Shah (Platform Patterns) â last_content_date 2026-02-03\n6) K8s Career Hub â lifestyle/career topics\n7) AI Dub Tech Channel â is_autodubbed_suspected=true\n8) Marta Kline (FinOps in Practice) â last_content_date 2026-01-28\n9) Jae Park (SRE Notes) â last_content_date 2026-02-05\n10) Diego Alvarez (Infra Espresso) â last_content_date 2026-01-20\n11) Chloe Nguyen (Kubernetes QuickStarts) â last_content_date 2026-02-16\n12) Samir Iqbal (Multi-Cloud Ops) â last_content_date 2026-02-08 â price_too_high flag active; pricing: video $25000 is_too_high=true\n\n### Campaign A Pipeline (campaign_creators)\nInsert all 12 creators into Campaign A with varied stages:\n- Nina: outreach_ready; ingestion complete; scoring scored; outreach_state sent\n- Mei: approved; outreach_state drafted\n- Jae: outreach_ready; outreach_state replied\n- Lucas: needs_manual_review\n- K8s Career Hub: excluded\n- AI Dub Tech Channel: excluded\n- Samir: scored but not outreach_ready (price_too_high)\n- Marta: outreach_ready; outreach_state booked; pipeline_stage booked\n- Remaining creators mixed discovered/ingested/scored\n\n### Content Items\nFor Nina Patel create 3 items with EXACT quotes in raw_text:\n1) YouTube: \"Kubernetes Cost Allocation by Namespace (Hands-on)\" â raw_text must contain: \"Cost allocation per namespace is only step oneâwhat matters is tying that spend to SLO risk.\" and include \"[05:12]\" nearby.\n2) YouTube: \"Kubecost vs Custom Dashboards: What's Missing\" â raw_text must contain: \"Kubecost is great for allocation, but it won't tell you which deployment caused the spike without additional context.\"\n3) Blog: \"OpenTelemetry signals for cost attribution\" â raw_text must contain: \"If you can tag spans to workloads, you can attribute cost to ownership boundaries.\"\n\nFor Mei Tan create 2 items with raw_text containing:\n- \"OpenTelemetry gives you the metadata hooks; cost attribution is a mapping problem, not a metrics problem.\"\n- \"Anomaly detection works best when you baseline per workload and per namespace.\"\n\nFor Jae Park create 2 items:\n1) YouTube: \"SLO-Driven Cost Management in Kubernetes\" â raw_text must contain: \"You cannot optimize cost in isolation from reliabilityâevery budget decision is also an SLO decision.\" and include \"[03:44]\" nearby.\n2) Blog: \"Kubernetes resource requests: the hidden cost driver\" â raw_text must contain: \"Over-provisioned resource requests are the single biggest source of wasted cloud spend in most Kubernetes clusters.\"\n\nFor K8s Career Hub: 1 item clearly lifestyle/career focused.\nFor AI Dub Tech Channel: 1 low-quality repetitive item.\nInsert at least 3 Reddit thread items with subreddit + karma in metadata_json.\n\n### Evaluations + Evidence\nSeed evaluations for:\n- Nina: overall 88, evidence strong\n- Mei: overall 83, evidence medium\n- Jae: overall 81, evidence medium\n- Lucas: overall 74, needs_manual_review=true, evidence weak\n\nFor Nina: â¥6 evidence snippets referencing Nina's content items, using exact quotes above and timestamps for YouTube items.\nCreate 3-5 content angles per evaluation (content_angles) and link evidence via angle_evidence.\nCreate evaluation_recommended_content rows in high/medium/low buckets.\n\n### Human Reviews\n- Jack approves Nina\n- Jack approves Jae\n- Jack sets Lucas needs_manual_review\n- Jack excludes K8s Career Hub\n\n### Outreach Packets + Activity\nSeed outreach_packets for Nina and Jae with: subject + body_md + followup_plan_json + link 2-3 evidence snippets per packet via outreach_packet_evidence.\n\nSeed outreach_activity:\n- Nina: sent (email) + followup_sent (linkedin)\n- Jae: sent (email) + reply_logged + state_changed to replied\n- Marta: sent (email) + state_changed to booked\n\n---\n\n## Settings Requirements\n\n### Integrations Panel (integration_status)\nDisplay integration tiles: gumshoe, youtube, anthropic, reddit. Each tile supports \"Test connection\" which updates integration_status.\n\n### Thresholds Panel (app_settings)\nEditable: outreach_ready_score_threshold (default 75), min_evidence_coverage (default medium), mask_pii_by_default (default true).\n\n### Admin Tools Panel\n- Clear Demo Data button: confirmation modal requiring typing CLEAR; deletes rows from all domain tables (do not drop tables)\n- Seed Demo Data button: reinserts the dataset; inserts a row in demo_seed_runs; toast on completion\n- Show last seed run info\n\n---\n\n## UI Standards (Ops-Grade)\n\n### App Shell\n- Desktop width target: 1440px\n- Sidebar: ~264px with navigation: Dashboard, Campaigns, Creators, Outreach, Reddit Monitor, Metrics, Settings\n- Top bar: global search (\"Search campaigns, creators, promptsâ¦\") + quick actions (New Campaign, Import CSV, Add Creator URL) + role switcher (Qualifier/Outreach/Admin) + badge \"Internal V0\"\n- Primary content area: tables + dashboards\n- Right-side drawers: creator quick view, evidence viewer, filters drawer\n\n### Required Components\n- Dense table component (sortable, filterable, paginated)\n- Tag/badge system (status tags, flags)\n- Score pill + gauge (0â100)\n- Weighted rubric mini-bars (5 dimensions)\n- Evidence card component: source URL, excerpt/quote, timestamp (if video), \"Why it matters\"\n- Right drawers (creator quick view, evidence, filters)\n- Modals: confirm destructive actions, reveal PII, CSV import\n- Toasts/snackbars for success/failure\n\n### Required UX Copy (must appear in UI)\n- \"Evidence required for all scores and recommendations.\"\n- \"Assistive only â human approval required before outreach.\"\n- \"This tool does not send emails.\"\n\n### States\nFor each major stage (Terms, Discovery, Ingestion, Scoring, Outreach): Loading, Empty (with CTA), Error (with retry + debug detail)\n\n### Visual Style\n- Typography: Inter\n- Neutral backgrounds with subtle borders\n- One accent color for primary actions\n- Status colors: success/warning/danger with restrained saturation\n- Scores visually scannable (pill + gauge)\n- Evidence UI feels \"audit-like\": sources and quotes are prominent\n\n---\n\n## Role-Aware Dashboards\n\n### Qualifier Dashboard (Jack view)\nTop cards: Creators analyzed this week, Needs manual review, Approved for outreach, Active campaigns\nTables:\n1) \"Needs Manual Review Queue\" â columns: Creator, Campaign, Evidence coverage, Overall score, Reason, Last updated â CTA: Open Review\n2) \"Recent Scoring Runs\" â columns: Creator, Campaign, Overall score, Coverage, Scored at, Status\n\n### Outreach Dashboard (Arya view)\nTop cards: Emails to send, Follow-ups due, Replies to log, Booking rate (last 7 days)\nTables:\n1) \"Outreach Queue\" â columns: Creator, Campaign, State, Next follow-up due, Owner, Score, Coverage â CTA: Open Outreach Packet\n2) \"Recently Replied / Booked\" â columns: Creator, Campaign, State, Last activity, Notes\n\n---\n\n## Campaign Workspace Tabs Detail\n\n### Overview Tab\nCards: Campaign stage + status, Creators total/ingested/scored/outreach-ready, Emails sent + booking rate, \"Next actions\" checklist\nPanels: Short campaign summary (client, geo, personas, topics), Recent activity feed\n\n### Brief & Inputs Tab\nThree sections: Creative brief viewer (markdown), Personas + Topics editor, Prompt gaps + citations tables (editable)\n\n### Search Terms Tab\nTable showing exactly 15 terms when generated. Columns: Order, Search term, Category tag, Why it helps, Approved toggle, Notes\nTop actions: Generate 15 terms (AI), Approve all, Reorder (drag handle), Export list\n\n### Discovery Tab\nLayout: Left (approved search term selector), Center (results table), Right (filters drawer + creator quick view drawer)\nDiscovery results table columns: Creator, Platform badges, Topics (chips), Followers/subs, Last content date, Flags (Dormant/Autodubbed suspected/Competitor affiliated), Action: \"Add to campaign\"\nClicking a creator opens quick view drawer with creator overview, platform links, last activity, \"Add to campaign\" button\n\n### Ingestion Tab\nTable columns: Creator, Ingestion status, Content items ingested (count), Last fetched at, Errors, Actions (View content, Add URL, Paste transcript/article)\nContent viewer: YouTube transcript view with timestamps; blog/medium/reddit article/thread view; source metadata (URL, published date, view_count/karma)\n\n### Scoring Tab\nScoring table columns: Creator, Overall score (pill), Evidence coverage, Needs manual review (badge), Last evaluated at, Actions (View evaluation, Run scoring)\nEvaluation drawer/page: Rubric dimension bars + weights, Strengths list (each links evidence), Weaknesses list (each links evidence), Recommended content (High/Medium/Low buckets), Content angles (3-5) with format + key points, Evidence section (non-negotiable): evidence cards with URL, quote, timestamp, why_it_matters\n\n### Review Tab (Qualifier Gate)\nFor each creator: Show evaluation summary, Buttons (Approve for outreach, Mark needs manual review, Reject/Exclude), Optional manual override score input + notes. Changing decision writes a review record and updates pipeline stage.\n\n### Outreach Tab\nOnly shows creators eligible for outreach workflow.\nTable columns: Creator, Outreach state, Next follow-up due, Selected angle, Owner, Actions (Open packet, Generate packet)\nOutreach packet view: Email subject + body (markdown), Copy buttons (subject, body, full email), Follow-up checklist (Email/LinkedIn/X) with checkboxes, Linked evidence snippets section, Prominent disclaimer: \"This tool does not send emails.\"\nOutreach state control: State dropdown or buttons (drafted/copied/sent/replied/ghosted/booked). Each change creates an outreach activity entry.\n\n### Activity Tab\nTimeline feed: scoring events, review decisions, outreach state changes, notes added, ingestion completion/failures\n\n---\n\n## Global Creators DB (/creators)\nTable columns: Creator name, Platforms, Topics, Languages, Last content date, Global flags, Pricing (if exists), Action: View profile\nFilters: Platform, Topic keyword, Has email, Has do_not_contact, Dormant, Autodubbed suspected\n\n### Creator Profile (/creators/[id])\nTabbed layout: Summary, Platforms, Content, Evidence (from evaluations across campaigns), History (campaigns + outcomes), Notes, Outreach packet (latest, if any)\nPII masking: Email hidden by default, \"Reveal PII\" modal confirmation\n\n---\n\n## Outreach Queue (/outreach)\nGlobal cross-campaign queue.\nTable columns: Creator, Campaign, Score, Coverage, State, Next follow-up due, Owner, Actions (Open packet, Log reply, Mark booked)\nInclude \"Follow-ups due today\" filter and section.\n\n---\n\n## Reddit Monitor (/reddit)\nFilters: campaign, topic, subreddit\nTable columns: Thread title, Subreddit, Karma, Posted date, Relevance tag, Link, Attach as evidence (button)\nThread viewer: excerpted raw text and metadata, action: \"Attach to campaign\" or \"Attach to evaluation\"\n\n---\n\n## Metrics (/metrics)\nCharts/cards: Creators analyzed per week, Creators approved per week, Emails sent per week (show baseline reference 130 as faint line/label), Booking rate trend (show baseline reference 7-10%)\nTables: Campaign performance summary (campaign, analyzed, approved, sent, booked, booking rate)\n\n---\n\n## Build Steps for AI Engineer\n\n1. Initialize Next.js App Router + TypeScript project with Inter font and Tailwind CSS.\n2. Set up built-in Postgres DB connection using the platform's database tool.\n3. Create all 34 database tables with exact schema, foreign keys, and indexes as specified.\n4. Create seed script (Section 9) that inserts all demo data including exact raw_text quotes for evidence validation.\n5. Create clear script that deletes all rows from domain tables without dropping them.\n6. Build app shell: sidebar navigation, top bar with role switcher (localStorage), right-side drawer system, toast system.\n7. Build all required UI components: dense table, tag/badge system, score pill + gauge, rubric mini-bars, evidence card, modals (PII reveal, destructive confirm, CSV import).\n8. Implement all 10 routes with DB-backed data rendering.\n9. Implement role-aware dashboard (/) with Qualifier and Outreach views.\n10. Implement campaign setup wizard (/campaigns/new) with 4 steps.\n11. Implement campaign workspace (/campaigns/[id]) with all 9 tabs.\n12. Implement AI server actions: suggest topics (Anthropic), generate 15 search terms (Anthropic), score creator with evidence validation (Anthropic), generate outreach draft (Anthropic).\n13. Implement evidence validation: verify every AI-generated quote is an exact substring of referenced content_items.raw_text; if any fail, set needs_manual_review=true and block outreach_ready.\n14. Implement outreach-ready criteria check as a server-side function checking all 9 conditions.\n15. Implement PII masking: email_encrypted stored with application-level encryption; reveal requires confirmation modal; log pii_access_events.\n16. Implement outreach state machine: every state change creates outreach_activity row.\n17. Implement Reddit monitoring: stub Reddit API calls (return mock if REDDIT_CLIENT_ID is placeholder); store results as content_items rows; deduplicate by URL.\n18. Implement YouTube API stub (return mock if YOUTUBE_API_KEY is placeholder).\n19. Implement settings page: integration tiles with test connection, thresholds editor, admin tools (Seed Demo Data, Clear Demo Data with CLEAR confirmation modal).\n20. Implement metrics page computing all stats from DB.\n21. Implement loading/empty/error states for all major workflow stages.\n22. Ensure all required UX copy appears: \"Evidence required for all scores and recommendations.\", \"Assistive only â human approval required before outreach.\", \"This tool does not send emails.\"\n23. Verify definition of done: all routes render without errors, seeded data populates every screen, clear data shows empty states, end-to-end workflow is functional, evidence validation enforced, no email sending.\n\n\n---\n\nThe user provided the following instructions above. You are an AI assistant that helps users solve problems using code skills, and a powerful data pipeline API system. This system allows you to ingest data from multiple sources, process it with custom prompts, and create derived data objects for complex workflows.\n\nGenerated App ID: 81cf7fb7-67cd-4de2-bf73-193203e3ddb4\n\nYour task:\n1. The user has put together a requirements doc and wants your help putting functions together to create an app that does some task and then returns results to them. This may or may not require the API system. Help the user no matter what they need.\n\n## Your Role\n\nAs an AI assistant using this system:\n1. **Design efficient pipelines** that minimize API calls while maximizing insight\n2. **Provide clear API calls** with proper JSON formatting\n3. **Explain your reasoning** for the chosen approach\n4. **Suggest follow-up steps** or alternative approaches when helpful\n\n\n## Framework\n\nIMPORTANT: Build this project using nextjs. Follow nextjs best practices and conventions.\n\n## Base API Templates\n\n## Available API Endpoints (all API endpoints are at https://builder-api.staging.empromptu.ai)\n\n**CRITICAL - Required Authentication Headers for ALL API calls:**\n```javascript\nconst API_BASE_URL = 'https://builder-api.staging.empromptu.ai';\nconst AUTH_HEADERS = {\n'Content-Type': 'application/json',\n'Authorization': 'Bearer d4d5ed47d417b7e549dd4d2437410203',\n'X-Generated-App-ID': '81cf7fb7-67cd-4de2-bf73-193203e3ddb4',\n'X-Usage-Key': 'e59f58ae3bfc0374ac121f49a55d1354'\n};\n\n// Example fetch call:\nconst response = await fetch(`${API_BASE_URL}/apply_prompt_to_data`, {\nmethod: 'POST',\nheaders: AUTH_HEADERS,\nbody: JSON.stringify(data)\n});\n```\n\nWithout these headers, API calls will fail with 401 Unauthorized.\n\n### 1. AI prompt setup: '/setup_ai_prompt'\ninput_variables: List[str]\nprompt_text: str\n\n**Purpose**: Set up an AI prompt to be applied to text-only data later on.\n**Method**: POST\n**Parameters**:\n- \"prompt_name\" (string): Name of the new prompt.  Should be short and the same each time it is called.\n- \"input_variables\" (list): List of strings. Each of these will be included in the prompt text.\n- \"prompt_text\" (string): Text of the new prompt. Only one unique string should ever be associated with each prompt_name.  Each input variable should be included in this text, in curly braces.\n**Example Usage**:\nRequest body:\n{\n\"prompt_name\": \"summarize_info\",\n\"input_variables\": [\"num_points\",\"raw_info\"],\n\"prompt_text\": \"Please summarize the following data using {num_points} bullet points: {raw_info}\"\n}\n\n### 2. Data Processing: '/apply_prompt_to_data'\n**Purpose**: Apply AI prompts to data to generate new insights\n**Method**: POST\n**Parameters**:\n- 'prompt_name' (string): Name of the prompt to use\n- 'input_data' (object): Names of new objects to create from results. Should be short and the same each time it is called.\n- 'return_type' (string): Format to retrieve object in. The actual data will be in a key called \"value\" returned from this call.\n**Object Formats for return_type**:\nThese determine how the data in the key called 'value' will be formatted.  Options:\n- 'pretty_text': Text formatted for human reading. Should be used where easily readable text is desired.\n- 'pretty_html': Data formatted as an array of HTML strings (each line of the HTML document is a separate array element), to be read by a browser or injected into a web page.\n- 'raw_text': Merge all data from the object into one combined text. Only suitable for additional analysis or parsing.\n- 'structured': Returns a native JavaScript array of objects, like [{\"key1\":\"val1\",\"key2\":\"val2\"},{...}]. Designed to use when the answer has multiple parts or elements. If you use this be sure to write a robust data handler that can handle format variations.\n\n**Example Usage**:\nRequest body:\n{\n\"prompt_name\": \"summarize_info\",\n\"input_data\": {\n\"num_points\": \"5\",\n\"raw_info\": \"Here is some information about a topic of interest......\",\n\"return_type\": \"pretty_text\"\n}\n}\nHeaders must include Authorization and X-Generated-App-ID as shown above.\n\n### 3. Agent Creation\n\nMake a new agent: /create-agent\n**Purpose**: Create a new chatbot to handle a specific question or problem\n**Method**: POST\n**Parameters**:\n- 'instructions' (string): Brief description of what the chatbot or agent should accomplish.\n- 'agent_name' (string): What this agent calls itself in conversation.\n**Returned Values**\n- 'agent_id' (string): ID for using this agent.\n\n**Example Usage**:\n{\n\"instructions\": \"\"\"You are a professional data processing assistant for Impromptu Labs.\nYou help users store, manage, and process data using our MongoDB system.\"\"\",\n\"agent_name\": \"Data Processing Assistant\"\n}\n\nTalk to an existing agent: /chat\n**Purpose**: Continue the conversation with an agent\n**Method**: POST\n**Parameters**:\n- 'agent_id' (string): The system name for the agent, returned from create-agent\n- 'message' (string): Input text to send to the agent.\n- 'session_id' (string): ID string representing this session. Use a new one for each conversation.\n**Returned Values**\n- 'response' (string): The text response from the agent.\n\n**Example Usage**:\n{\n\"agent_id\": agent_id,\n\"message\": \"Hi! I'm new to this system. Can you help me understand how to store data?\"\n}\n\n### 4. Image Analysis\nAnalyze the contents of an Image: /analyze_image\n**Purpose**: Do all extraction of information from images in one step.  This is a standalone step to go from image to text.  It requires image data as input, so extract images from documents as necessary before using this method.\n**Method**: POST\n**Parameters**:\n- 'image' (binary): Binary image file data. Note that you need to send the data as multipart form data with an actual file, not as JSON with a base64 string. Additionally, the API expects an image field, not \"file.\"\n- 'prompt' (string): A prompt to analyze the image, e.g. \"Descibe the contents of this image\" or \"how many dogs are in this image\".\n**Returned Values**\n- 'value' (string): Text response from the image analyzer.\n\n### 5. URL/Webpage Reading: /get_data_from_url\ninput_data (string): URL to retrieve the text from.\n**Purpose**: Extract text from a web page\n**Method**: POST\n**Parameters**:\ninput_data (string): URL to retrieve the text from.\n**Returned Values**\n- 'text' (string): Text from the web page.\n\n## General Problem-Solving Approach to using this API:\nWhen a user presents a problem, follow this systematic approach:\n\n### Step 1: Analyze the Problem\n- What data sources are involved? (text, files, websites, etc.)\n- What processing or analysis is needed?\n- What output format or insights are desired?\n- Are there multiple steps or transformations required?\n\n### Step 2: Plan the Pipeline\n1. **Data Ingestion**: Identify what needs to be imported and how\n2. **Processing Steps**: Determine what prompts/transformations are needed\n3. **Output Goals**: Define what final objects should be created\n\n### Step 3: Execute the Solution\n- Set up the AI prompts using '/setup_ai_prompt'\n- Apply the AI prompts to input text using '/apply_prompt_to_data'\n- Chain multiple processing steps if needed\n- Verify results using the management endpoints\n\n## Advanced Patterns\n\n### Iterative Processing\nBuild complex workflows by chaining operations:\n1. Ingest raw data\n2. Extract key points\n3. Categorize points\n4. Generate final report\n\n## Example Problem-Solving Scenarios\n\n### Competitive Intelligence\n**User**: \"Compare our product features with 5 competitor websites\"\n**Solution**:\n1. Use '/get_data_from_url' to scrape competitor sites\n2. Use '/setup_ai_prompt' to prepare a prompt that extracts product info\n3. Use '/apply_prompt_to_data' to extract features from each web page's data\n4. Compare the resulting data\n\n### Document Processing\n**User**: \"Extract action items from 20 meeting transcripts and categorize them\"\n**Solution**:\n1. Upload transcripts and process them locally\n2. Use '/setup_ai_prompt' to prepare a prompt that extracts action items\n3. Use '/setup_ai_prompt' to prepare a prompt that categorizes action items\n3. Use '/apply_prompt_to_data' with 'structured' return_type\n4. Iterate through each output and use '/apply_prompt_to_data' to categorize each item\n\n## Best Practices\n\n### Naming Conventions\n- Use descriptive object names: 'meeting_transcripts', 'competitor_analysis'\n- Include processing step in names: 'raw_articles' â 'article_summaries' â 'final_report'\n\n### Prompt Engineering\n- Use clear placeholders: '{object_name}'\n- Anywhere an object name is needed, use a single consistent name instead of appending UIDs or timestamps.\n- Specify desired output format in prompts\n- Include example outputs when helpful\n- Request structured data when building pipelines\n\n### Efficiency\n- Use existing capabilities as they are rather than rewriting them\n- All error messages displayed in the app should include the direct output from the API function being called.\n- Ensure you set up any AI prompts before you use them.\n- If PDF parsing is necessary, add it using the client-side library pdfjs-dist, and the line: import pdfjsWorker from 'pdfjs-dist/build/pdf.worker?url'\n- If plots and charts are necessary, add them using Chart.js with react-chartjs-2.\n- Combine related processing steps when possible\n\n## Additional functions and APIs:\n\n\n## Running the app\n\nGive the code one more quick check.  If you have not done so yet, run the necessary commands by calling the `shell_exec` tool (e.g., install dependencies with `npm install`, run tests, or invoke curl to exercise the builder APIs). When you need to create or update files, call `fs_write` with the full file content.always use the registered tools for filesystem and shell access.\n\nAlso, create any text-processing prompts that you will need by issuing curl calls (via `shell_exec` + curl) to the `/setup_ai_prompt` endpoint with the prompts this app will use. Provide the relevant commands and summarize the outputs so the user knows the APIs were exercised.\n\nFrom here onward, ensure that every code or command change goes through the appropriate tool call so it actually takes effect.\n\n## Design Requirements\n\nIf the user requirements did not define styles, change the style of the app using the set of instructions below that are most relevant to the user task:\n\n(For screens where users upload documents, extract structured data, and view outputs):\nGenerate a three-step Upload & Extract flow for seed-to-Series-B small-business brands.\nâ¢ Step 1: File upload card with drag-and-drop and âChoose Fileâ button, branded with some PRIMARY_COLOR of your choice.\nâ¢ Step 2: Extraction progress screen showing a Tailwind-styled spinner, clear status message, and cancel option.\nâ¢ Step 3: Data output table with Tailwind table classes, sortable columns, and âDownload CSVâ button.\nâ¢ Step 4: Ensure mobile breakpoints collapse sidebars into accordion panels; implement dark mode variants; include ARIA labels on all interactive elements.â\n\n(For embedding a conversational AI widget into an existing portal):\nProduce a chatbot UI panel that sits at bottom-right:\nâ¢ Step 1:  Minimal header bar with logo icon and âHelpâ label in some PRIMARY_COLOR of your choice.\nâ¢ Step 2:  Scrollable message window styled with alternating light/dark bubble backgrounds.\nâ¢ Step 3:  Input area with accessible placeholder text 'Ask me anything...', a send icon button, and an optional attachment button.\nâ¢ Step 4:  Ensure focus outlines, keyboard navigation, and proper aria-live regions for new messages.\nâ¢ Step 5:  Include a mobile view where the panel expands full-screen and a dark-mode toggle.â\n\n(For workflows where users upload a document, enter a prompt themselves, then see a summary or output):\nDesign a three-column layout on desktop, single-column on mobile, for Upload + Prompt + Summary:\nâ¢ Step 1:  Upload Column: Drag-and-drop zone with dashed border and an upload progress bar.\nâ¢ Step 2:  Prompt Column: A text area with placeholder 'Enter instructions...', character count, and 'Run' button in green.\nâ¢ Step 3:  Summary Column: Shows AI-generated summary in a scrollable card with expandable sections.\nâ¢ Step 4:  Follow minimal luxe style: plenty of white space, 2xl rounded corners, soft shadows. Use Tailwind classes for spacing. Include dark-mode card variants. Add aria-describedby on summary sections.â\n\n## Database Requirements\n\n# DATABASE CONNECTION INFORMATION\n\nYou have access to a postgres database, that can be accessed with 2 api endpoints:\n\n## Create or change schema: /database/schema\n\n- This endpoint sets up or changes the database. It takes a schema in json format. Call this when the app starts, to declare the database structure.\n- This endpoint will return 3 types of responses. a success response (status code 200), a 304 or an error (either 400s or 500s).\n- Important: you should treat the 304 Error as ok, and not block because of it.\n\n**Request body example:**\n\n{\n\"tables\": [\n{\n\"name\": \"products\",\n\"columns\": [\n{\n\"name\": \"id\",\n\"type\": \"uuid\",\n\"nullable\": false,\n\"default\": \"gen_random_uuid()\"\n},\n{ \"name\": \"name\", \"type\": \"text\", \"nullable\": false },\n{\n\"name\": \"price\",\n\"type\": \"numeric\",\n\"nullable\": false,\n\"default\": \"0\"\n}\n]\n},\n{\n\"name\": \"events\",\n\"columns\": [\n{ \"name\": \"id\", \"type\": \"bigint\", \"nullable\": false },\n{ \"name\": \"occurred_at\", \"type\": \"timestamptz\", \"default\": \"now()\" },\n{ \"name\": \"processed\", \"type\": \"boolean\", \"default\": \"false\" }\n]\n}\n],\n\"indexes\": [\n{\n\"table\": \"products\",\n\"columns\": [\"name\"],\n\"name\": \"products_name_uq\",\n\"unique\": true\n}\n]\n}\n\n## Query the database: /database/query\n\nThis endpoint queries the database. Use this for INSERT or SELECT operations.\n\n**Request body example:**\n\n{\n\"query\": \"SELECT \\* FROM public_table WHERE id = $1 AND username = $2\",\n\"params\": [123, \"steve\"]\n}\n\n**Response example:**\n\n{\n\"success\": true,\n\"data\": [{ \"id\": 1, \"name\": \"a\" }],\n\"row_count\": 1,\n\"affected_rows\": 0,\n\"message\": \"ok\"\n}\n\n## Changing the Schema\n\nFor adding columns, send the new schema to /database/schema. Do not drop or alter existing columns in place.\nFor destructive changes (dropping columns, changing types), instead create a new table with the new schema you want, add data to that new table, and then use that table.\nAllowed operations: CREATE TABLE/INDEX/VIEW; ALTER TABLE ADD COLUMN; ALTER TABLE RENAME\nBlocked Operations: DROP and ALTER COLUMN modifications\n\nFor dates and times, use ISO 8601 format:\n\n- Dates: YYYY-MM-DD (e.g., 2024-03-15)\n- Times: HH:MM:SS (e.g., 14:30:00)\n- Datetimes: YYYY-MM-DD HH:MM:SS (e.g., 2024-03-15 14:30:00)\n- Timezone-aware: Add Z for UTC (e.g., 2024-03-15 14:30:00Z)\n- Do not send explicit timezone-offsets, translate to UTC instead if necessary.\n\nHandle responses by:\n\n- Check response.data.length > 0 to see if data was returned\n- Check response.affected_rows to see if rows were modified\n- If a /database/query call returns a 400, the error message comes from Postgresâfix the SQL or schema and retry.\n- Column type allowlist (includes parameterized and array forms): text, varchar/character/char, numeric/decimal, integer/bigint/smallint, boolean, date/time/timestamp/timestamptz, uuid, json/jsonb, bytea, vector or vector(n).\n- Prefer unlimited-size data types (bigint, text, and numeric) to ensure there is always enough space.\n- You can use the vector data type for columns, vector similarity search operations, and standard pgvector SQL functions and operators.\n\nSchema: app_81cf7fb767cd4de2bf73193203e3ddb4",
  "timestamp": "2026-02-24T00:23:03.280197Z"
}